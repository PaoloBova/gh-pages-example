{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Payoff Matrices (part 2)\n",
    "\n",
    "> This module contains payoff matrices for different evolutionary games\n",
    ">\n",
    "> Part 2 contains payoff matrices for the following games\n",
    "> - Encanacao et al. 2016\n",
    "> - Vasconcelos et al. 2014\n",
    "> - Stochastic payoffs, a. la. Hilbe et al. 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp `dummy_exp`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "# We could like to export all payoff matrices to the same module, `payoffs`.\n",
    "# However,  we must set a default_exp and if we use the same module as\n",
    "# another notebook, we will overwrite all existing exports with those in\n",
    "# this file. Hence we set a dummy default_exp, `dummy_exp`, and each time\n",
    "# we export a cell, we specify the `payoffs` module.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/d/Paolo-Work/git/gh-pages-example/gh_pages_example/model_utils.py:299: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if (ind not in allowed_inds) and (str(ind) not in allowed_inds):\n",
      "/mnt/d/Paolo-Work/git/gh-pages-example/gh_pages_example/methods.py:260: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  ergodic = np.array(V.transpose(0, 2, 1)[y], dtype=float)\n"
     ]
    }
   ],
   "source": [
    "# | hide\n",
    "# | export\n",
    "from nbdev.showdoc import *\n",
    "from fastcore.test import test_eq, test_close\n",
    "import collections\n",
    "import functools\n",
    "from gh_pages_example.utils import *\n",
    "from gh_pages_example.types import *\n",
    "from gh_pages_example.methods import *\n",
    "from gh_pages_example.model_utils import *\n",
    "import itertools\n",
    "import math\n",
    "import typing\n",
    "\n",
    "import fastcore.test\n",
    "import more_itertools\n",
    "import numpy as np\n",
    "import nptyping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True)  # don't use scientific notation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export payoffs\n",
    "def payoffs_encanacao_2016(models):\n",
    "    names = ['b_r', 'b_s', 'c_s', 'c_t', 'σ']\n",
    "    b_r, b_s, c_s, c_t, σ = [models[k] for k in names]\n",
    "    payoffs = {}\n",
    "    n_players = 3\n",
    "    n_sectors = 3\n",
    "    n_strategies_per_sector = [2, 2, 2]\n",
    "    n_strategies_total = 6\n",
    "    # All players are from the first sector, playing that sector's first strategy\n",
    "    index_min = \"0-0-0\"\n",
    "    # All players are from the third sector, playing that sector's second strategy\n",
    "    index_max = \"5-5-5\"\n",
    "    # Note: The seperator makes it easy to represent games where n_strategies_total >= 10.\n",
    "\n",
    "    # It is also trivial to define a vector which maps these indexes to strategy profiles\n",
    "    # As sector order is fixed we could neglect to mention suscripts for each sector\n",
    "    strategy_names = [\"D\", \"C\", \"D\", \"C\", \"D\", \"C\"]\n",
    "\n",
    "    zero = np.zeros(b_r.shape[0])\n",
    "    # As in the main text\n",
    "    payoffs[\"C-C-C\"] = {\"P3\": b_r-2*c_s,\n",
    "                        \"P2\": σ+b_s-c_t,\n",
    "                        \"P1\": σ+b_s}\n",
    "    payoffs[\"C-C-D\"] = {\"P3\": -c_s,\n",
    "                        \"P2\": b_s-c_t,\n",
    "                        \"P1\": zero}\n",
    "    payoffs[\"C-D-C\"] = {\"P3\": b_r-c_s,\n",
    "                        \"P2\": zero,\n",
    "                        \"P1\": b_s}\n",
    "    payoffs[\"C-D-D\"] = {\"P3\": zero,\n",
    "                        \"P2\": σ,\n",
    "                        \"P1\": σ}\n",
    "    payoffs[\"D-C-C\"] = {\"P3\": zero,\n",
    "                        \"P2\": σ-c_t,\n",
    "                        \"P1\": σ}\n",
    "    payoffs[\"D-C-D\"] = {\"P3\": zero,\n",
    "                        \"P2\": -c_t,\n",
    "                        \"P1\": zero}\n",
    "    payoffs[\"D-D-C\"] = {\"P3\": zero,\n",
    "                        \"P2\": zero,\n",
    "                        \"P1\": zero}\n",
    "    payoffs[\"D-D-D\"] = {\"P3\": zero,\n",
    "                        \"P2\": σ,\n",
    "                        \"P1\": σ}\n",
    "\n",
    "    # The following indexes capture all strategy profiles where each player is fixed to a unique sector\n",
    "    # (and player order does not matter, so we need only consider one ordering of sectors).\n",
    "    payoffs[\"4-2-0\"] = payoffs[\"D-D-D\"]\n",
    "    payoffs[\"4-2-1\"] = payoffs[\"D-D-C\"]\n",
    "    payoffs[\"4-3-0\"] = payoffs[\"D-C-D\"]\n",
    "    payoffs[\"4-3-1\"] = payoffs[\"D-C-C\"]\n",
    "    payoffs[\"5-2-0\"] = payoffs[\"C-D-D\"]\n",
    "    payoffs[\"5-2-1\"] = payoffs[\"C-D-C\"]\n",
    "    payoffs[\"5-3-0\"] = payoffs[\"C-C-D\"]\n",
    "    payoffs[\"5-3-1\"] = payoffs[\"C-C-C\"]\n",
    "    return {**models, \"payoffs\": payoffs}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vasconselos et al. 2014"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They introduce a model of a Collective Risk Dilemma. It is a variant of the\n",
    "public goods game where players must achieve a target level of contributions\n",
    "to avoid risking a disaster which destroys the group's endowments.\n",
    "\n",
    "We compute payoffs when players contribute $0$ or a fixed $c$ proportion of\n",
    "their endowment as a contribution in\n",
    "a game with up to $n$ participants. To do this, we compute the payoffs as a\n",
    "function of the number of contributors, then use that function for each\n",
    "relevant strategy profile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export payoffs\n",
    "@multi\n",
    "def build_payoffs(models: dict):\n",
    "    return models.get('payoffs_key')\n",
    "\n",
    "\n",
    "@method(build_payoffs, 'vasconcelos_2014_primitives')\n",
    "def build_payoffs(models: dict):\n",
    "    names = ['payoffs_state', 'c', 'T', 'b_r', 'b_p', 'r']\n",
    "    payoffs_state, c, T, b_r, b_p, r = [models[k] for k in names]\n",
    "    strategy_counts = payoffs_state['strategy_counts']\n",
    "    n_r = strategy_counts[\"2\"]\n",
    "    n_p = strategy_counts[\"4\"]\n",
    "    risk = r * (n_r * c * b_r + n_p * c * b_p < T)\n",
    "    # The payoffs must be computed for each strategy type in the interaction.\n",
    "    # In games where we employ hypergeometric sampling, we usually do not\n",
    "    # care about player order in the interaction. If order did matter, then\n",
    "    # we would represent the payoffs per strategy still but it would capture\n",
    "    # the expected payoffs given how likely a player of that strategy was to\n",
    "    # play in each node of the extensive-form game. Non-players of type 0\n",
    "    # usually do not have payoffs.\n",
    "    payoffs = {\"1\": (1 - risk) * b_r,  # rich_free_rider\n",
    "               \"2\": (1 - risk) * c * b_r,  # rich_contributor\n",
    "               \"3\": (1 - risk) * b_p,  # poor_free_rider\n",
    "               \"4\": (1 - risk) * c * b_p}  # poor_contributor\n",
    "    return {**models, \"payoff_primitives\": payoffs}\n",
    "\n",
    "\n",
    "@method(build_payoffs, 'vasconcelos_2014')\n",
    "def build_payoffs(models: dict):\n",
    "    profiles = create_profiles({'n_players': models.get('n_players', 5),\n",
    "                                'n_strategies': [2, 2]})['profiles']\n",
    "    payoffs = {}\n",
    "    for profile in profiles:\n",
    "        profile_tuple = thread_macro(profile,\n",
    "                                     (str.split, \"-\"),\n",
    "                                     (map, int, \"self\"),\n",
    "                                     list,\n",
    "                                     reversed,\n",
    "                                     list,\n",
    "                                     np.array,\n",
    "                                     )\n",
    "        strategy_counts = {f\"{i}\": np.sum(\n",
    "            profile_tuple == i) for i in range(5)}\n",
    "        payoffs_state = {'strategy_counts': strategy_counts}\n",
    "        primitives = thread_macro(models,\n",
    "                                  (assoc,\n",
    "                                   'payoffs_state', payoffs_state,\n",
    "                                   'payoffs_key', \"vasconcelos_2014_primitives\"),\n",
    "                                  build_payoffs,\n",
    "                                  (get, \"payoff_primitives\"),\n",
    "                                  )\n",
    "        payoffs[profile] = {}\n",
    "        for i, strategy in enumerate(profile_tuple):\n",
    "            if strategy == 0:\n",
    "                continue\n",
    "            elif strategy == 1:\n",
    "                payoffs[profile][f\"P{i+1}\"] = primitives['1']\n",
    "            elif strategy == 2:\n",
    "                payoffs[profile][f\"P{i+1}\"] = primitives['2']\n",
    "            elif strategy == 3:\n",
    "                payoffs[profile][f\"P{i+1}\"] = primitives['3']\n",
    "            elif strategy == 4:\n",
    "                payoffs[profile][f\"P{i+1}\"] = primitives['4']\n",
    "            else:\n",
    "                continue\n",
    "    return {**models, \"payoffs\": payoffs}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are a few simple tests of the payoff primitives for their model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {'payoffs_state': {'strategy_counts': {\"2\": 2,\n",
    "                                                \"4\": 4}},\n",
    "          'c': 0.5,\n",
    "          'T': 2,\n",
    "          'b_r': 4,\n",
    "          'b_p': 2,\n",
    "          'r': 0.5,\n",
    "          'payoffs_key': 'vasconcelos_2014_primitives'}\n",
    "models = build_payoffs(models)\n",
    "fastcore.test.test_eq(models['payoff_primitives'],\n",
    "                      {'1': 4,\n",
    "                       '2': 2,\n",
    "                       '3': 2,\n",
    "                       '4': 1})\n",
    "models = {**models,\n",
    "          'payoffs_state': {'strategy_counts': {\"2\": 0,\n",
    "                                                \"4\": 1}}, }\n",
    "models = build_payoffs(models)\n",
    "fastcore.test.test_eq(models['payoff_primitives'],\n",
    "                      {'1': 2,\n",
    "                       '2': 1,\n",
    "                       '3': 1,\n",
    "                       '4': 0.5})\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We quickly check that we can generate payoffs for each of the 4**5 possible\n",
    "interactions in their model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {'c': 0.5,\n",
    "          'T': 2,\n",
    "          'b_r': 4,\n",
    "          'b_p': 2,\n",
    "          'r': 0.5,\n",
    "          'payoffs_key': 'vasconcelos_2014'}\n",
    "models = build_payoffs(models)\n",
    "fastcore.test.test_eq(len(models['payoffs']), 4**5)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we are unwilling to use the 5**5 possible strategy profiles for computing\n",
    "the transition matrices for the evolutionary system, we can always restrict\n",
    "our attention to the payoffs given the number of contributors from each sector.\n",
    "We often use hypergeometric sampling anyways when computing the success of\n",
    "each strategy in the evolutionary system."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Payoff Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export payoffs\n",
    "@method(build_payoffs, 'payoff_function_wrapper')\n",
    "def build_payoffs(models: dict):\n",
    "    profiles = create_profiles(models)['profiles']\n",
    "    profile_payoffs_key = models['profile_payoffs_key']\n",
    "    payoffs_state = models.get(\"payoffs_state\", {})\n",
    "    payoffs = {}\n",
    "    for profile in profiles:\n",
    "        profile_tuple = string_to_tuple(profile)\n",
    "        strategy_counts = dict(zip(*np.unique(profile_tuple,\n",
    "                                              return_counts=True)))\n",
    "        payoffs_state = {**payoffs_state,\n",
    "                         'strategy_counts': strategy_counts}\n",
    "        profile_models = {**models,\n",
    "                          \"strategy_profile\": profile,\n",
    "                          \"payoffs_state\": payoffs_state,\n",
    "                          \"payoffs_key\": profile_payoffs_key}\n",
    "        profile_payoffs = thread_macro(profile_models,\n",
    "                                       build_payoffs,\n",
    "                                       (get, \"profile_payoffs\"),\n",
    "                                       )\n",
    "        payoffs[profile] = {}\n",
    "        for i, strategy in enumerate(profile_tuple):\n",
    "            if strategy == 0:\n",
    "                # A strategy of 0 is reserved for missing players, missing\n",
    "                # players do not have payoffs.\n",
    "                continue\n",
    "            elif str(strategy) in profile_payoffs.keys():\n",
    "                payoffs[profile][f\"P{i+1}\"] = profile_payoffs[f\"{strategy}\"]\n",
    "            else:\n",
    "                continue\n",
    "    return {**models, \"payoffs\": payoffs}\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic Payoffs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic payoffs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compute the payoffs of stochastic games with state-action transition\n",
    "matrix, $M$, and state-action utilities, $u$, and discount factor, $\\delta$,\n",
    "as follows:\n",
    "\n",
    "$v = (1 - \\delta) v^0 (I - \\delta M)^{-1}$ \\\n",
    "$payoffs = v \\cdot u$\n",
    "\n",
    "When $\\delta \\rightarrow 1$, we instead compute $v$ as the eigenvector of $M$\n",
    "with associated eigenvalue $1$.\n",
    "\n",
    "$M$ is the product of a transition matrix and a matrix containing the\n",
    "probabilities with which each action profile occurs (i.e. a matrix of player\n",
    "(mixed) strategies). $M$ has size $2mk + 1$, where $m$ is the number of states\n",
    "and $k$ is the number of strategies available to each player."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first need to define our flow payoffs, that is, at each state-action\n",
    "combination, what are the payoffs to each type of player."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export payoffs\n",
    "@method(build_payoffs, \"flow_payoffs_wrapper\")\n",
    "def build_payoffs(models):\n",
    "    \"Build the flow payoffs for each state-action in a stochastic game.\"\n",
    "    state_actions = models['state_actions']\n",
    "    payoffs_state = models.get('payoffs_state', {})\n",
    "    flow_payoffs = collections.defaultdict()\n",
    "    for state_action in state_actions:\n",
    "        state, action_profile = str.split(state_action, \":\")\n",
    "        action_tuple = string_to_tuple(action_profile)\n",
    "        action_counts = dict(zip(*np.unique(action_tuple,\n",
    "                                            return_counts=True)))\n",
    "        payoffs_state = {**payoffs_state,\n",
    "                         'strategy_counts': action_counts,\n",
    "                         'state': state}\n",
    "        payoffs_flow_key = models['payoffs_flow_key']\n",
    "        profile_models = {**models,\n",
    "                          \"payoffs_state\": payoffs_state,\n",
    "                          \"payoffs_key\": payoffs_flow_key}\n",
    "        flow_payoffs[state_action] = thread_macro(profile_models,\n",
    "                                                  build_payoffs,\n",
    "                                                  (get, \"flow_payoffs\"),\n",
    "                                                  )\n",
    "    return {**models, \"flow_payoffs\": flow_payoffs}\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#| hide\n",
    "\n",
    "Specify Q as a map of state-action keys to probabilities for each next state \\\n",
    "Specify P as a map of state-action keys to probabilities for each next action that each player could take.\n",
    "\n",
    "There can be memory issues with storing so many state_actions:\n",
    "- Total number of possible state_actions is equal to (n_states * n_choices^n_players)^2\n",
    "- If game is anonymous (so order does not matter), this reduces to (n_states * ncr(n_choices + n_players -1, n_choices-1))^2\n",
    "\n",
    "The second approach is much much smaller if n_choices is a lot larger than n_players. Unfortunately, we\n",
    "still need to add up the likelihood of each possible action profile, so computation may still \n",
    "be incredibly slow, even if the result still fits in memory.\n",
    "\n",
    "If we ever find ourselves needing to look at many players when trying to\n",
    "compute the transition probabilities for a stochastic game, use a monte carlo\n",
    "simulation instead to learn the transition probabilities and payoffs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export payoffs\n",
    "@multi\n",
    "def compute_transition(models):\n",
    "    \"Compute the transition likelihood for the given transition.\"\n",
    "    return models.get('compute_transition_key')\n",
    "\n",
    "@method(compute_transition, 'anonymous_actions')\n",
    "def compute_transition(models):\n",
    "    \"\"\"Compute transition likelihood when we are only passed anonymous action\n",
    "    profiles (i.e. order does not matter).\"\"\"\n",
    "    P, Q = [models[k] for k in ['P', 'Q']]\n",
    "    transition_start, transition_end = [models[k] for k in ['transition_start',\n",
    "                                                            'transition_end']]\n",
    "    next_state, action_profile = transition_end.split(\":\")\n",
    "    action_tuple = string_to_tuple(action_profile)\n",
    "    action_count = dict(zip(*np.unique(action_tuple, return_counts=True)))\n",
    "    profiles = create_profiles({**models,\n",
    "                                \"profiles_rule\": \"from_strategy_count\",\n",
    "                                \"strategy_count\": action_count})['profiles']\n",
    "    profile_tuples = map(string_to_tuple, profiles)\n",
    "    p = [np.prod([P[f\"P{player + 1}\"][transition_start].get(f\"A{action}\", 0)\n",
    "                  for player, action in enumerate(profile_tuple)])\n",
    "         for profile_tuple in profile_tuples]\n",
    "    return np.sum(p) * Q[transition_start][next_state]\n",
    "\n",
    "\n",
    "@method(compute_transition)\n",
    "def compute_transition(models):\n",
    "    \"Compute transition likelihood given the states and action profiles.\"\n",
    "    P, Q = [models[k] for k in ['P', 'Q']]\n",
    "    transition_start, transition_end = [models[k] for k in ['transition_start',\n",
    "                                                            'transition_end']]\n",
    "    next_state, action_profile = transition_end.split(\":\")\n",
    "    action_tuple = string_to_tuple(action_profile)\n",
    "    p = np.prod([P[f\"P{player + 1}\"][transition_start].get(f\"A{action}\", 0)\n",
    "                 for player, action in enumerate(action_tuple)])\n",
    "    return p * Q[transition_start][next_state]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export payoffs\n",
    "@method(build_payoffs, \"stochastic-no-discounting\")\n",
    "def build_payoffs(models: dict):\n",
    "    \"\"\"Compute the payoffs for a stochastic game with the given flow_payoffs,\n",
    "    state_transitions, strategies, and strategy_profile, when there is no\n",
    "    discounting.\"\"\"\n",
    "    u = models['flow_payoffs']\n",
    "    Q = models['state_transitions']\n",
    "    strategy_profile = models['strategy_profile'].split(\"-\")[::-1]\n",
    "    strategies = models['strategies']\n",
    "    P = {f\"P{player + 1}\": strategies[strategy_key]\n",
    "         for player, strategy_key in enumerate(strategy_profile)}\n",
    "    state_actions = list(Q.keys())\n",
    "    M = np.zeros((len(state_actions), len(state_actions)))\n",
    "    for row, transition_start in enumerate(state_actions):\n",
    "        for col, transition_end in enumerate(state_actions):\n",
    "            transition_data = {**models,\n",
    "                               \"P\": P,\n",
    "                               \"Q\": Q,\n",
    "                               \"transition_start\": transition_start,\n",
    "                               \"transition_end\": transition_end}\n",
    "            M[row, col] = compute_transition(transition_data)\n",
    "    v = thread_macro({**models, \"transition_matrix\": np.array([M])},\n",
    "                     find_ergodic_distribution,\n",
    "                     (get, \"ergodic\"))[0]\n",
    "    u = np.array([[u[s][f\"{i+1}\"] for i in range(len(u[s]))]\n",
    "                  for s in state_actions])\n",
    "    for _ in range(v.ndim, u.ndim):\n",
    "        v = v[:, None]\n",
    "    payoffs = np.sum(v * u, axis=0)\n",
    "    profile_payoffs = {f\"{i+1}\": pi for i, pi in enumerate(payoffs)}\n",
    "    return {**models, \"profile_payoffs\": profile_payoffs}\n",
    "\n",
    "\n",
    "@method(build_payoffs, \"stochastic-with-discounting\")\n",
    "def build_payoffs(models: dict):\n",
    "    \"\"\"Compute the payoffs for a stochastic game with the given flow_payoffs,\n",
    "    state_transitions, strategies, and strategy_profile.\"\"\"\n",
    "    u = models['flow_payoffs']\n",
    "    Q = models['state_transitions']\n",
    "    d = models['discount_rate']\n",
    "    v0 = models['initial_state_action_distribution']\n",
    "    strategy_profile = models['strategy_profile'].split(\"-\")[::-1]\n",
    "    strategies = models['strategies']\n",
    "    P = {f\"P{player + 1}\": strategies[strategy_key]\n",
    "         for player, strategy_key in enumerate(strategy_profile)}\n",
    "    state_actions = list(Q.keys())\n",
    "    M = np.zeros((len(state_actions), len(state_actions)))\n",
    "    for row, transition_start in enumerate(state_actions):\n",
    "        for col, transition_end in enumerate(state_actions):\n",
    "            transition_data = {**models,\n",
    "                               \"P\": P,\n",
    "                               \"Q\": Q,\n",
    "                               \"transition_start\": transition_start,\n",
    "                               \"transition_end\": transition_end}\n",
    "            M[row, col] = compute_transition(transition_data)\n",
    "    v = (1 - d) * v0 * np.linalg.inv(np.eye(M.shape) - d * M)\n",
    "    u = np.array([[u[s][f\"{i+1}\"] for i in range(len(u[s]))]\n",
    "                  for s in state_actions])\n",
    "    for _ in range(v.ndim, u.ndim):\n",
    "        v = v[:, None]\n",
    "    payoffs = np.sum(v * u, axis=0)\n",
    "    profile_payoffs = {f\"{i+1}\": pi for i, pi in enumerate(payoffs)}\n",
    "    return {**models, \"profile_payoffs\": profile_payoffs}\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tests for \"flow_payoffs_wrapper\" method of `build_payoffs`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example of flow payoffs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export payoffs\n",
    "@method(build_payoffs, 'vasconcelos_2014_flow')\n",
    "def build_payoffs(models: dict):\n",
    "    names = ['payoffs_state', 'c', 'T', 'b_r', 'b_p', 'r', 'g']\n",
    "    payoffs_state, c, T, b_r, b_p, r, g = [models[k] for k in names]\n",
    "    strategy_counts = payoffs_state['strategy_counts']\n",
    "    state = payoffs_state['state']\n",
    "    reward_bonus = g if state=='1' else 1\n",
    "    n_r = strategy_counts.get(\"2\", 0)\n",
    "    n_p = strategy_counts.get(\"4\", 0)\n",
    "    risk = r * (n_r * c * b_r + n_p * c * b_p < T)\n",
    "    payoffs = {\"1\": (1 - risk) * b_r * reward_bonus,  # rich_free_rider\n",
    "               \"2\": (1 - risk) * c * b_r * reward_bonus,  # rich_contributor\n",
    "               \"3\": (1 - risk) * b_p * reward_bonus,  # poor_free_rider\n",
    "               \"4\": (1 - risk) * c * b_p * reward_bonus}  # poor_contributor\n",
    "    return {**models, \"flow_payoffs\": payoffs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\"allowed_sectors\": {\"P1\": [\"S1\", \"S2\"],\n",
    "                              \"P2\": [\"S1\", \"S2\"]},\n",
    "          \"sector_strategies\": {\"S1\": [1, 2],\n",
    "                                \"S2\": [3, 4]},\n",
    "          \"profiles_rule\": \"allowed_sectors\",}\n",
    "action_profiles = create_profiles(models)[\"profiles\"]\n",
    "n_states = 2\n",
    "state_actions = []\n",
    "for profile in action_profiles:\n",
    "    for state in range(n_states):\n",
    "        state_actions.append(f\"{state}:{profile}\")\n",
    "\n",
    "models = {\"payoffs_flow_key\": \"vasconcelos_2014_flow\",\n",
    "          \"payoffs_key\": \"flow_payoffs_wrapper\",\n",
    "          \"state_actions\": state_actions,\n",
    "          'c': 0.5,\n",
    "          'T': 2,\n",
    "          'b_r': 4,\n",
    "          'b_p': 2,\n",
    "          'r': 0.8,\n",
    "          'g': 2,\n",
    "          }\n",
    "flow_payoffs = build_payoffs(models)['flow_payoffs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(None,\n",
       "            {'0:1-1': {'1': 0.7999999999999998,\n",
       "              '2': 0.3999999999999999,\n",
       "              '3': 0.3999999999999999,\n",
       "              '4': 0.19999999999999996},\n",
       "             '1:1-1': {'1': 1.5999999999999996,\n",
       "              '2': 0.7999999999999998,\n",
       "              '3': 0.7999999999999998,\n",
       "              '4': 0.3999999999999999},\n",
       "             '0:1-2': {'1': 0.7999999999999998,\n",
       "              '2': 0.3999999999999999,\n",
       "              '3': 0.3999999999999999,\n",
       "              '4': 0.19999999999999996},\n",
       "             '1:1-2': {'1': 1.5999999999999996,\n",
       "              '2': 0.7999999999999998,\n",
       "              '3': 0.7999999999999998,\n",
       "              '4': 0.3999999999999999},\n",
       "             '0:1-3': {'1': 0.7999999999999998,\n",
       "              '2': 0.3999999999999999,\n",
       "              '3': 0.3999999999999999,\n",
       "              '4': 0.19999999999999996},\n",
       "             '1:1-3': {'1': 1.5999999999999996,\n",
       "              '2': 0.7999999999999998,\n",
       "              '3': 0.7999999999999998,\n",
       "              '4': 0.3999999999999999},\n",
       "             '0:1-4': {'1': 0.7999999999999998,\n",
       "              '2': 0.3999999999999999,\n",
       "              '3': 0.3999999999999999,\n",
       "              '4': 0.19999999999999996},\n",
       "             '1:1-4': {'1': 1.5999999999999996,\n",
       "              '2': 0.7999999999999998,\n",
       "              '3': 0.7999999999999998,\n",
       "              '4': 0.3999999999999999},\n",
       "             '0:2-1': {'1': 0.7999999999999998,\n",
       "              '2': 0.3999999999999999,\n",
       "              '3': 0.3999999999999999,\n",
       "              '4': 0.19999999999999996},\n",
       "             '1:2-1': {'1': 1.5999999999999996,\n",
       "              '2': 0.7999999999999998,\n",
       "              '3': 0.7999999999999998,\n",
       "              '4': 0.3999999999999999},\n",
       "             '0:2-2': {'1': 0.7999999999999998,\n",
       "              '2': 0.3999999999999999,\n",
       "              '3': 0.3999999999999999,\n",
       "              '4': 0.19999999999999996},\n",
       "             '1:2-2': {'1': 1.5999999999999996,\n",
       "              '2': 0.7999999999999998,\n",
       "              '3': 0.7999999999999998,\n",
       "              '4': 0.3999999999999999},\n",
       "             '0:2-3': {'1': 0.7999999999999998,\n",
       "              '2': 0.3999999999999999,\n",
       "              '3': 0.3999999999999999,\n",
       "              '4': 0.19999999999999996},\n",
       "             '1:2-3': {'1': 1.5999999999999996,\n",
       "              '2': 0.7999999999999998,\n",
       "              '3': 0.7999999999999998,\n",
       "              '4': 0.3999999999999999},\n",
       "             '0:2-4': {'1': 0.7999999999999998,\n",
       "              '2': 0.3999999999999999,\n",
       "              '3': 0.3999999999999999,\n",
       "              '4': 0.19999999999999996},\n",
       "             '1:2-4': {'1': 1.5999999999999996,\n",
       "              '2': 0.7999999999999998,\n",
       "              '3': 0.7999999999999998,\n",
       "              '4': 0.3999999999999999},\n",
       "             '0:3-1': {'1': 0.7999999999999998,\n",
       "              '2': 0.3999999999999999,\n",
       "              '3': 0.3999999999999999,\n",
       "              '4': 0.19999999999999996},\n",
       "             '1:3-1': {'1': 1.5999999999999996,\n",
       "              '2': 0.7999999999999998,\n",
       "              '3': 0.7999999999999998,\n",
       "              '4': 0.3999999999999999},\n",
       "             '0:3-2': {'1': 0.7999999999999998,\n",
       "              '2': 0.3999999999999999,\n",
       "              '3': 0.3999999999999999,\n",
       "              '4': 0.19999999999999996},\n",
       "             '1:3-2': {'1': 1.5999999999999996,\n",
       "              '2': 0.7999999999999998,\n",
       "              '3': 0.7999999999999998,\n",
       "              '4': 0.3999999999999999},\n",
       "             '0:3-3': {'1': 0.7999999999999998,\n",
       "              '2': 0.3999999999999999,\n",
       "              '3': 0.3999999999999999,\n",
       "              '4': 0.19999999999999996},\n",
       "             '1:3-3': {'1': 1.5999999999999996,\n",
       "              '2': 0.7999999999999998,\n",
       "              '3': 0.7999999999999998,\n",
       "              '4': 0.3999999999999999},\n",
       "             '0:3-4': {'1': 0.7999999999999998,\n",
       "              '2': 0.3999999999999999,\n",
       "              '3': 0.3999999999999999,\n",
       "              '4': 0.19999999999999996},\n",
       "             '1:3-4': {'1': 1.5999999999999996,\n",
       "              '2': 0.7999999999999998,\n",
       "              '3': 0.7999999999999998,\n",
       "              '4': 0.3999999999999999},\n",
       "             '0:4-1': {'1': 0.7999999999999998,\n",
       "              '2': 0.3999999999999999,\n",
       "              '3': 0.3999999999999999,\n",
       "              '4': 0.19999999999999996},\n",
       "             '1:4-1': {'1': 1.5999999999999996,\n",
       "              '2': 0.7999999999999998,\n",
       "              '3': 0.7999999999999998,\n",
       "              '4': 0.3999999999999999},\n",
       "             '0:4-2': {'1': 0.7999999999999998,\n",
       "              '2': 0.3999999999999999,\n",
       "              '3': 0.3999999999999999,\n",
       "              '4': 0.19999999999999996},\n",
       "             '1:4-2': {'1': 1.5999999999999996,\n",
       "              '2': 0.7999999999999998,\n",
       "              '3': 0.7999999999999998,\n",
       "              '4': 0.3999999999999999},\n",
       "             '0:4-3': {'1': 0.7999999999999998,\n",
       "              '2': 0.3999999999999999,\n",
       "              '3': 0.3999999999999999,\n",
       "              '4': 0.19999999999999996},\n",
       "             '1:4-3': {'1': 1.5999999999999996,\n",
       "              '2': 0.7999999999999998,\n",
       "              '3': 0.7999999999999998,\n",
       "              '4': 0.3999999999999999},\n",
       "             '0:4-4': {'1': 0.7999999999999998,\n",
       "              '2': 0.3999999999999999,\n",
       "              '3': 0.3999999999999999,\n",
       "              '4': 0.19999999999999996},\n",
       "             '1:4-4': {'1': 1.5999999999999996,\n",
       "              '2': 0.7999999999999998,\n",
       "              '3': 0.7999999999999998,\n",
       "              '4': 0.3999999999999999}})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flow_payoffs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### State transition functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export payoffs\n",
    "@multi\n",
    "def state_transition(models):\n",
    "    \"Compute the likelihood of the given state_transition.\"\n",
    "    return models.get('state_transition_key')\n",
    "\n",
    "@method(state_transition, 'ex1')\n",
    "def state_transition(models):\n",
    "    \"\"\"Compute transition likelihood for a model with 2 states and an arbitrary\n",
    "    number of players. To stay in the good state, 0, all players need to choose\n",
    "    to cooperate, i.e. action 1.\"\"\"\n",
    "    state_action, next_state = [models[k] for k in ['state_action',\n",
    "                                                    'next_state']]\n",
    "    current_state, action_profile = state_action.split(\":\")\n",
    "    action_tuple = string_to_tuple(action_profile)\n",
    "    action_count = dict(zip(*np.unique(action_tuple, return_counts=True)))\n",
    "    n_players = len(action_tuple)\n",
    "    n_cooperators = action_count.get(1, 0) + action_count.get(3, 0)\n",
    "    if (current_state == '0'\n",
    "        and next_state == '1'\n",
    "        and n_cooperators != n_players):\n",
    "        transition_likelihood = 1\n",
    "    elif (current_state == '1'\n",
    "          and next_state == '0'\n",
    "          and n_cooperators == n_players):\n",
    "        transition_likelihood = 1\n",
    "    elif (current_state == '0'\n",
    "          and next_state == '0'\n",
    "          and n_cooperators == n_players):\n",
    "        transition_likelihood = 1\n",
    "    elif (current_state == '1'\n",
    "          and next_state == '1'\n",
    "          and n_cooperators != n_players):\n",
    "        transition_likelihood = 1\n",
    "    else:\n",
    "        transition_likelihood = 0\n",
    "    return transition_likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export payoffs\n",
    "def build_state_transitions(models):\n",
    "    state_actions = models['state_actions']\n",
    "    n_states = models['n_states']\n",
    "    state_transitions = {}\n",
    "    for state_action in state_actions:\n",
    "        state_transitions[state_action] = {}\n",
    "        for next_state in [f\"{i}\" for i in range(n_states)]:\n",
    "            likelihood = state_transition({**models,\n",
    "                                           \"state_action\": state_action,\n",
    "                                           \"next_state\": next_state})\n",
    "            state_transitions[state_action][next_state] = likelihood\n",
    "    return {**models, \"state_transitions\": state_transitions}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tests for `build_state_transitions`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\"allowed_sectors\": {\"P1\": [\"S1\", \"S2\"],\n",
    "                              \"P2\": [\"S1\", \"S2\"]},\n",
    "          \"sector_strategies\": {\"S1\": [1, 2],\n",
    "                                \"S2\": [3, 4]},\n",
    "          \"profiles_rule\": \"allowed_sectors\", }\n",
    "action_profiles = create_profiles(models)[\"profiles\"]\n",
    "n_states = 2\n",
    "state_actions = [f\"{state}:{a}\"\n",
    "                 for a in action_profiles\n",
    "                 for state in range(n_states)]\n",
    "models = {'n_states':n_states,\n",
    "          'state_actions': state_actions,\n",
    "          'state_transition_key': 'ex1'}\n",
    "result = build_state_transitions(models)['state_transitions']\n",
    "expected = {'0:1-1': {'0': 1, '1': 0},\n",
    " '1:1-1': {'0': 1, '1': 0},\n",
    " '0:1-2': {'0': 0, '1': 1},\n",
    " '1:1-2': {'0': 0, '1': 1},\n",
    " '0:1-3': {'0': 1, '1': 0},\n",
    " '1:1-3': {'0': 1, '1': 0},\n",
    " '0:1-4': {'0': 0, '1': 1},\n",
    " '1:1-4': {'0': 0, '1': 1},\n",
    " '0:2-1': {'0': 0, '1': 1},\n",
    " '1:2-1': {'0': 0, '1': 1},\n",
    " '0:2-2': {'0': 0, '1': 1},\n",
    " '1:2-2': {'0': 0, '1': 1},\n",
    " '0:2-3': {'0': 0, '1': 1},\n",
    " '1:2-3': {'0': 0, '1': 1},\n",
    " '0:2-4': {'0': 0, '1': 1},\n",
    " '1:2-4': {'0': 0, '1': 1},\n",
    " '0:3-1': {'0': 1, '1': 0},\n",
    " '1:3-1': {'0': 1, '1': 0},\n",
    " '0:3-2': {'0': 0, '1': 1},\n",
    " '1:3-2': {'0': 0, '1': 1},\n",
    " '0:3-3': {'0': 1, '1': 0},\n",
    " '1:3-3': {'0': 1, '1': 0},\n",
    " '0:3-4': {'0': 0, '1': 1},\n",
    " '1:3-4': {'0': 0, '1': 1},\n",
    " '0:4-1': {'0': 0, '1': 1},\n",
    " '1:4-1': {'0': 0, '1': 1},\n",
    " '0:4-2': {'0': 0, '1': 1},\n",
    " '1:4-2': {'0': 0, '1': 1},\n",
    " '0:4-3': {'0': 0, '1': 1},\n",
    " '1:4-3': {'0': 0, '1': 1},\n",
    " '0:4-4': {'0': 0, '1': 1},\n",
    " '1:4-4': {'0': 0, '1': 1}}\n",
    "fastcore.test.test_eq(result, expected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\"allowed_sectors\": {\"P1\": [\"S1\", \"S2\"],\n",
    "                              \"P2\": [\"S1\", \"S2\"]},\n",
    "          \"sector_strategies\": {\"S1\": [\"1\", \"2\"],\n",
    "                                \"S2\": [\"3\", \"4\"]},\n",
    "          \"profiles_rule\": \"anonymous\", }\n",
    "action_profiles = create_profiles(models)[\"profiles\"]\n",
    "n_states = 2\n",
    "state_actions = [f\"{state}:{a}\"\n",
    "                 for a in action_profiles\n",
    "                 for state in range(n_states)]\n",
    "models = {'n_states':n_states,\n",
    "          'state_actions': state_actions,\n",
    "          'state_transition_key': 'ex1'}\n",
    "result = build_state_transitions(models)['state_transitions']\n",
    "expected = {'0:4-4': {'0': 0, '1': 1},\n",
    " '1:4-4': {'0': 0, '1': 1},\n",
    " '0:4-3': {'0': 0, '1': 1},\n",
    " '1:4-3': {'0': 0, '1': 1},\n",
    " '0:3-3': {'0': 1, '1': 0},\n",
    " '1:3-3': {'0': 1, '1': 0},\n",
    " '0:4-2': {'0': 0, '1': 1},\n",
    " '1:4-2': {'0': 0, '1': 1},\n",
    " '0:3-2': {'0': 0, '1': 1},\n",
    " '1:3-2': {'0': 0, '1': 1},\n",
    " '0:2-2': {'0': 0, '1': 1},\n",
    " '1:2-2': {'0': 0, '1': 1},\n",
    " '0:4-1': {'0': 0, '1': 1},\n",
    " '1:4-1': {'0': 0, '1': 1},\n",
    " '0:3-1': {'0': 1, '1': 0},\n",
    " '1:3-1': {'0': 1, '1': 0},\n",
    " '0:2-1': {'0': 0, '1': 1},\n",
    " '1:2-1': {'0': 0, '1': 1},\n",
    " '0:1-1': {'0': 1, '1': 0},\n",
    " '1:1-1': {'0': 1, '1': 0}}\n",
    "fastcore.test.test_eq(result, expected)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Strategy construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export payoffs\n",
    "@multi\n",
    "def build_strategy(models):\n",
    "    \"Build the desired strategy\"\n",
    "    return models.get('strategy_key')\n",
    "\n",
    "@method(build_strategy, 'ex1_rich_cooperator')\n",
    "def build_strategy(models):\n",
    "    \"\"\"A rich player who cooperates with 95% probability if everyone currently\n",
    "    cooperates, otherwise defects with 95% probability.\"\"\"\n",
    "    state_action = models['state_action']\n",
    "    current_state, action_profile = state_action.split(\":\")\n",
    "    action_tuple = string_to_tuple(action_profile)\n",
    "    action_count = dict(zip(*np.unique(action_tuple, return_counts=True)))\n",
    "    n_players = len(action_tuple)\n",
    "    n_cooperators = action_count.get(1, 0) + action_count.get(3, 0)\n",
    "    if (current_state == '0'\n",
    "        and n_cooperators == n_players):\n",
    "        strategy = {\"A1\": 0.95, \"A2\": 0.05}\n",
    "    elif (current_state == '0'\n",
    "          and n_cooperators != n_players):\n",
    "        strategy = {\"A1\": 0.05, \"A2\": 0.95}\n",
    "    elif (current_state == '1'\n",
    "          and n_cooperators == n_players):\n",
    "        strategy = {\"A1\": 0.95, \"A2\": 0.05}\n",
    "    elif (current_state == '1'\n",
    "          and n_cooperators != n_players):\n",
    "        strategy = {\"A1\": 0.05, \"A2\": 0.95}\n",
    "    return strategy\n",
    "\n",
    "@method(build_strategy, 'ex1_rich_defector')\n",
    "def build_strategy(models):\n",
    "    \"\"\"A rich player who defects with 95% probability no matter what others\n",
    "    do, nor what state they are in.\"\"\"\n",
    "    state_action = models['state_action']\n",
    "    current_state, action_profile = state_action.split(\":\")\n",
    "    action_tuple = string_to_tuple(action_profile)\n",
    "    action_count = dict(zip(*np.unique(action_tuple, return_counts=True)))\n",
    "    n_players = len(action_tuple)\n",
    "    n_cooperators = action_count.get(1, 0) + action_count.get(3, 0)\n",
    "    if (current_state == '0'\n",
    "        and n_cooperators == n_players):\n",
    "        strategy = {\"A1\": 0.05, \"A2\": 0.95}\n",
    "    elif (current_state == '0'\n",
    "          and n_cooperators != n_players):\n",
    "        strategy = {\"A1\": 0.05, \"A2\": 0.95}\n",
    "    elif (current_state == '1'\n",
    "          and n_cooperators == n_players):\n",
    "        strategy = {\"A1\": 0.05, \"A2\": 0.95}\n",
    "    elif (current_state == '1'\n",
    "          and n_cooperators != n_players):\n",
    "        strategy = {\"A1\": 0.05, \"A2\": 0.95}\n",
    "    return strategy\n",
    "\n",
    "@method(build_strategy, 'ex1_poor_cooperator')\n",
    "def build_strategy(models):\n",
    "    \"\"\"A poor player who cooperates with 95% probability if everyone currently\n",
    "    cooperates, otherwise defects with 95% probability.\"\"\"\n",
    "    state_action = models['state_action']\n",
    "    current_state, action_profile = state_action.split(\":\")\n",
    "    action_tuple = string_to_tuple(action_profile)\n",
    "    action_count = dict(zip(*np.unique(action_tuple, return_counts=True)))\n",
    "    n_players = len(action_tuple)\n",
    "    n_cooperators = action_count.get(1, 0) + action_count.get(3, 0)\n",
    "    if (current_state == '0'\n",
    "        and n_cooperators == n_players):\n",
    "        strategy = {\"A3\": 0.95, \"A4\": 0.05}\n",
    "    elif (current_state == '0'\n",
    "          and n_cooperators != n_players):\n",
    "        strategy = {\"A3\": 0.05, \"A4\": 0.95}\n",
    "    elif (current_state == '1'\n",
    "          and n_cooperators == n_players):\n",
    "        strategy = {\"A3\": 0.95, \"A4\": 0.05}\n",
    "    elif (current_state == '1'\n",
    "          and n_cooperators != n_players):\n",
    "        strategy = {\"A3\": 0.05, \"A4\": 0.95}\n",
    "    return strategy\n",
    "\n",
    "@method(build_strategy, 'ex1_poor_defector')\n",
    "def build_strategy(models):\n",
    "    \"\"\"A poor player who defects with 95% probability no matter what others\n",
    "    do, nor what state they are in.\"\"\"\n",
    "    state_action = models['state_action']\n",
    "    current_state, action_profile = state_action.split(\":\")\n",
    "    action_tuple = string_to_tuple(action_profile)\n",
    "    action_count = dict(zip(*np.unique(action_tuple, return_counts=True)))\n",
    "    n_players = len(action_tuple)\n",
    "    n_cooperators = action_count.get(1, 0) + action_count.get(3, 0)\n",
    "    if (current_state == '0'\n",
    "        and n_cooperators == n_players):\n",
    "        strategy = {\"A3\": 0.05, \"A4\": 0.95}\n",
    "    elif (current_state == '0'\n",
    "          and n_cooperators != n_players):\n",
    "        strategy = {\"A3\": 0.05, \"A4\": 0.95}\n",
    "    elif (current_state == '1'\n",
    "          and n_cooperators == n_players):\n",
    "        strategy = {\"A3\": 0.05, \"A4\": 0.95}\n",
    "    elif (current_state == '1'\n",
    "          and n_cooperators != n_players):\n",
    "        strategy = {\"A3\": 0.05, \"A4\": 0.95}\n",
    "    return strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export payoffs\n",
    "def build_strategies(models):\n",
    "    \"Build a dictionary containing the specified strategies in `models`\"\n",
    "    state_actions, strategy_keys = [models[k] for k in [\"state_actions\",\n",
    "                                                        \"strategy_keys\"]]\n",
    "    strategies = {f\"{i+1}\": {s: build_strategy({\"strategy_key\": strategy_key,\n",
    "                                            \"state_action\": s})\n",
    "                         for s in state_actions}\n",
    "              for i, strategy_key in enumerate(strategy_keys)}\n",
    "    return {**models, \"strategies\": strategies}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tests for `build_strategy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\"allowed_sectors\": {\"P1\": [\"S1\", \"S2\"],\n",
    "                              \"P2\": [\"S1\", \"S2\"]},\n",
    "          \"sector_strategies\": {\"S1\": [\"1\", \"2\"],\n",
    "                                \"S2\": [\"3\", \"4\"]},\n",
    "          \"profiles_rule\": \"anonymous\", }\n",
    "action_profiles = create_profiles(models)[\"profiles\"]\n",
    "n_states = 2\n",
    "state_actions = [f\"{state}:{a}\"\n",
    "                 for a in action_profiles\n",
    "                 for state in range(n_states)]\n",
    "strategy_keys = [\"ex1_rich_cooperator\",\n",
    "                 \"ex1_rich_defector\",\n",
    "                 \"ex1_poor_cooperator\",\n",
    "                 \"ex1_poor_defector\",]\n",
    "strategies = {f\"{i+1}\": {s: build_strategy({\"strategy_key\": strategy_key,\n",
    "                                            \"state_action\": s})\n",
    "                         for s in state_actions}\n",
    "              for i, strategy_key in enumerate(strategy_keys)}\n",
    "expected = {'1': {'0:4-4': {'A1': 0.05, 'A2': 0.95},\n",
    "  '1:4-4': {'A1': 0.05, 'A2': 0.95},\n",
    "  '0:4-3': {'A1': 0.05, 'A2': 0.95},\n",
    "  '1:4-3': {'A1': 0.05, 'A2': 0.95},\n",
    "  '0:3-3': {'A1': 0.95, 'A2': 0.05},\n",
    "  '1:3-3': {'A1': 0.95, 'A2': 0.05},\n",
    "  '0:4-2': {'A1': 0.05, 'A2': 0.95},\n",
    "  '1:4-2': {'A1': 0.05, 'A2': 0.95},\n",
    "  '0:3-2': {'A1': 0.05, 'A2': 0.95},\n",
    "  '1:3-2': {'A1': 0.05, 'A2': 0.95},\n",
    "  '0:2-2': {'A1': 0.05, 'A2': 0.95},\n",
    "  '1:2-2': {'A1': 0.05, 'A2': 0.95},\n",
    "  '0:4-1': {'A1': 0.05, 'A2': 0.95},\n",
    "  '1:4-1': {'A1': 0.05, 'A2': 0.95},\n",
    "  '0:3-1': {'A1': 0.95, 'A2': 0.05},\n",
    "  '1:3-1': {'A1': 0.95, 'A2': 0.05},\n",
    "  '0:2-1': {'A1': 0.05, 'A2': 0.95},\n",
    "  '1:2-1': {'A1': 0.05, 'A2': 0.95},\n",
    "  '0:1-1': {'A1': 0.95, 'A2': 0.05},\n",
    "  '1:1-1': {'A1': 0.95, 'A2': 0.05}},\n",
    " '2': {'0:4-4': {'A1': 0.05, 'A2': 0.95},\n",
    "  '1:4-4': {'A1': 0.05, 'A2': 0.95},\n",
    "  '0:4-3': {'A1': 0.05, 'A2': 0.95},\n",
    "  '1:4-3': {'A1': 0.05, 'A2': 0.95},\n",
    "  '0:3-3': {'A1': 0.05, 'A2': 0.95},\n",
    "  '1:3-3': {'A1': 0.05, 'A2': 0.95},\n",
    "  '0:4-2': {'A1': 0.05, 'A2': 0.95},\n",
    "  '1:4-2': {'A1': 0.05, 'A2': 0.95},\n",
    "  '0:3-2': {'A1': 0.05, 'A2': 0.95},\n",
    "  '1:3-2': {'A1': 0.05, 'A2': 0.95},\n",
    "  '0:2-2': {'A1': 0.05, 'A2': 0.95},\n",
    "  '1:2-2': {'A1': 0.05, 'A2': 0.95},\n",
    "  '0:4-1': {'A1': 0.05, 'A2': 0.95},\n",
    "  '1:4-1': {'A1': 0.05, 'A2': 0.95},\n",
    "  '0:3-1': {'A1': 0.05, 'A2': 0.95},\n",
    "  '1:3-1': {'A1': 0.05, 'A2': 0.95},\n",
    "  '0:2-1': {'A1': 0.05, 'A2': 0.95},\n",
    "  '1:2-1': {'A1': 0.05, 'A2': 0.95},\n",
    "  '0:1-1': {'A1': 0.05, 'A2': 0.95},\n",
    "  '1:1-1': {'A1': 0.05, 'A2': 0.95}},\n",
    " '3': {'0:4-4': {'A3': 0.05, 'A4': 0.95},\n",
    "  '1:4-4': {'A3': 0.05, 'A4': 0.95},\n",
    "  '0:4-3': {'A3': 0.05, 'A4': 0.95},\n",
    "  '1:4-3': {'A3': 0.05, 'A4': 0.95},\n",
    "  '0:3-3': {'A3': 0.95, 'A4': 0.05},\n",
    "  '1:3-3': {'A3': 0.95, 'A4': 0.05},\n",
    "  '0:4-2': {'A3': 0.05, 'A4': 0.95},\n",
    "  '1:4-2': {'A3': 0.05, 'A4': 0.95},\n",
    "  '0:3-2': {'A3': 0.05, 'A4': 0.95},\n",
    "  '1:3-2': {'A3': 0.05, 'A4': 0.95},\n",
    "  '0:2-2': {'A3': 0.05, 'A4': 0.95},\n",
    "  '1:2-2': {'A3': 0.05, 'A4': 0.95},\n",
    "  '0:4-1': {'A3': 0.05, 'A4': 0.95},\n",
    "  '1:4-1': {'A3': 0.05, 'A4': 0.95},\n",
    "  '0:3-1': {'A3': 0.95, 'A4': 0.05},\n",
    "  '1:3-1': {'A3': 0.95, 'A4': 0.05},\n",
    "  '0:2-1': {'A3': 0.05, 'A4': 0.95},\n",
    "  '1:2-1': {'A3': 0.05, 'A4': 0.95},\n",
    "  '0:1-1': {'A3': 0.95, 'A4': 0.05},\n",
    "  '1:1-1': {'A3': 0.95, 'A4': 0.05}},\n",
    " '4': {'0:4-4': {'A3': 0.05, 'A4': 0.95},\n",
    "  '1:4-4': {'A3': 0.05, 'A4': 0.95},\n",
    "  '0:4-3': {'A3': 0.05, 'A4': 0.95},\n",
    "  '1:4-3': {'A3': 0.05, 'A4': 0.95},\n",
    "  '0:3-3': {'A3': 0.05, 'A4': 0.95},\n",
    "  '1:3-3': {'A3': 0.05, 'A4': 0.95},\n",
    "  '0:4-2': {'A3': 0.05, 'A4': 0.95},\n",
    "  '1:4-2': {'A3': 0.05, 'A4': 0.95},\n",
    "  '0:3-2': {'A3': 0.05, 'A4': 0.95},\n",
    "  '1:3-2': {'A3': 0.05, 'A4': 0.95},\n",
    "  '0:2-2': {'A3': 0.05, 'A4': 0.95},\n",
    "  '1:2-2': {'A3': 0.05, 'A4': 0.95},\n",
    "  '0:4-1': {'A3': 0.05, 'A4': 0.95},\n",
    "  '1:4-1': {'A3': 0.05, 'A4': 0.95},\n",
    "  '0:3-1': {'A3': 0.05, 'A4': 0.95},\n",
    "  '1:3-1': {'A3': 0.05, 'A4': 0.95},\n",
    "  '0:2-1': {'A3': 0.05, 'A4': 0.95},\n",
    "  '1:2-1': {'A3': 0.05, 'A4': 0.95},\n",
    "  '0:1-1': {'A3': 0.05, 'A4': 0.95},\n",
    "  '1:1-1': {'A3': 0.05, 'A4': 0.95}}}\n",
    "fastcore.test.test_eq(strategies, expected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\"allowed_sectors\": {\"P1\": [\"S1\", \"S2\"],\n",
    "                              \"P2\": [\"S1\", \"S2\"]},\n",
    "          \"sector_strategies\": {\"S1\": [\"1\", \"2\"],\n",
    "                                \"S2\": [\"3\", \"4\"]},\n",
    "          \"profiles_rule\": \"anonymous\", }\n",
    "action_profiles = create_profiles(models)[\"profiles\"]\n",
    "n_states = 2\n",
    "state_actions = [f\"{state}:{a}\"\n",
    "                 for a in action_profiles\n",
    "                 for state in range(n_states)]\n",
    "strategy_keys = [\"ex1_rich_cooperator\",\n",
    "                 \"ex1_rich_defector\",\n",
    "                 \"ex1_poor_cooperator\",\n",
    "                 \"ex1_poor_defector\",]\n",
    "models = {**models,\n",
    "          \"strategy_keys\": strategy_keys,\n",
    "          \"state_actions\": state_actions}\n",
    "strategies = build_strategies(models)['strategies']\n",
    "expected = {'1': {'0:4-4': {'A1': 0.05, 'A2': 0.95},\n",
    "  '1:4-4': {'A1': 0.05, 'A2': 0.95},\n",
    "  '0:4-3': {'A1': 0.05, 'A2': 0.95},\n",
    "  '1:4-3': {'A1': 0.05, 'A2': 0.95},\n",
    "  '0:3-3': {'A1': 0.95, 'A2': 0.05},\n",
    "  '1:3-3': {'A1': 0.95, 'A2': 0.05},\n",
    "  '0:4-2': {'A1': 0.05, 'A2': 0.95},\n",
    "  '1:4-2': {'A1': 0.05, 'A2': 0.95},\n",
    "  '0:3-2': {'A1': 0.05, 'A2': 0.95},\n",
    "  '1:3-2': {'A1': 0.05, 'A2': 0.95},\n",
    "  '0:2-2': {'A1': 0.05, 'A2': 0.95},\n",
    "  '1:2-2': {'A1': 0.05, 'A2': 0.95},\n",
    "  '0:4-1': {'A1': 0.05, 'A2': 0.95},\n",
    "  '1:4-1': {'A1': 0.05, 'A2': 0.95},\n",
    "  '0:3-1': {'A1': 0.95, 'A2': 0.05},\n",
    "  '1:3-1': {'A1': 0.95, 'A2': 0.05},\n",
    "  '0:2-1': {'A1': 0.05, 'A2': 0.95},\n",
    "  '1:2-1': {'A1': 0.05, 'A2': 0.95},\n",
    "  '0:1-1': {'A1': 0.95, 'A2': 0.05},\n",
    "  '1:1-1': {'A1': 0.95, 'A2': 0.05}},\n",
    " '2': {'0:4-4': {'A1': 0.05, 'A2': 0.95},\n",
    "  '1:4-4': {'A1': 0.05, 'A2': 0.95},\n",
    "  '0:4-3': {'A1': 0.05, 'A2': 0.95},\n",
    "  '1:4-3': {'A1': 0.05, 'A2': 0.95},\n",
    "  '0:3-3': {'A1': 0.05, 'A2': 0.95},\n",
    "  '1:3-3': {'A1': 0.05, 'A2': 0.95},\n",
    "  '0:4-2': {'A1': 0.05, 'A2': 0.95},\n",
    "  '1:4-2': {'A1': 0.05, 'A2': 0.95},\n",
    "  '0:3-2': {'A1': 0.05, 'A2': 0.95},\n",
    "  '1:3-2': {'A1': 0.05, 'A2': 0.95},\n",
    "  '0:2-2': {'A1': 0.05, 'A2': 0.95},\n",
    "  '1:2-2': {'A1': 0.05, 'A2': 0.95},\n",
    "  '0:4-1': {'A1': 0.05, 'A2': 0.95},\n",
    "  '1:4-1': {'A1': 0.05, 'A2': 0.95},\n",
    "  '0:3-1': {'A1': 0.05, 'A2': 0.95},\n",
    "  '1:3-1': {'A1': 0.05, 'A2': 0.95},\n",
    "  '0:2-1': {'A1': 0.05, 'A2': 0.95},\n",
    "  '1:2-1': {'A1': 0.05, 'A2': 0.95},\n",
    "  '0:1-1': {'A1': 0.05, 'A2': 0.95},\n",
    "  '1:1-1': {'A1': 0.05, 'A2': 0.95}},\n",
    " '3': {'0:4-4': {'A3': 0.05, 'A4': 0.95},\n",
    "  '1:4-4': {'A3': 0.05, 'A4': 0.95},\n",
    "  '0:4-3': {'A3': 0.05, 'A4': 0.95},\n",
    "  '1:4-3': {'A3': 0.05, 'A4': 0.95},\n",
    "  '0:3-3': {'A3': 0.95, 'A4': 0.05},\n",
    "  '1:3-3': {'A3': 0.95, 'A4': 0.05},\n",
    "  '0:4-2': {'A3': 0.05, 'A4': 0.95},\n",
    "  '1:4-2': {'A3': 0.05, 'A4': 0.95},\n",
    "  '0:3-2': {'A3': 0.05, 'A4': 0.95},\n",
    "  '1:3-2': {'A3': 0.05, 'A4': 0.95},\n",
    "  '0:2-2': {'A3': 0.05, 'A4': 0.95},\n",
    "  '1:2-2': {'A3': 0.05, 'A4': 0.95},\n",
    "  '0:4-1': {'A3': 0.05, 'A4': 0.95},\n",
    "  '1:4-1': {'A3': 0.05, 'A4': 0.95},\n",
    "  '0:3-1': {'A3': 0.95, 'A4': 0.05},\n",
    "  '1:3-1': {'A3': 0.95, 'A4': 0.05},\n",
    "  '0:2-1': {'A3': 0.05, 'A4': 0.95},\n",
    "  '1:2-1': {'A3': 0.05, 'A4': 0.95},\n",
    "  '0:1-1': {'A3': 0.95, 'A4': 0.05},\n",
    "  '1:1-1': {'A3': 0.95, 'A4': 0.05}},\n",
    " '4': {'0:4-4': {'A3': 0.05, 'A4': 0.95},\n",
    "  '1:4-4': {'A3': 0.05, 'A4': 0.95},\n",
    "  '0:4-3': {'A3': 0.05, 'A4': 0.95},\n",
    "  '1:4-3': {'A3': 0.05, 'A4': 0.95},\n",
    "  '0:3-3': {'A3': 0.05, 'A4': 0.95},\n",
    "  '1:3-3': {'A3': 0.05, 'A4': 0.95},\n",
    "  '0:4-2': {'A3': 0.05, 'A4': 0.95},\n",
    "  '1:4-2': {'A3': 0.05, 'A4': 0.95},\n",
    "  '0:3-2': {'A3': 0.05, 'A4': 0.95},\n",
    "  '1:3-2': {'A3': 0.05, 'A4': 0.95},\n",
    "  '0:2-2': {'A3': 0.05, 'A4': 0.95},\n",
    "  '1:2-2': {'A3': 0.05, 'A4': 0.95},\n",
    "  '0:4-1': {'A3': 0.05, 'A4': 0.95},\n",
    "  '1:4-1': {'A3': 0.05, 'A4': 0.95},\n",
    "  '0:3-1': {'A3': 0.05, 'A4': 0.95},\n",
    "  '1:3-1': {'A3': 0.05, 'A4': 0.95},\n",
    "  '0:2-1': {'A3': 0.05, 'A4': 0.95},\n",
    "  '1:2-1': {'A3': 0.05, 'A4': 0.95},\n",
    "  '0:1-1': {'A3': 0.05, 'A4': 0.95},\n",
    "  '1:1-1': {'A3': 0.05, 'A4': 0.95}}}\n",
    "fastcore.test.test_eq(strategies, expected)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stochastic payoffs test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\"allowed_sectors\": {\"P1\": [\"S1\", \"S2\"],\n",
    "                              \"P2\": [\"S1\", \"S2\"]},\n",
    "          \"sector_strategies\": {\"S1\": [\"1\", \"2\"],\n",
    "                                \"S2\": [\"3\", \"4\"]},\n",
    "          \"profiles_rule\": \"anonymous\", }\n",
    "action_profiles = create_profiles(models)[\"profiles\"]\n",
    "n_states = 2\n",
    "state_actions = [f\"{state}:{a}\"\n",
    "                 for a in action_profiles\n",
    "                 for state in range(n_states)]\n",
    "\n",
    "strategy_keys = [\"ex1_rich_cooperator\",\n",
    "                 \"ex1_rich_defector\",\n",
    "                 \"ex1_poor_cooperator\",\n",
    "                 \"ex1_poor_defector\",]\n",
    "models = {**models,\n",
    "          \"strategy_keys\": strategy_keys,\n",
    "          \"state_actions\": state_actions}\n",
    "strategies = build_strategies(models)['strategies']\n",
    "strategy_profile = \"1-2-3\"\n",
    "models = {\"payoffs_flow_key\": \"vasconcelos_2014_flow\",\n",
    "          \"payoffs_key\": \"flow_payoffs_wrapper\",\n",
    "          \"state_actions\": state_actions,\n",
    "          \"strategies\": strategies,\n",
    "          \"strategy_profile\": strategy_profile,\n",
    "          'n_states':n_states,\n",
    "          'state_transition_key': 'ex1',\n",
    "          'compute_transition_key': \"anonymous_actions\",\n",
    "          'c': 0.5,\n",
    "          'T': 2,\n",
    "          'b_r': 4,\n",
    "          'b_p': 2,\n",
    "          'r': 0.8,\n",
    "          'g': 2,\n",
    "          }\n",
    "\n",
    "models = build_state_transitions(models)\n",
    "models = build_payoffs(models)\n",
    "models = {**models,\n",
    "          \"payoffs_key\": \"stochastic-no-discounting\"}\n",
    "results = build_payoffs(models)\n",
    "expected = {'1': 1.5979057591623032,\n",
    " '2': 0.7989528795811516,\n",
    " '3': 0.7989528795811516,\n",
    " '4': 0.3994764397905758}\n",
    "for k, v in results['profile_payoffs'].items():\n",
    "    fastcore.test.test_close(v, expected[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/d/Paolo-Work/git/gh-pages-example/gh_pages_example/methods.py:260: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  ergodic = np.array(V.transpose(0, 2, 1)[y], dtype=float)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'4-4': {'P1': 0.39949999999999986, 'P2': 0.39949999999999986},\n",
       " '4-3': {'P1': 0.7989528795811517, 'P2': 0.39947643979057584},\n",
       " '3-3': {'P1': 0.7899999999999998, 'P2': 0.7899999999999998},\n",
       " '4-2': {'P1': 0.7989999999999997, 'P2': 0.39949999999999986},\n",
       " '3-2': {'P1': 0.7989528795811518, 'P2': 0.7989528795811518},\n",
       " '2-2': {'P1': 0.7989999999999997, 'P2': 0.7989999999999997},\n",
       " '4-1': {'P1': 1.5979057591623036, 'P2': 0.3994764397905759},\n",
       " '3-1': {'P1': 1.5799999999999994, 'P2': 0.7899999999999997},\n",
       " '2-1': {'P1': 1.5979057591623034, 'P2': 0.7989528795811517},\n",
       " '1-1': {'P1': 1.5799999999999994, 'P2': 1.5799999999999994}}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = {\"allowed_sectors\": {\"P1\": [\"S1\", \"S2\"],\n",
    "                              \"P2\": [\"S1\", \"S2\"]},\n",
    "          \"sector_strategies\": {\"S1\": [\"1\", \"2\"],\n",
    "                                \"S2\": [\"3\", \"4\"]},\n",
    "          \"profiles_rule\": \"anonymous\", }\n",
    "action_profiles = create_profiles(models)[\"profiles\"]\n",
    "n_states = 2\n",
    "state_actions = [f\"{state}:{a}\"\n",
    "                 for a in action_profiles\n",
    "                 for state in range(n_states)]\n",
    "\n",
    "strategy_keys = [\"ex1_rich_cooperator\",\n",
    "                 \"ex1_rich_defector\",\n",
    "                 \"ex1_poor_cooperator\",\n",
    "                 \"ex1_poor_defector\",]\n",
    "models = {**models,\n",
    "          \"strategy_keys\": strategy_keys,\n",
    "          \"state_actions\": state_actions}\n",
    "strategies = build_strategies(models)['strategies']\n",
    "strategy_profile = \"1-2-3\"\n",
    "models = {**models,\n",
    "          \"payoffs_flow_key\": \"vasconcelos_2014_flow\",\n",
    "          \"payoffs_key\": \"flow_payoffs_wrapper\",\n",
    "          \"state_actions\": state_actions,\n",
    "          \"strategies\": strategies,\n",
    "          \"strategy_profile\": strategy_profile,\n",
    "          'n_states':n_states,\n",
    "          'state_transition_key': 'ex1',\n",
    "          'compute_transition_key': \"anonymous_actions\",\n",
    "          'c': 0.5,\n",
    "          'T': 2,\n",
    "          'b_r': 4,\n",
    "          'b_p': 2,\n",
    "          'r': 0.8,\n",
    "          'g': 2,\n",
    "          }\n",
    "models = build_state_transitions(models)\n",
    "models = build_payoffs(models)\n",
    "models = {**models,\n",
    "          \"payoffs_key\": \"payoff_function_wrapper\",\n",
    "          \"profile_payoffs_key\": \"stochastic-no-discounting\"}\n",
    "results = build_payoffs(models)\n",
    "results['payoffs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "import nbdev\n",
    "nbdev.nbdev_export()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "5844494aa8caf4c1a0a05d85746d5381f91a25fadc32ae63a73a248c881db361"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
