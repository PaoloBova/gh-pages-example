{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3275141f-78f8-43c7-8a4f-7517dee6f284",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b6efd0-6adb-4de2-8383-2bdc5af68496",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#| export\n",
    "from nbdev.showdoc import *\n",
    "import fastcore.test\n",
    "from gh_pages_example.utils import *\n",
    "from gh_pages_example.types import *\n",
    "import typing\n",
    "\n",
    "import numpy as np\n",
    "import nptyping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c675457e-78d3-4dcc-8b4d-9dc966a3ec97",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c06847-fe93-4fc5-9b91-30f92cc69f3c",
   "metadata": {},
   "source": [
    "# Methods in Evolutionary Game Theory\n",
    "\n",
    "> A set of methods for solving Evolutionary Games (see Nowak 2006 and the references section)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66e4126-c29d-41e8-bce9-54dcabbc63ba",
   "metadata": {},
   "source": [
    "## Evolutionary Dynamics in Finite Populations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8f91a3-f1d3-4ad5-a574-3ab583f1edf5",
   "metadata": {},
   "source": [
    "We examine a finite population of players using different strategies who engage in social learning.\n",
    "\n",
    "In the limit of small mutations, most of the time everyone plays the same strategy. States in which everyone plays the same strategy are known as **monomorphic states**. Occassionally, mutant strategies can fixate in the population, resulting in everyone adopting the same new strategy. We can use Markov Chains to analyse the relative frequencies with which each strategy is played by the population.\n",
    "\n",
    "The steps for computing the ergodic (i.e. long-run, stationary) strategy distribution is as follows:\n",
    "\n",
    "1. Build a transition matrix between all monomorphic states\n",
    "2. Find the ergodic distribution for the markov chain defined using this transition matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb44b7a3-d2ca-4492-b844-5bb9eec99c5c",
   "metadata": {},
   "source": [
    "### Fermi social learning\n",
    "\n",
    "> A Fermi social learning rule means that individuals make pairwise comparisons between their own strategy and and another strategy in the population that they may choose to copy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cab4078-47e3-4468-af4a-742219f3b2c5",
   "metadata": {},
   "source": [
    "#### Derivation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5245cb-1d83-4bbe-8683-96cf42af71a3",
   "metadata": {},
   "source": [
    "Each period of the evolutionary game involves individuals being randomly selected to play against one another individual.\n",
    "\n",
    "Letting $Z$ denote the size of the population, and $π$ denote the game's payoff matrix, we can compute the fitness of a strategy, $B$ for example, when $k$ individuals are of type $B$ as follows:\n",
    "\n",
    "\\begin{equation}\n",
    "ΠB_k = πBA \\frac{k-1}{Z - 1} + πBB \\frac{Z-k}{Z- 1}\n",
    "\\end{equation}\n",
    "\n",
    "where $πBA$ and $πBB$ are the payoffs for playing $B$ against type $A$ or $B$ respectively.\n",
    "\n",
    "The **Fermi social learning rule** adopts strategy $B$ selected from the population over their current strategy $A$ with probability given by:\n",
    "\n",
    "\\begin{equation}\n",
    "Pr(adopt \\, B | k) = \\frac{1}{(1 + \\exp^{-\\beta (ΠB_k - ΠA_k)})}\n",
    "\\end{equation}\n",
    "\n",
    "where $ΠB_k - ΠA_k$ is the relative fitness of strategy $B$ over $A$ in a population with $k$ individuals of type $B$, the rest of type $A$. Notice how the larger the relative fitness, the closer the denominator, and therefore the probability, is to $1$.\n",
    "\n",
    "Using the Fermi social learning rule above, we can write the probability of increasing the number of type $B$ individuals as\n",
    "\n",
    "\\begin{equation}\n",
    "T^+_B(k) = \\frac{Z-k}{Z} \\frac{k}{Z} Pr(adopt \\, B | k) \n",
    "\\end{equation}\n",
    "Z\n",
    "as an individual of type $A$ needs to randomly be chosen to compare their strategy against someone of type $B$.\n",
    "\n",
    "and the probability of decreasing the number of type $B$ individuals as\n",
    "\n",
    "\\begin{equation}\n",
    "T^-_B(k) = \\frac{k}{Z} \\frac{Z-k}{Z} Pr(adopt \\, A | k) \n",
    "\\end{equation}\n",
    "\n",
    "as an individual of type $B$ needs to randomly be chosen to compare their strategy against someone of type $A$.\n",
    "\n",
    "We will often employ their ratio, which is: \n",
    "\n",
    "\\begin{equation}\n",
    "\\frac{T^-_B(k)}{T^+_B(k)} = \\frac{Pr(adopt \\, A | k) }{Pr(adopt \\, B | k)} = \\frac{1 + \\exp^{-\\beta (ΠB_k - ΠA_k)}}{1 + \\exp^{-\\beta (ΠA_k - ΠB_k)}}\n",
    "\\end{equation}\n",
    "\n",
    "Notice that $\\frac{1 + \\exp^x}{1 + \\exp^{-x}} = \\exp^{x}$\n",
    "\n",
    "So, this ratio simplifies to $\\frac{T^-_B(k)}{T^+_B(k)} =  \\exp^{-\\beta (ΠB_k - ΠA_k)}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86898d7e-42d1-4ef9-af35-0859f8097c22",
   "metadata": {},
   "source": [
    "#### Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bea9cbf-f84a-4131-893c-47099a4487a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def fermi_learning(fitnessA:nptyping.NDArray, # fitness of strategy A\n",
    "                   fitnessB:nptyping.NDArray, # fitness of strategy B\n",
    "                   β:nptyping.NDArray, # learning rate\n",
    "                  ) -> nptyping.NDArray:\n",
    "    \"\"\"Compute the likelihood that a player with strategy A adopts strategy B using the fermi function.\"\"\"\n",
    "    return (1 + np.exp(-β*(fitnessB - fitnessA)))**(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb62f2bd-4534-4464-9147-de20bf2dc42b",
   "metadata": {},
   "source": [
    "#### Examples and Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fca8e00-f849-490b-b29d-54119b064a2e",
   "metadata": {},
   "source": [
    "When each strategy has the same fitness, then the likelihood that a player adopts strategy $B$ is 50%, no matter the value of $\\beta$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678244e2-9597-4d85-96ae-a69211d64539",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = fermi_learning(np.array([5]),\n",
    "                   np.array([5]),\n",
    "                   np.array([1]),)\n",
    "nptyping.assert_isinstance(x, nptyping.NDArray[nptyping.Shape[\"1\"], typing.Any])\n",
    "fastcore.test.test_eq(x, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e881f80e-272a-4727-9a46-881e5b51e38f",
   "metadata": {},
   "source": [
    "### Fixation rate\n",
    "\n",
    "> The fixation rate for type B in a population of type A, $\\rho$, is defined as the probability that the appearance of a mutant of type B leads to the entire population adopting type B instead of A, i.e. what is the likelihood that a mutant of type B invades population A."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a01463-b50c-4fd6-aade-8ec965813481",
   "metadata": {},
   "source": [
    "#### Derivation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ffe1bf-842e-4890-b40f-493bd627e9ce",
   "metadata": {},
   "source": [
    "A derivation of the fixation rate defined below can be found in Nowak 2006 (reproduced below).\n",
    "\n",
    "> Consider a one-dimensional stochastic process on a discrete state space, $ i \\in \\{0, 1, \\cdots, N\\}$ that represents the number of individuals in a population of $N$ individuals who are of type $B$, the rest are type $A$.\n",
    ">\n",
    "> In each stochastic event, the number of individuals of type $B$ can at most increase or decrease by 1.\n",
    ">\n",
    "> For a given number of individuals, $i$, let $a_i$, $b_i$, and $1 - a_i - b_i$ represent the chance of an increase, decrease, or no change in $i$.\n",
    "> \n",
    "> This stochastic process follows the transition matrix ,$P$ (*not to be confused with the transition matrices we discuss elsewhere!*)\n",
    ">\n",
    ">\n",
    "> \\begin{equation}\n",
    "P \\, = \\, \\begin{pmatrix}\n",
    "1 & 0 & 0 & \\cdots & 0 & 0 & 0\\\\\n",
    "b_1 & (1 - a_1 - b_1) & a_1 & \\cdots & 0 & 0 & 0\\\\\n",
    "\\vdots & \\vdots & \\vdots & \\ddots & \\vdots & \\vdots & \\vdots\\\\\n",
    "0 & 0 & 0 & \\cdots & b_{n-1} & (1 - a_{n-1} - b_{n-1}) & a_{n-1}\\\\\n",
    "0 & 0 & 0 & \\cdots & 0 & 0 & 1\\\\\n",
    "\\end{pmatrix}\n",
    "\\end{equation}\n",
    ">\n",
    "> Denote by $x_i$ the probability of reaching state $N$ when starting from $i$.\n",
    ">\n",
    "> From transition matrix $P$ above, we can see that $x_i$ must satisfy:\n",
    ">\n",
    "> $x_0 = 0$\n",
    ">\n",
    "> $x_i = b_i x_{i-1} + (1 - a_i - b_i) x_i + a_i x_{i+1}$\n",
    ">\n",
    "> $x_N = 1$\n",
    ">\n",
    "> The fixation rate for a mutant B in a population of type A is clearly $x_1$\n",
    ">\n",
    "> We can solve for $x_i$ by rewriting the above as $b_i x_i - b_i  x_{i-1} = a_i x_{i+1} - a_i x_i$.\n",
    "> \n",
    "> We can denote $y_i = x_i - x_{i-1}$ to simplify the above to $y_{i+1} = \\frac{b_i}{a_i} y_i$\n",
    ">\n",
    "> Notice that $\\sum_{i=1}^N{y_i} = x_N - x_0 = 1$ and that $y_1 = x_1$\n",
    ">\n",
    "> We can use the above to write\n",
    "\\begin{equation}\n",
    "x_1 + {\\sum_{i=2}^N{y_i}} = x_1 (1 + {\\sum_{i=1}^{N-1}{\\prod_{j=1}^{i} \\frac{b_j}{a_j}}}) = 1\n",
    "\\end{equation}\n",
    ">\n",
    "> And so\n",
    "\\begin{equation}\n",
    "x_1 = \\frac{1}{(1 + \\sum_{i=1}^{N-1}{\\prod_{j=1}^{i} \\frac{b_j}{a_j}})}\n",
    "\\end{equation}\n",
    ">\n",
    "> Note that $x_1$ is the fixation rate for a mutant $B$ in a population of type $A$, often denoted as $\\rho$.\n",
    ">\n",
    "> *Also note that $x_{N-1}$ is the fixation rate for a mutant $A$ in a population of type $B$. We could find expressions for all $x_i$ if we note that $x_i = x_1 (1 + \\sum_{j=1}^{i-1}{\\prod_{k=1}^{j} \\frac{b_k}{a_k}})$ (see Nowak 2006 for further details).*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd408dd8-b57b-4fce-9100-758299ea3c18",
   "metadata": {},
   "source": [
    "#### Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4b2af0-7469-4788-bd6b-96d143e27ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "T_type = list[nptyping.NDArray[nptyping.Shape[\"N_models\"], typing.Any]]\n",
    "\n",
    "def fixation_rate(Tplus: T_type, # A list of NDarrays, one array (of size n_models) for each possible number of mutants in the population; the probability of gaining one mutant\n",
    "                  Tneg: T_type, # A list of NDarrays, one array (of size n_models) for each possible number of mutants in the population; the probability of losing one mutant\n",
    "                 ) -> nptyping.NDArray[nptyping.Shape[\"N_models\"], typing.Any]: # Fixation rates for the given strategy in each model\n",
    "    \"\"\"Calculate the likelihood that a mutant invades the population.\"\"\"\n",
    "    Z = len(Tplus) + 1\n",
    "    ρ = (np.sum([np.prod([Tneg[j-1]/Tplus[j-1]\n",
    "                         for j in range(1,i+1)],\n",
    "                        axis=0,\n",
    "                        keepdims=False)\n",
    "                 for i in range(1,Z)],\n",
    "                axis=0,\n",
    "                keepdims=False)\n",
    "        + 1)**-1\n",
    "    return ρ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4236065c-1875-4503-b790-8b59188e13b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/PaoloBova/gh-pages-example/blob/main/gh_pages_example/methods.py#L28){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### fixation_rate\n",
       "\n",
       ">      fixation_rate (Tplus:list[nptyping.base_meta_classes.NDArray],\n",
       ">                     Tneg:list[nptyping.base_meta_classes.NDArray])\n",
       "\n",
       "Calculate the likelihood that a mutant invades the population.\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| Tplus | list | A list of NDarrays, one array (of size n_models) for each possible number of mutants in the population; the probability of gaining one mutant |\n",
       "| Tneg | list | A list of NDarrays, one array (of size n_models) for each possible number of mutants in the population; the probability of losing one mutant |\n",
       "| **Returns** | **NDArray** | **Fixation rates for the given strategy in each model** |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/PaoloBova/gh-pages-example/blob/main/gh_pages_example/methods.py#L28){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### fixation_rate\n",
       "\n",
       ">      fixation_rate (Tplus:list[nptyping.base_meta_classes.NDArray],\n",
       ">                     Tneg:list[nptyping.base_meta_classes.NDArray])\n",
       "\n",
       "Calculate the likelihood that a mutant invades the population.\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| Tplus | list | A list of NDarrays, one array (of size n_models) for each possible number of mutants in the population; the probability of gaining one mutant |\n",
       "| Tneg | list | A list of NDarrays, one array (of size n_models) for each possible number of mutants in the population; the probability of losing one mutant |\n",
       "| **Returns** | **NDArray** | **Fixation rates for the given strategy in each model** |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(fixation_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aeab27b-5b89-424e-981d-0a6d1b161e7e",
   "metadata": {},
   "source": [
    "#### Examples and Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005877f9-bb91-4f68-a982-a5d50ca48f71",
   "metadata": {},
   "source": [
    "When the chance of gaining a mutant always equals the chance of losing a mutant, then the fixation rate will be $\\frac{1}{Z}$\n",
    "\n",
    "Note that because we have to sample the population for a mutant and the player of the type being invaded, the chance of gaining or losing a mutant can be no greater than $\\frac{k}{Z} \\frac{Z-k}{Z}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be4272f-1d85-416b-b424-53d4d3186b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = 2 # With Z=2, we only need to evaluate Tplus and Tneg for when k=1\n",
    "Tplus_example = [np.array([1/8])]\n",
    "Tneg_example =  [np.array([1/8])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0d9199-f2e7-4dfd-927e-f6c21fc83454",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|  hide\n",
    "# validate test inputs\n",
    "assert len(Tplus_example) == len(Tneg_example)\n",
    "for tplus, tneg in zip(Tplus_example, Tneg_example):\n",
    "    assert tplus.shape == tneg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f41700-0399-4be0-9992-5a111cc086c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fixation_rate_result = fixation_rate(Tplus_example, Tneg_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97469d4-36bf-4d67-9e1f-d39651db1b61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "nptyping.assert_isinstance(fixation_rate_result,\n",
    "                           nptyping.NDArray[nptyping.Shape[\"1\"], typing.Any])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd36d254-7f82-4f86-bd1f-c5bcd6d679e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fastcore.test.test_eq(fixation_rate_result, np.array([0.5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9516d8-2e23-4468-8086-54e4dcd59c8a",
   "metadata": {},
   "source": [
    "When the chance of gaining a mutant is half the chance of losing a mutant, then the fixation rate will be\n",
    "\n",
    "\\begin{equation}\n",
    "\\rho = \\frac{1}{(1 + \\sum_{j=1}^{Z-1}{2^j})}\n",
    "\\end{equation}\n",
    "\n",
    "When $Z=2$, we have $\\rho = \\frac{1}{3}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c929e5-3ab3-48ae-9dba-002c0054f437",
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = 2 # With Z=2, we only need to evaluate Tplus and Tneg for when k=1\n",
    "Tplus_example = [np.array([0.1])]\n",
    "Tneg_example =  [np.array([0.2])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ccc5de-08ce-4d23-bcc4-0f19eb93f390",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|  hide\n",
    "# validate test inputs\n",
    "assert len(Tplus_example) == len(Tneg_example)\n",
    "for i, tplus in enumerate(Tplus_example):\n",
    "    assert tplus.shape == Tneg_example[i].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011ff240-e534-4220-bd37-fb42cb30caa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fixation_rate_result = fixation_rate(Tplus_example, Tneg_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca864e7-693c-4787-9eb7-c3416c5245fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "fastcore.test.test_eq(fixation_rate_result, np.array([1/3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2cff06-3c08-458d-a02a-e68a1c518211",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "nptyping.assert_isinstance(fixation_rate_result,\n",
    "                           nptyping.NDArray[nptyping.Shape[\"1\"], typing.Any])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f635d3-37a5-4969-a784-1875e9486665",
   "metadata": {},
   "source": [
    "We could instead consider an example where we have a mutant Defector (D) who appears in a population of Cooperators (C) playing a standard Prisoner's Dilemma.\n",
    "\n",
    "We will consider an example of such a scenario where chance of gaining/losing a D player be given by $\\frac{1}{1 + e^{\\pm \\beta \\frac{Z+1}{Z-1}}}$.\n",
    "\n",
    "The fixation rate will be given by the following expression:\n",
    "\n",
    "\\begin{equation}\n",
    "\\rho = \\frac{1}{1 + \\sum_{j=1}^{Z-1}{(\\frac{1 + e^{- \\beta \\frac{Z+1}{Z-1}}}{1 + e^{\\beta \\frac{Z+1}{Z-1}}})^j}}\n",
    "\\end{equation}\n",
    "\n",
    "For this example, we will let $\\beta=1$ and $Z=10$, so $\\beta \\frac{Z+1}{Z-1} = \\frac{11}{9}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3006c88-0cde-4e32-934e-59c97c91df6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "β = 1\n",
    "Z = 10\n",
    "ρ_CD = 1 / (1 + sum((1 + np.exp(- β * (Z + 1) / (Z-1)))**j \n",
    "                    / (1 + np.exp(β * (Z + 1) / (Z-1)))**j\n",
    "                    for j in range(1, Z)))\n",
    "Tplus_example = [np.array([1 / (1 + np.exp(- β * (Z + 1) / (Z-1)))])\n",
    "                 for _ in range(Z-1)]\n",
    "Tneg_example =  [np.array([1 / (1 + np.exp(β * (Z + 1) / (Z-1)))])\n",
    "                 for _ in range(Z-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e5b49e-be35-475b-80c1-249b248672dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|  hide\n",
    "# validate test inputs\n",
    "assert len(Tplus_example) == len(Tneg_example)\n",
    "for i, tplus in enumerate(Tplus_example):\n",
    "    assert tplus.shape == Tneg_example[i].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023ec211-bf09-48b8-b14a-1f7d9f2a2e10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "nptyping.assert_isinstance(fixation_rate(Tplus_example, Tneg_example),\n",
    "                           nptyping.NDArray[nptyping.Shape[\"1\"], typing.Any])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfa15aa-41f1-478e-8d5f-edb6f7902064",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fastcore.test.is_close(fixation_rate(Tplus_example, Tneg_example), ρ_CD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763c7ecc-6786-44ea-b479-7f8eeec3cc0d",
   "metadata": {},
   "source": [
    "Finally, it is useful to know how the fixation rate behaves when any elements of Tplus are zero (as the fixation rate divides by those elements). Even though the Fermi learning rule we use theoretically gives a number between 0 and 1 exclusive, in practise the number may underflow to a 0 if low enough. This will cause unexpected behaviour if we allow it in our alogorithm for computing the transition matrix.\n",
    "\n",
    "We can avoid this issue by using a slightly altered method for calculating the fixation rate, taking advantage of our choice to use the `fermi_learning` rule.\n",
    "\n",
    "In the above fixation rate calculations we used the `fermi_learning` function to calculate the probability of a player with strategy $D$ adopting strategy $C$ (and likewise for the probability of a player with $C$ adopting $D$). Their ratio takes the form, $\\frac{1 + e^x}{1 + e^{-x}}$. It is not too hard to verify that $\\frac{1 + e^x}{1 + e^{-x}} = e^x$.\n",
    "\n",
    "Moreover, we can avoid taking the product of the ratios at all, since the product of exponentials (with the same base) is just the exponential of the sum of their exponents.\n",
    "\n",
    "By using the above substitution and algebraic manipulation, we can substantially mitigate the numerical stability issues. For this reason, we will not use `fermi_learning` nor `fixation_rate` in our algorithm at all (although in most cases we would expect these methods to yield the same answers). Instead, we will use `fixation_rate_stable`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3822d05b-aa2c-407a-babb-0fa6dc2b7169",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def fixation_rate_stable(ΠA:list, # Average payoffs for the strategy A they consider adopting for each number of mutants following A\n",
    "                         ΠB:list, # Average payoffs for the strategy B that the player currently follows for each number of mutants following A\n",
    "                         β:Array1D, # learning rate \n",
    "                        ):\n",
    "    \"\"\"Calculate the likelihood that a mutant B invades population A\n",
    "    using a numerically stable method.\"\"\"\n",
    "    fastcore.test.test_eq(len(ΠA), len(ΠB))\n",
    "    Z = len(ΠA) + 1\n",
    "    ρ = (np.sum([np.exp(np.clip(np.sum([-β*(ΠB[j-1] - ΠA[j-1])\n",
    "                                        for j in range(1,i+1)],\n",
    "                                       axis=0,\n",
    "                                       keepdims=False),\n",
    "                                -500,\n",
    "                                500)) # avoid underflow/overflow warnings\n",
    "                 for i in range(1,Z)],\n",
    "                axis=0,\n",
    "                keepdims=False)\n",
    "        + 1)**-1\n",
    "    return ρ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45f22eb-9d81-4cd6-86e1-c86cefbdf7b1",
   "metadata": {},
   "source": [
    "We can see in the examples which follow that both methods usually give the same answers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba97c8c5-cd72-48da-87ed-d17e2c47b950",
   "metadata": {},
   "source": [
    "To match an earlier example where `Tplus` and `Tneg` were both equal to $\\frac{1}{8}$ (as $Z=2$ we only need to consider one value for each when $k=1$), we let $\\beta=1$ and recall that $T^+_B(k) = \\frac{Z-k}{Z} \\frac{k}{Z} Pr(adopt \\, B | k) = \\frac{Z-k}{Z} \\frac{k}{Z} \\frac{1}{1 + \\exp^{-\\beta (ΠB(k) - ΠA(k))}} $\n",
    "\n",
    "We can then say that $ΠA - ΠB = \\log{(\\frac{1}{\\frac{4}{8}} - 1)} = \\log{\\frac{4}{4}} = \\log{4} - \\log{4}$\n",
    "\n",
    "Notice that to achieve netural drift, the payoffs have to be equal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c6a3ee-2171-4ce2-a9f7-b9ad627f71ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = 2\n",
    "β = 1\n",
    "ΠA = [np.array([np.log(4)])]\n",
    "ΠB = [np.array([np.log(4)])]\n",
    "result = fixation_rate_stable(ΠA, ΠB, β)\n",
    "fastcore.test.test_close(result, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab6a8b1-95c7-48fe-a235-b36a929e1dd1",
   "metadata": {},
   "source": [
    "We can also consider an example from a payoff matrix I've run into in practise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ccbfcc-91c7-4849-96ed-d3e3b2c1dc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "payoffs = np.array([[51, 0.6, 51],\n",
    "                    [114.3, 57.75, 39.38],\n",
    "                    [51, 0.99798, 51]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526bcead-17a7-4305-9d09-ec9e8723e672",
   "metadata": {},
   "source": [
    "We are interested in the fixation rate of a mutant B in a population of A\n",
    "\n",
    "Strategy A is the strategy represented by row 3\n",
    "\n",
    "Strategy B is the strategy represented by row 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14ae521-1122-484a-9b61-8f5405b479a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = 100\n",
    "β = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000f38ed-56ca-4ad5-b1f2-d2e5fe19c5dd",
   "metadata": {},
   "source": [
    "We need only the average payoffs for the stable calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd49060-30d6-4b2b-a395-cef069f36a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "ΠA = [k/(Z-1) * payoffs[2,1] + (Z-k-1)/(Z-1) * payoffs[2,2]\n",
    "      for k in range(1, Z)]\n",
    "ΠB = [(k-1)/(Z-1) * payoffs[1,1] + (Z-k)/(Z-1) * payoffs[1,2]\n",
    "      for k in range(1, Z)]\n",
    "\n",
    "result_stable = fixation_rate_stable(ΠA, ΠB, β)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632080d7-60ac-4ca5-976c-e90a7087c5a5",
   "metadata": {},
   "source": [
    "We also need the adoption rates for the unstable calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b007792b-11a9-4ff4-97fc-8f5efaa0823f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tneg = [fermi_learning(ΠB[k-1], ΠA[k-1], β)\n",
    "                     for k in range(1, Z)]\n",
    "Tplus = [fermi_learning(ΠA[k-1], ΠB[k-1], β)\n",
    "         for k in range(1, Z)]\n",
    "\n",
    "# Naiive and unstable calculation\n",
    "result_unstable = fixation_rate(Tplus, Tneg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c007dbe6-4a3f-4f39-8ffe-88c4ba52df67",
   "metadata": {},
   "outputs": [],
   "source": [
    "fastcore.test.test_close(result_stable, 0)\n",
    "fastcore.test.test_close(result_unstable, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c827802-97f6-4bf4-a626-3e8db969fb97",
   "metadata": {},
   "source": [
    "### Build transition matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd8d5bc-dfd0-4a4b-a750-9ecec7fdd117",
   "metadata": {},
   "source": [
    "Recall that step 1 of finding the solution to the Evolutionary Game dynamics is to build a transition matrix between all monomorphic states. \n",
    "\n",
    "The transition matrix captures the probability that if the population of the Evolutionary Game transitions to another state. We read an entry of the transition matrix as saying the probability of transitioning from the row state to column state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932859e9-a0bb-48c3-9853-7ff72c997165",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#| hide\n",
    "class ModelTypeEGT():\n",
    "    \"\"\"This is the schema for an Evolutionary Game Theory model.\n",
    "    \n",
    "    Note: This schema is not enforced and is here purely for documentation\n",
    "    purposes.\"\"\"\n",
    "    def __init__(self, \n",
    "                 Z: int, # the size of the population\n",
    "                 strategy_set: list[str], # the set of strategies in the model\n",
    "                 β: Array1D, # the learning rate\n",
    "                 payoffs: Array3D, # the payoffs of the game\n",
    "                 transition_matrix: Array3D=None, # the model's transition matrix\n",
    "                 ergodic: Array2D=None, # ergodic distribution of the model's markov chain\n",
    "                ):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525269fc-1afe-4e7b-9e72-c7f6f6596cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#| hide\n",
    "@multi\n",
    "def build_transition_matrix(models:dict # A dictionary that contains the parameters in `ModelTypeEGT`\n",
    "                           ):\n",
    "    \"\"\"Build a transition matrix between all monomorphic states using the\n",
    "    fermi social learning rule.\"\"\"\n",
    "    return models.get('dispatch-type')\n",
    "    \n",
    "\n",
    "@method(build_transition_matrix)\n",
    "def build_transition_matrix(models:dict # A dictionary that contains the parameters in `ModelTypeEGT`\n",
    "                           ):\n",
    "    \"\"\"Build a transition matrix between all monomorphic states\n",
    "    using the fermi social learning rule for each model.    \n",
    "    \"\"\"\n",
    "    \n",
    "    Z, S, β = [models[k] for k in ['Z','strategy_set', 'β']]\n",
    "    π = models['payoffs']\n",
    "    n_models = π.shape[0]\n",
    "    M = np.zeros(( n_models, len(S), len(S)))\n",
    "    for row_ind, s in enumerate(S):\n",
    "        for col_ind, sₒ in enumerate(S):\n",
    "            if row_ind == col_ind:\n",
    "                M[:, row_ind, row_ind] += 1\n",
    "                # We calibrate these entries later so rows add up to 1\n",
    "                continue\n",
    "            πAA = π[:, row_ind, row_ind]\n",
    "            πAB = π[:, row_ind, col_ind]\n",
    "            πBA = π[:, col_ind, row_ind]\n",
    "            πBB = π[:, col_ind, col_ind]\n",
    "            ΠA = [πAA*(Z-k-1)/(Z-1) + πAB*k/(Z-1)\n",
    "                  for k in range(1, Z)]\n",
    "            ΠB = [πBA*(Z-k)/(Z-1)  + πBB*(k-1)/(Z-1)\n",
    "                  for k in range(1, Z)]\n",
    "            # We use a numerically stable method to find the fixation rate, ρ.\n",
    "            # ρ is the probability that mutant B successfully invades A\n",
    "            ρ = fixation_rate_stable(ΠA, ΠB, β)\n",
    "            M[:, row_ind, col_ind] = ρ / max(1, len(S)-1)\n",
    "            M[:, row_ind, row_ind] -= ρ / max(1, len(S)-1)\n",
    "    return {**models, \"transition_matrix\": M}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e727d1b-c3a9-411c-89b4-e4483a4d32fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#| hide\n",
    "@method(build_transition_matrix, 'unstable')\n",
    "def build_transition_matrix(models:dict # A dictionary that contains the parameters in `ModelTypeEGT`\n",
    "                           ):\n",
    "    \"\"\"Build a transition matrix using a numerically unstable method.\"\"\"\n",
    "    \n",
    "    Z, S, β = [models[k] for k in ['Z','strategy_set', 'β']]\n",
    "    π = models['payoffs']\n",
    "    n_models = π.shape[0]\n",
    "    M = np.zeros(( n_models, len(S), len(S)))\n",
    "    for row_ind, s in enumerate(S):\n",
    "        for col_ind, sₒ in enumerate(S):\n",
    "            if row_ind == col_ind:\n",
    "                M[:, row_ind, row_ind] += 1\n",
    "                # We calibrate these entries later so rows add up to 1\n",
    "                continue\n",
    "            πAA = π[:, row_ind, row_ind]\n",
    "            πAB = π[:, row_ind, col_ind]\n",
    "            πBA = π[:, col_ind, row_ind]\n",
    "            πBB = π[:, col_ind, col_ind]\n",
    "            ΠA = [πAA*(Z-k-1)/(Z-1) + πAB*k/(Z-1)\n",
    "                  for k in range(1, Z)]\n",
    "            ΠB = [πBA*(Z-k)/(Z-1)  + πBB*(k-1)/(Z-1)\n",
    "                  for k in range(1, Z)]\n",
    "            Tneg = [fermi_learning(ΠB[k-1], ΠA[k-1], β)\n",
    "                    for k in range(1, Z)]\n",
    "            Tplus = [fermi_learning(ΠA[k-1], ΠB[k-1], β)\n",
    "                     for k in range(1, Z)]\n",
    "            ρ = fixation_rate(Tplus, Tneg)\n",
    "            M[:, row_ind, col_ind] = ρ / max(1, len(S)-1)\n",
    "            M[:, row_ind, row_ind] -= ρ / max(1, len(S)-1)\n",
    "    return {**models, \"transition_matrix\": M}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28cfebf8-5411-4d33-89b6-cf010a272b93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/PaoloBova/gh-pages-example/blob/main/gh_pages_example/methods.py#L184){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### build_transition_matrix\n",
       "\n",
       ">      build_transition_matrix (models:dict)\n",
       "\n",
       "Build a transition matrix between all monomorphic states using the\n",
       "fermi social learning rule.\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| models | dict | A dictionary that contains the parameters in `ModelTypeEGT` |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/PaoloBova/gh-pages-example/blob/main/gh_pages_example/methods.py#L184){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### build_transition_matrix\n",
       "\n",
       ">      build_transition_matrix (models:dict)\n",
       "\n",
       "Build a transition matrix between all monomorphic states using the\n",
       "fermi social learning rule.\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| models | dict | A dictionary that contains the parameters in `ModelTypeEGT` |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(build_transition_matrix.__dispatch_fn__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61aaa4a8-200c-4bbe-b6bb-34ed13151248",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/PaoloBova/gh-pages-example/blob/main/gh_pages_example/methods.py#L65){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ModelTypeEGT\n",
       "\n",
       ">      ModelTypeEGT (Z:int, strategy_set:list[str],\n",
       ">                    β:gh_pages_example.types.Array1D,\n",
       ">                    payoffs:gh_pages_example.types.Array3D,\n",
       ">                    transition_matrix:gh_pages_example.types.Array3D=None,\n",
       ">                    ergodic:gh_pages_example.types.Array2D=None)\n",
       "\n",
       "This is the schema for an Evolutionary Game Theory model.\n",
       "\n",
       "Note: This schema is not enforced and is here purely for documentation\n",
       "purposes.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| Z | int |  | the size of the population |\n",
       "| strategy_set | list |  | the set of strategies in the model |\n",
       "| β | Array1D |  | the learning rate |\n",
       "| payoffs | Array3D |  | the payoffs of the game |\n",
       "| transition_matrix | Array3D | None | the model's transition matrix |\n",
       "| ergodic | Array2D | None | ergodic distribution of the model's markov chain |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/PaoloBova/gh-pages-example/blob/main/gh_pages_example/methods.py#L65){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ModelTypeEGT\n",
       "\n",
       ">      ModelTypeEGT (Z:int, strategy_set:list[str],\n",
       ">                    β:gh_pages_example.types.Array1D,\n",
       ">                    payoffs:gh_pages_example.types.Array3D,\n",
       ">                    transition_matrix:gh_pages_example.types.Array3D=None,\n",
       ">                    ergodic:gh_pages_example.types.Array2D=None)\n",
       "\n",
       "This is the schema for an Evolutionary Game Theory model.\n",
       "\n",
       "Note: This schema is not enforced and is here purely for documentation\n",
       "purposes.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| Z | int |  | the size of the population |\n",
       "| strategy_set | list |  | the set of strategies in the model |\n",
       "| β | Array1D |  | the learning rate |\n",
       "| payoffs | Array3D |  | the payoffs of the game |\n",
       "| transition_matrix | Array3D | None | the model's transition matrix |\n",
       "| ergodic | Array2D | None | ergodic distribution of the model's markov chain |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(ModelTypeEGT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098a1361-4d6c-4eb5-8c6f-6df0a2ab8938",
   "metadata": {},
   "source": [
    "#### Examples and Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25222a93-d57e-47b9-abb6-d1280b5d99a3",
   "metadata": {},
   "source": [
    "Consider the following two examples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b182c962-85a7-4812-aa09-d5a9487909fd",
   "metadata": {},
   "source": [
    "**Example 1**\n",
    "\n",
    "Let all payoffs be equal in the game's payoff matrix. All expected payoffs will be equal too.\n",
    "\n",
    "So, Fermi learning will say that each individual has a 50% chance of adopting the behaviour of the one they observe.\n",
    "\n",
    "We therefore have an equal chance during each epoch of gaining or losing an individual of the given type, in this example we denote the type as $s \\in \\{A, B\\}$, although this probability depends on population size $Z$ and the current number of individuals of that type, $k$, $T^+_s(k) = T^-_s(k) = \\frac{Z-k}{Z} \\frac{k}{Z} \\frac{1}{2}$.\n",
    "\n",
    "Recall that we calculate the fixation rate, $\\rho$ as follows:\n",
    "\\begin{equation}\n",
    "\\rho = \\frac{1}{1 + \\sum_{j=1}^{N-1}{\\prod_{k=1}^{j} \\frac{b_k}{a_k}}}\n",
    "\\end{equation}\n",
    "where $N=Z$, $b_k = T^-_s(k)$ and $a_k = T^+_s(k)$\n",
    "\n",
    "In this example, for each strategy $s$, $T^-_s(k) = T^+_s(k), \\, \\forall k$, so $\\rho = \\frac{1}{Z}$.\n",
    "\n",
    "We only have $2$ strategies, and $Z=10$, so the final transition matrix will look like\n",
    "\n",
    "\\begin{equation}\n",
    "M \\, = \\, \\begin{pmatrix}\n",
    "1 - \\frac{\\rho}{2 - 1} & \\frac{\\rho}{2 - 1} &\\\\\n",
    "\\frac{\\rho}{2 - 1} & 1 - \\frac{\\rho}{2 - 1}\\\\\n",
    "\\end{pmatrix}\n",
    "= \\begin{pmatrix}\n",
    "0.9 & 0.1 &\\\\\n",
    "0.1 & 0.9\\\\\n",
    "\\end{pmatrix}\n",
    "\\end{equation}\n",
    "\n",
    "Note that the above example describes neutral drift, the idea that even if there is no advantage to be gained from any particular strategy, social learning can still result in the spread of that behaviour. Neutral drift also occurs if we set the Fermi learning rate $\\beta = 0$, no matter what payoff matrix describes the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b51afb-7c71-4fed-a636-a67705304ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "payoffs = np.array([[[2, 2],\n",
    "                     [2, 2]]\n",
    "                   ])\n",
    "Z = 10\n",
    "β = 1\n",
    "models = {\"payoffs\": payoffs,\n",
    "          \"Z\": Z,\n",
    "          \"β\": β,\n",
    "          \"strategy_set\": [\"A\", \"B\"],\n",
    "         }\n",
    "result = build_transition_matrix(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d41c9a-9ad4-482f-a003-63eb6477a2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fastcore.test.test_close(result['transition_matrix'],\n",
    "                         np.array([[0.9, 0.1],\n",
    "                                   [0.1, 0.9]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a32d142-e5ae-455d-b782-117edb407a10",
   "metadata": {},
   "source": [
    "**Example 2**\n",
    "\n",
    "Let the payoff matrix be akin to a Prisoner's Dilemma with two strategies, $C$ or $D$ (Cooperate or Defect respectively):\n",
    "\n",
    "\\begin{pmatrix}\n",
    "2 & 0\\\\\n",
    "3 & 1\\\\\n",
    "\\end{pmatrix}\n",
    "\n",
    "Again, for this simple example, the relative average success of strategy $C$ is independent of the number of $C$ players, $k$. This is rarely the case in practise but permits a more legible example.\n",
    "\n",
    "$C$'s relative success over $D$ will be $\\frac{2 (k-1)}{Z-1} - \\frac{3 k + (Z - k - 1)}{Z-1} = - \\frac{Z + 1}{Z-1}$.\n",
    "\n",
    "Fermi learning means the probability of a $D$ player adopting what they see $C$ do is:\n",
    "\n",
    "\\begin{equation}\n",
    "\\frac{1}{1 + e^{- \\beta (\\Pi_C(k) - \\Pi_D(k))}} = \\frac{1}{1 + e^{\\beta \\frac{Z + 1}{Z-1}}}\n",
    "\\end{equation}\n",
    "\n",
    "The fixation rate for mutant $C$ in a population of $D$ players, $\\rho_{DC}$, can be computed as\n",
    "\n",
    "\\begin{equation}\n",
    "\\rho_{DC} = \\frac{1}{1 + \\sum_{j=1}^{Z-1}{(\\frac{1 + e^{\\beta \\frac{Z + 1}{Z-1}}}{1 + e^{-\\beta \\frac{Z + 1}{Z-1}}})^j}}\n",
    "\\end{equation}\n",
    "\n",
    "Similarly, the fixation rate for mutant $D$ in a population of $C$ players, $\\rho_{CD}$, can be computed as \n",
    "\n",
    "\\begin{equation}\n",
    "\\rho_{CD} = \\frac{1}{1 + \\sum_{j=1}^{Z-1}{(\\frac{1 + e^{-\\beta \\frac{Z + 1}{Z-1}}}{1 + e^{\\beta \\frac{Z + 1}{Z-1}}})^j}}\n",
    "\\end{equation}\n",
    "\n",
    "For $Z=10$ and $\\beta = 1$, the above yields the following transition matrix,\n",
    "\n",
    "\\begin{equation}\n",
    "M \\, = \\, \\begin{pmatrix}\n",
    "1 - \\frac{\\rho_{CD}}{2 - 1} & \\frac{\\rho_{CD}}{2 - 1} &\\\\\n",
    "\\frac{\\rho_{DC}}{2 - 1} & 1 - \\frac{\\rho_{DC}}{2 - 1}\\\\\n",
    "\\end{pmatrix}\n",
    "\\approx \\begin{pmatrix}\n",
    "0.295 & 0.705 &\\\\\n",
    "0.000 & 1.000\\\\\n",
    "\\end{pmatrix}\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06de05f4-e0b9-4cbb-963c-18b83039e7d4",
   "metadata": {},
   "source": [
    "\n",
    "Note how in the above fixation rate calculations how we used the `fermi_learning` function to calculate the probability of a player with strategy $D$ adopting strategy $C$ (and likewise for the probability of a player with $C$ adopting $D$). This function has special properties which aid us in calculating the fixation rate.\n",
    "\n",
    "Notice how the ratio of the two adoption rates takes the form, $\\frac{1 + e^x}{1 + e^{-x}}$. It is not too hard to verify that $\\frac{1 + e^x}{1 + e^{-x}} = e^x$.\n",
    "\n",
    "We utilities this property to considerably improve the numerical stability of our algorithm for building a transition matrix. For this reason, we do not use `fermi_learning` in our algorithm at all.\n",
    "\n",
    "We can similarly note that $\\frac{1}{1 + e^{-x}} = 1 - \\frac{1}{1 + e^{x}}$, i.e. the two adoption rates are complementary probabilities.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e885818-dcfd-4443-9ae3-2c616b8e976e",
   "metadata": {},
   "outputs": [],
   "source": [
    "payoffs = np.array([[[2, 0],\n",
    "                     [3, 1]],\n",
    "                   ])\n",
    "Z = 10\n",
    "β = 1\n",
    "models = {\"payoffs\": payoffs,\n",
    "          \"Z\": Z,\n",
    "          \"β\": β,\n",
    "          \"strategy_set\": [\"C\", \"D\"],\n",
    "         }\n",
    "result = build_transition_matrix(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f9b18d-a668-430f-8fcf-a9702fbfd9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ρ_CD = 1 / (1 + sum((1 + np.exp(- β * (Z + 1) / (Z-1)))**j \n",
    "                    / (1 + np.exp(β * (Z + 1) / (Z-1)))**j\n",
    "                    for j in range(1, Z)))\n",
    "ρ_DC = 1 / (1 + sum((1 + np.exp(β * (Z + 1) / (Z-1)))**j\n",
    "                    / (1 + np.exp(- β * (Z + 1) / (Z-1)))**j \n",
    "                    for j in range(1, Z)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96de16cf-c528-4dfd-aeb2-e349a3811415",
   "metadata": {},
   "outputs": [],
   "source": [
    "ρ_CD_alt = 1 / (1 + sum(np.exp(- j * β * (Z + 1) / (Z-1))\n",
    "                        for j in range(1, Z)))\n",
    "ρ_DC_alt = 1 / (1 + sum(np.exp(j * β * (Z + 1) / (Z-1))\n",
    "                        for j in range(1, Z)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ede78a-9d20-4bfa-92b3-61ae7a4096a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fastcore.test.test_close(ρ_CD, ρ_CD_alt)\n",
    "fastcore.test.test_close(ρ_DC, ρ_DC_alt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deed5ac3-48a9-47ea-86b8-d3a1135077fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fastcore.test.test_close(result['transition_matrix'],\n",
    "                         np.array([[1- ρ_CD, ρ_CD],\n",
    "                                   [ρ_DC, 1 - ρ_DC]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e68e50-329b-4e8d-b3cb-9b81e051384c",
   "metadata": {},
   "source": [
    "**Example 3**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c81be48-0a09-488f-94f0-dc60127c454e",
   "metadata": {},
   "source": [
    "Here is an additional example for the 3 by 3 matrix we discussed when testing other functions.\n",
    "\n",
    "This time, we make sure we get the correct probabilities for each transition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a94eb04-dcff-4d54-a218-d90c5137eaaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "payoffs = np.array([[[51, 0.6, 51],\n",
    "                     [114.3, 57.75, 39.38],\n",
    "                     [51, 0.99798, 51]],\n",
    "                   ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4dd779-f4db-4347-a0a2-e78a9bd85738",
   "metadata": {},
   "outputs": [],
   "source": [
    "expected = np.array([[[0.495, 0.5, 0.005],\n",
    "                     [0, 1, 0],\n",
    "                     [0.005, 0, 0.995]],\n",
    "                   ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3abd346-2a8a-4f0d-8136-7a56fa4f4bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = 100\n",
    "β = 1\n",
    "models = {\"payoffs\": payoffs,\n",
    "          \"Z\": Z,\n",
    "          \"β\": β,\n",
    "          \"strategy_set\": [\"AS\", \"AU\", \"PS\"],\n",
    "         }\n",
    "result = build_transition_matrix(models)\n",
    "fastcore.test.test_close(result['transition_matrix'], expected)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf604f74-2729-4ac9-bbfc-f1cf1fa4a9fc",
   "metadata": {},
   "source": [
    "### Find ergodic strategy distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aced671-f623-440b-ab31-c0d200ee0729",
   "metadata": {},
   "source": [
    "Step 2 is to find the ergodic distribution for the Evolutionary Game using the transition matrix we constructed in step 1.\n",
    "\n",
    "Let $M$ denote the transition matrix, and $\\omega_t$ be the column vector describing the proportions with which each strategy is played in the population.\n",
    "\n",
    "We can describe the evolution of this system with $\\omega_{t+1} = M^T \\omega_t$, i.e. the proportion of players that use a given strategy in the next round will be equal to the sum of the proportions of players for each strategy who adopted that strategy in the current round. Equivalently, we can also consider $\\omega_t$ as describing the probabilities that the system at time t is in each of the monomorphic states.\n",
    "\n",
    "As each of the monomporphic states described in the transition matrix is reachable from any other with some probability and since the transition probabilities only depend on the current state, what we have is a markov chain which is irreducible.\n",
    "\n",
    "The ergodicity theorem guarantees that such irreducible and aperiodic markov chains have an ergodic distribution that the system converges to, no matter where it starts. An ergodic distribution (also called a stationary distribution),  $\\omega^*$ satisfies  $\\omega^* = M^T \\omega^*$ [[1]](https://gregorygundersen.com/blog/2019/10/28/ergodic-markov-chains/) [[2]](http://www.stat.columbia.edu/~liam/teaching/neurostat-spr11/papers/mcmc/Ergodicity_Theorem.pdf) [[3]](https://textbooks.math.gatech.edu/ila/1553/stochastic-matrices.html).\n",
    "\n",
    "Our ergodic distribution, $\\omega^*$, is therefore defined as the normalised right-hand eigenvector with eigenvalue 1 of the transposed transition matrix, $M^T$ (or equivalently, if we defined $\\omega$ as a row vector instead, $\\omega^*$ would be the left-hand eigenvector with eigenvalue 1 of transition matrix, $M$; numerical computing packages usually return the right-hand eigenvectors more directly, which is why I used the other formalism).\n",
    "\n",
    "We use standard linear algebra methods from the [numpy](https://numpy.org/) package to find this eigenvector. These numerical methods will usually not return an eigenvector which is normalised to sum to 1, so we must normalise the eigenvector we are given. See their documentation to learn more about these numerical methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c98786-9d06-4471-b322-a90e521e6fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def find_ergodic_distribution(models:dict # A dictionary that contains the parameters in `ModelTypeEGT`\n",
    "                             ):\n",
    "    \"\"\"Find the ergodic distribution of a markov chain with the\n",
    "    given transition matrix.\"\"\"\n",
    "    M = models[\"transition_matrix\"]\n",
    "    # find unit eigenvector of markov chain\n",
    "    Λ,V = np.linalg.eig(M.transpose(0,2,1))\n",
    "    V = np.real_if_close(V)\n",
    "    x = np.isclose(Λ, 1)\n",
    "    # if multiple unit eigenvalues then choose the first\n",
    "    y = np.zeros_like(x, dtype=bool)\n",
    "    idx = np.arange(len(x)), x.argmax(axis=1)\n",
    "    y[idx] = x[idx]\n",
    "    ergodic = np.array(V.transpose(0,2,1)[y], dtype=float)\n",
    "    # ensure ergodic frequencies are positive and sum to 1\n",
    "    ergodic = np.abs(ergodic) / np.sum(np.abs(ergodic), axis=1)[:, None]\n",
    "    return {**models, 'ergodic':ergodic}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0249dbbc-12f1-4cee-8488-c5f755216cf9",
   "metadata": {},
   "source": [
    "#### Examples and Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb2ae7f-f94f-4b54-90eb-ec4af9077aba",
   "metadata": {},
   "source": [
    "Let our transition matrix, $M$ be\n",
    "\n",
    "\\begin{equation}\n",
    "M = \\begin{pmatrix}\n",
    "\\frac{3}{4} & \\frac{1}{4} \\\\\n",
    "\\frac{1}{4} & \\frac{3}{4} \\\\\n",
    "\\end{pmatrix}\n",
    "\\end{equation}\n",
    "\n",
    "Note that $M^T$ is a stochastic matrix because each column of the transposed matrix would sum to $1$ (in general the rows of the transposed matrix are unlikely to sum to 1, but choosing an example like the above makes it easy to compute the eigenvectors).\n",
    "\n",
    "It's not too hard to verify that the characteristic polynomial of $M^T$ can be factored into $(\\lambda - 1)(\\lambda - \\frac{1}{2})$, so we have two eigenvalues, $1$ and $\\frac{1}{2}$.\n",
    "\n",
    "It's not too hard to verify that column vector $[1, 1]$ is the eigenvector of $M^T$ with eigenvalue $1$\n",
    ".\n",
    "\n",
    "Now that we know the weights placed on each strategy, we can compute the strategy distribution by normalising our eigenvector.\n",
    "\n",
    "The ergodic distribution i $\\omega^* = [\\frac{1}{2}, \\frac{1}{2}]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ac241d-d8c9-40f6-ad80-0ddb81b00e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "M = np.array([[[3/4, 1/4],\n",
    "               [1/4, 3/4]],\n",
    "             ])\n",
    "models = {\"transition_matrix\": M}\n",
    "result = find_ergodic_distribution(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc0de01-3983-48c1-956f-3c686c4d27b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fastcore.test.test_eq(result['ergodic'],\n",
    "                      np.array([[1/2, 1/2]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3a57ac-f485-46a0-b736-2a08cdf18a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #| hide\n",
    "# # Here is some code which illustrates how one could use sympy to find the relevant eigenvectors \n",
    "# # using symbolic methods (but please note that even sympy must resort to numerical methods if\n",
    "# # the matrices are bigger than 5 by 5 in size, due to the fundamental lack of exact solutions to \n",
    "# # polynomial equations with order greater than 5)\n",
    "# import sympy\n",
    "# for m in M:\n",
    "#     # Sympy needs integers or expressions to work\n",
    "#     # Integers is usually safer\n",
    "#     m = np.array(1000 * m, dtype=int)\n",
    "#     M_symbolic = sympy.Matrix(m)\n",
    "#     for result in M_symbolic.eigenvects():\n",
    "#         lamda, multiplicity, evs = result\n",
    "        \n",
    "#         # print(\"lambda: \" , lamda,\n",
    "#         #           \"multiplicity: \", multiplicity,\n",
    "#         #           \"eigenvectors: \", evs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94604c8-2f2b-46d5-8234-334635abd500",
   "metadata": {},
   "source": [
    "Here is another quick illustrative example.\n",
    "\n",
    "Let our transition matrix, $M$ be\n",
    "\n",
    "\\begin{equation}\n",
    "M = \\begin{pmatrix}\n",
    "\\frac{3}{4} & \\frac{1}{4} \\\\\n",
    "\\frac{3}{4} & \\frac{1}{4} \\\\\n",
    "\\end{pmatrix}\n",
    "\\end{equation}\n",
    "\n",
    "$M^T$ is a stochastic matrix. It is easy to verify that $[\\frac{3}{4}, \\frac{1}{4}]$ is the normalised eigenvector with eigenvalue 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ae7587-ea91-4a61-a316-35563ea0222f",
   "metadata": {},
   "outputs": [],
   "source": [
    "M = np.array([[[3/4, 1/4],\n",
    "               [3/4, 1/4]],\n",
    "             ])\n",
    "models = {\"transition_matrix\": M}\n",
    "result = find_ergodic_distribution(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8543490-6385-4b3b-9801-9229a54cb053",
   "metadata": {},
   "outputs": [],
   "source": [
    "fastcore.test.test_eq(result['ergodic'],\n",
    "                      np.array([[3/4, 1/4]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27968b3f-8b47-4298-b6e6-1020c894e8ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/PaoloBova/gh-pages-example/blob/main/gh_pages_example/methods.py#L155){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### find_ergodic_distribution\n",
       "\n",
       ">      find_ergodic_distribution (models:dict)\n",
       "\n",
       "Find the ergodic distribution of a markov chain with the\n",
       "given transition matrix.\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| models | dict | A dictionary that contains the parameters in `ModelTypeEGT` |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/PaoloBova/gh-pages-example/blob/main/gh_pages_example/methods.py#L155){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### find_ergodic_distribution\n",
       "\n",
       ">      find_ergodic_distribution (models:dict)\n",
       "\n",
       "Find the ergodic distribution of a markov chain with the\n",
       "given transition matrix.\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| models | dict | A dictionary that contains the parameters in `ModelTypeEGT` |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(find_ergodic_distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d870ac66-b641-434b-bb9a-27df3577eecf",
   "metadata": {},
   "source": [
    "### Run full markov chain algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9cd9f0e-f1e5-459a-b7a9-829c11bfc7e9",
   "metadata": {},
   "source": [
    "Finally, here is a helper function to both build the transition matrix for the model and find its ergodic distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe4a9b3-6248-4f70-9694-820307de7b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def markov_chain(models:dict # A dictionary that contains the parameters in `ModelTypeEGT`\n",
    "                ):\n",
    "    \"\"\"Find the ergodic distribution of the evolutionary\n",
    "    game given by each model in models.\"\"\"\n",
    "    return thread_macro(models,\n",
    "                        build_transition_matrix,\n",
    "                        find_ergodic_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0fb6f2-cb09-4a98-ac1c-f91aa1b292f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/PaoloBova/gh-pages-example/blob/main/gh_pages_example/methods.py#L174){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### markov_chain\n",
       "\n",
       ">      markov_chain (models:dict)\n",
       "\n",
       "Find the ergodic distribution of the evolutionary\n",
       "game given by each model in models.\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| models | dict | A dictionary that contains the parameters in `ModelTypeEGT` |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/PaoloBova/gh-pages-example/blob/main/gh_pages_example/methods.py#L174){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### markov_chain\n",
       "\n",
       ">      markov_chain (models:dict)\n",
       "\n",
       "Find the ergodic distribution of the evolutionary\n",
       "game given by each model in models.\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| models | dict | A dictionary that contains the parameters in `ModelTypeEGT` |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(markov_chain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ab3139-41ee-40d3-9a22-3506072288ae",
   "metadata": {},
   "source": [
    "## Multiple Populations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54550640-f67d-465d-a380-a94671f12b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "#| hide\n",
    "@method(build_transition_matrix, 'multiple-populations')\n",
    "def build_transition_matrix(models:dict # A dictionary that contains the parameters in `ModelTypeEGT`\n",
    "                           ):\n",
    "    \"\"\"Build a transition matrix between all monomorphic states\n",
    "    when there are multiple populations.    \n",
    "    \"\"\"\n",
    "    Z, S, β = [models[k] for k in ['Z', 'recurrent_state_space', 'β']]\n",
    "    valid_transitions = models['valid_transitions']\n",
    "    π = models['payoffs']\n",
    "    M = np.zeros((payoffs.shape[0], len(S), len(S)))\n",
    "    for row_ind in range(M.shape[-1]):\n",
    "        M[:, row_ind, row_ind] += 1\n",
    "    for transition in valid_transitions.values():\n",
    "        strategy_profile_indices = transition['strategy_profile_indices']\n",
    "        player_index = transition['player_index']\n",
    "        row_ind = transition['row_ind']\n",
    "        col_ind = transition['col_ind']\n",
    "        πAA = π[:, strategy_profile_indices['AA'], player_index]\n",
    "        πAB = π[:, strategy_profile_indices['AB'], player_index]\n",
    "        πBA = π[:, strategy_profile_indices['BA'], player_index]\n",
    "        πBB = π[:, strategy_profile_indices['BB'], player_index]\n",
    "        ΠA = [πAA*(Z-k-1)/(Z-1) + πAB*k/(Z-1)\n",
    "              for k in range(1, Z)]\n",
    "        ΠB = [πBA*(Z-k)/(Z-1)  + πBB*(k-1)/(Z-1)\n",
    "              for k in range(1, Z)]\n",
    "        # We use a numerically stable method to find the fixation rate, ρ.\n",
    "        # ρ is the probability that mutant B successfully invades A\n",
    "        ρ = fixation_rate_stable(ΠA, ΠB, β)\n",
    "        # We have to divide this rate by the number of possible mutations\n",
    "        n_mutations = 0\n",
    "        for vt in valid_transitions.values():\n",
    "            if vt['row_ind'] == row_ind:\n",
    "                n_mutations += 1\n",
    "        M[:, row_ind, col_ind] = ρ / n_mutations\n",
    "        M[:, row_ind, row_ind] -= ρ / n_mutations\n",
    "    return {**models, 'transition_matrix':M}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f54813-0349-47f6-8c27-0ecb1a1f0b57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/PaoloBova/gh-pages-example/blob/main/gh_pages_example/methods.py#L184){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### build_transition_matrix\n",
       "\n",
       ">      build_transition_matrix (models:dict)\n",
       "\n",
       "Build a transition matrix between all monomorphic states\n",
       "when there are multiple populations.\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| models | dict | A dictionary that contains the parameters in `ModelTypeEGT` |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/PaoloBova/gh-pages-example/blob/main/gh_pages_example/methods.py#L184){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### build_transition_matrix\n",
       "\n",
       ">      build_transition_matrix (models:dict)\n",
       "\n",
       "Build a transition matrix between all monomorphic states\n",
       "when there are multiple populations.\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| models | dict | A dictionary that contains the parameters in `ModelTypeEGT` |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(build_transition_matrix.__multi__['multiple-populations'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6726f055-32f6-44c2-bd72-f86671e6f86e",
   "metadata": {},
   "source": [
    "Here is an example of how to build a transition matrix when we have 2 populations.\n",
    "\n",
    "In the limit of small mutation rates, the system spends almost all its time in states where each population plays one strategy. Moreover, only a mutant for one population has the opportunity to fixate in that population. This means we only need to consider transitions where the strategy played by one population has changed. Transitions where both populations would have to change strategy occur with probability 0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57c478f-62eb-404e-ad11-170f14f69a23",
   "metadata": {},
   "source": [
    "As we are working with multiple populations, our `models` variable needs to declare this with the `dispatch-type` key.\n",
    "\n",
    "This time, the `payoffs` key must have payoffs for each population. We also need a set of `strategy_contests`, not only a `strategy_set`. `strategy_contests` tells us which strategy profiles are being compared for the relevant transition, which population is affected, and where to find the relevant payoffs for the comparison."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c466975-079c-4db1-ae7f-2a7a77788be2",
   "metadata": {},
   "source": [
    "`payoffs` is a 3D Array containing payoffs for each model, each strategy profile, and each player.\n",
    "\n",
    "**Note:** the above representation can also capture games where multiple players from the same population interact with players from another population (e.g. 2 companies and 1 regulator play an R&D game). This is achieved by noticing that players from the same population receive the same payoffs in a game as their counterparts do if they were to switch strategies (if we had a model with subpopulations, a similar logic applies but this time to each subpopulation rather than the population).\n",
    "\n",
    "**TODO:** the above representation needs to capture games where it is uncertain from which populations players will be sampled from. For example, in some climate change negotiation games, there are rich and poor subpopulations but due to random selection, games may feature all rich, all poor, or some mix of players. An alternative representation which may scale better is to give different symbols to each strategy depending on the subpopulation. In this way, a strategy implicitly informs us from which population the player is from. However, with such a representation, it is essential for `valid_transitions` to describe which strategies must be compared.\n",
    "\n",
    "**Warning:** In games with many players (e.g. > 100), the space of possible strategy profiles can be too large enough to justify storing payoffs in an array. Instead, payoffs will be a function that is called when needed.\n",
    "\n",
    "`valid-transitions` is a dictionary of transitions to information about the relevant players in the contest and the indices of the relevant payoffs for computing the likelihood of the transition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5525de3b-ff8a-4e73-bdda-dbd4da36d319",
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = 10\n",
    "β = 1\n",
    "payoffs = np.array([[[2, 0, 2],\n",
    "                     [3, 1, 3],\n",
    "                     [3, 1, 3],\n",
    "                     [4, 2, 4],\n",
    "                     [2, 0, 2],\n",
    "                     [3, 1, 3],\n",
    "                     [3, 1, 3],\n",
    "                     [4, 2, 4]],\n",
    "                   ])\n",
    "recurrent_state_space = [\"AX\", \"AY\", \"BX\", \"BY\"]\n",
    "valid_transitions = {\"AX->AY\": {\"row_ind\": 0,\n",
    "                                \"col_ind\": 1,\n",
    "                                \"player_index\": 0,  # We need to know which player's payoff matters\n",
    "                                # We need to know where to look for the payoffs\n",
    "                                # of the 4 strategy profiles relevant to deriving\n",
    "                                # the fixation rate for the given transition.\n",
    "                                \"strategy_profile_indices\": {\"AA\": 0, \"AB\": 1,\n",
    "                                                             \"BA\": 2, \"BB\": 3}},\n",
    "                     \"AY->AX\": {\"row_ind\": 1,\n",
    "                                \"col_ind\": 0,\n",
    "                                \"player_index\": 0,\n",
    "                                \"strategy_profile_indices\": {\"AA\": 3, \"AB\": 2,\n",
    "                                                             \"BA\": 1, \"BB\": 0}},\n",
    "                     \"BX->BY\": {\"row_ind\": 2,\n",
    "                                \"col_ind\": 3,\n",
    "                                \"player_index\": 0,\n",
    "                                \"strategy_profile_indices\": {\"AA\": 4, \"AB\": 5,\n",
    "                                                             \"BA\": 6, \"BB\": 7}},\n",
    "                     \"BY->BX\": {\"row_ind\": 3,\n",
    "                                \"col_ind\": 2,\n",
    "                                \"player_index\": 0,\n",
    "                                \"strategy_profile_indices\": {\"AA\": 7, \"AB\": 6,\n",
    "                                                             \"BA\": 5, \"BB\": 4}},\n",
    "                     \n",
    "                     # Regulators do not face each other, so their payoffs do\n",
    "                     # not depend on the number of mutants they see.\n",
    "                     # There are only two strategy profiles to consider, so for\n",
    "                     # compatibility with `build_transition_matrix`, we repeat\n",
    "                     # indices where necessary.\n",
    "                     \n",
    "                     \"AX->BX\": {\"row_ind\": 0,\n",
    "                                \"col_ind\": 2,\n",
    "                                \"player_index\": 2,\n",
    "                                \"strategy_profile_indices\": {\"AA\": 0, \"AB\": 0,\n",
    "                                                             \"BA\": 4, \"BB\": 4,\n",
    "                                                            }},\n",
    "                     \"AY->BY\": {\"row_ind\": 1,\n",
    "                                \"col_ind\": 3,\n",
    "                                \"player_index\": 2,\n",
    "                                \"strategy_profile_indices\": {\"AA\": 3, \"AB\": 3,\n",
    "                                                             \"BA\": 7, \"BB\": 7,\n",
    "                                                            }},\n",
    "                     \"BX->AX\": {\"row_ind\": 2,\n",
    "                                \"col_ind\": 0,\n",
    "                                \"player_index\": 2,\n",
    "                                \"strategy_profile_indices\": {\"AA\": 4, \"AB\": 4,\n",
    "                                                             \"BA\": 0, \"BB\": 0,\n",
    "                                                            }},\n",
    "                     \"BY->AY\": {\"row_ind\": 3,\n",
    "                                \"col_ind\": 1,\n",
    "                                \"player_index\": 2,\n",
    "                                \"strategy_profile_indices\": {\"AA\": 7, \"AB\": 7,\n",
    "                                                             \"BA\": 3, \"BB\": 3,\n",
    "                                                            }},\n",
    "                    }\n",
    "\n",
    "# What if Regulators could transition as a mutant company fixates (independent of the company's chance of fixating)\n",
    "# How do two populations emerge in the first place from one population? \n",
    "# Market games. Number of players of each strategy determines the market price which informs a strategy's average payoff\n",
    "# instead of averaging over the number of players of each strategy.\n",
    "\n",
    "models = {\"dispatch-type\": \"multiple-populations\",\n",
    "          \"β\": β,\n",
    "          \"Z\": Z,\n",
    "          \"recurrent_state_space\": recurrent_state_space,\n",
    "          \"valid_transitions\": valid_transitions,\n",
    "          \"payoffs\": payoffs,\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c08fa6-4519-49cb-80b6-7c1630b15cb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dispatch-type': 'multiple-populations',\n",
       " 'β': 1,\n",
       " 'Z': 10,\n",
       " 'recurrent_state_space': ['AX', 'AY', 'BX', 'BY'],\n",
       " 'valid_transitions': {'AX->AY': {'row_ind': 0,\n",
       "   'col_ind': 1,\n",
       "   'player_index': 0,\n",
       "   'strategy_profile_indices': {'AA': 0, 'AB': 1, 'BA': 2, 'BB': 3}},\n",
       "  'AY->AX': {'row_ind': 1,\n",
       "   'col_ind': 0,\n",
       "   'player_index': 0,\n",
       "   'strategy_profile_indices': {'AA': 3, 'AB': 2, 'BA': 1, 'BB': 0}},\n",
       "  'BX->BY': {'row_ind': 2,\n",
       "   'col_ind': 3,\n",
       "   'player_index': 0,\n",
       "   'strategy_profile_indices': {'AA': 4, 'AB': 5, 'BA': 6, 'BB': 7}},\n",
       "  'BY->BX': {'row_ind': 3,\n",
       "   'col_ind': 2,\n",
       "   'player_index': 0,\n",
       "   'strategy_profile_indices': {'AA': 7, 'AB': 6, 'BA': 5, 'BB': 4}},\n",
       "  'AX->BX': {'row_ind': 0,\n",
       "   'col_ind': 2,\n",
       "   'player_index': 2,\n",
       "   'strategy_profile_indices': {'AA': 0, 'AB': 0, 'BA': 4, 'BB': 4}},\n",
       "  'AY->BY': {'row_ind': 1,\n",
       "   'col_ind': 3,\n",
       "   'player_index': 2,\n",
       "   'strategy_profile_indices': {'AA': 3, 'AB': 3, 'BA': 7, 'BB': 7}},\n",
       "  'BX->AX': {'row_ind': 2,\n",
       "   'col_ind': 0,\n",
       "   'player_index': 2,\n",
       "   'strategy_profile_indices': {'AA': 4, 'AB': 4, 'BA': 0, 'BB': 0}},\n",
       "  'BY->AY': {'row_ind': 3,\n",
       "   'col_ind': 1,\n",
       "   'player_index': 2,\n",
       "   'strategy_profile_indices': {'AA': 7, 'AB': 7, 'BA': 3, 'BB': 3}}},\n",
       " 'payoffs': array([[[2, 0, 2],\n",
       "         [3, 1, 3],\n",
       "         [3, 1, 3],\n",
       "         [4, 2, 4],\n",
       "         [2, 0, 2],\n",
       "         [3, 1, 3],\n",
       "         [3, 1, 3],\n",
       "         [4, 2, 4]]]),\n",
       " 'transition_matrix': array([[[0.65551553, 0.29448447, 0.05      , 0.        ],\n",
       "         [0.00009879, 0.94990121, 0.        , 0.05      ],\n",
       "         [0.05      , 0.        , 0.65551553, 0.29448447],\n",
       "         [0.        , 0.05      , 0.00009879, 0.94990121]]])}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "build_transition_matrix(models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b7387c-e3a6-4aff-bfc4-6ce526a77853",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2068db8-0c99-4932-bdf8-cfe23f6b0594",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
