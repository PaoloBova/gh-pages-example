{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3275141f-78f8-43c7-8a4f-7517dee6f284",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b6efd0-6adb-4de2-8383-2bdc5af68496",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#| export\n",
    "from nbdev.showdoc import *\n",
    "import fastcore.test\n",
    "from gh_pages_example.utils import *\n",
    "import typing\n",
    "\n",
    "import numpy as np\n",
    "import nptyping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c06847-fe93-4fc5-9b91-30f92cc69f3c",
   "metadata": {},
   "source": [
    "# Methods in Evolutionary Game Theory\n",
    "\n",
    "> A set of methods for solving Evolutionary Games (see Nowak 2006 and the references section)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66e4126-c29d-41e8-bce9-54dcabbc63ba",
   "metadata": {},
   "source": [
    "## Evolutionary Dynamics in Finite Populations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8f91a3-f1d3-4ad5-a574-3ab583f1edf5",
   "metadata": {},
   "source": [
    "We examine a finite population of players using different strategies who engage in social learning.\n",
    "\n",
    "In the limit of small mutations, most of the time everyone plays the same strategy. States in which everyone plays the same strategy are known as **monomorphic states**. Occassionally, mutant strategies can fixate in the population, resulting in everyone adopting the same new strategy. We can use Markov Chains to analyse the relative frequencies with which each strategy is played by the population.\n",
    "\n",
    "The steps for computing the ergodic (i.e. long-run, stationary) strategy distribution is as follows:\n",
    "\n",
    "1. Build a transition matrix between all monomorphic states\n",
    "2. Find the ergodic distribution for the markov chain defined using this transition matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb44b7a3-d2ca-4492-b844-5bb9eec99c5c",
   "metadata": {},
   "source": [
    "### Fermi social learning\n",
    "\n",
    "> A Fermi social learning rule means that individuals make pairwise comparisons between their own strategy and and another strategy in the population that they may choose to copy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cab4078-47e3-4468-af4a-742219f3b2c5",
   "metadata": {},
   "source": [
    "#### Derivation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5245cb-1d83-4bbe-8683-96cf42af71a3",
   "metadata": {},
   "source": [
    "Each period of the evolutionary game involves individuals being randomly selected to play against one another individual.\n",
    "\n",
    "Letting $Z$ denote the size of the population, and $π$ denote the game's payoff matrix, we can compute the fitness of a strategy, $B$ for example, when $k$ individuals are of type $B$ as follows:\n",
    "\n",
    "\\begin{equation}\n",
    "ΠB_k = πBA \\frac{k-1}{Z - 1} + πBB \\frac{Z-k}{Z- 1}\n",
    "\\end{equation}\n",
    "\n",
    "where $πBA$ and $πBB$ are the payoffs for playing $B$ against type $A$ or $B$ respectively.\n",
    "\n",
    "The **Fermi social learning rule** adopts strategy $B$ selected from the population over their current strategy $A$ with probability given by:\n",
    "\n",
    "\\begin{equation}\n",
    "Pr(adopt \\, B | k) = \\frac{1}{(1 + \\exp^{-\\beta (ΠB_k - ΠA_k)})}\n",
    "\\end{equation}\n",
    "\n",
    "where $ΠB_k - ΠA_k$ is the relative fitness of strategy $B$ over $A$ in a population with $k$ individuals of type $B$, the rest of type $A$. Notice how the larger the relative fitness, the closer the denominator, and therefore the probability, is to $1$.\n",
    "\n",
    "Using the Fermi social learning rule above, we can write the probability of increasing the number of type $B$ individuals as\n",
    "\n",
    "\\begin{equation}\n",
    "T^+_B(k) = \\frac{Z-k}{Z} \\frac{k}{Z} Pr(adopt \\, B | k) \n",
    "\\end{equation}\n",
    "Z\n",
    "as an individual of type $A$ needs to randomly be chosen to compare their strategy against someone of type $B$.\n",
    "\n",
    "and the probability of decreasing the number of type $B$ individuals as\n",
    "\n",
    "\\begin{equation}\n",
    "T^-_B(k) = \\frac{k}{Z} \\frac{Z-k}{Z} Pr(adopt \\, A | k) \n",
    "\\end{equation}\n",
    "\n",
    "as an individual of type $B$ needs to randomly be chosen to compare their strategy against someone of type $A$.\n",
    "\n",
    "We will often employ their ratio, which is: \n",
    "\n",
    "\\begin{equation}\n",
    "\\frac{T^-_B(k)}{T^+_B(k)} = \\frac{Pr(adopt \\, A | k) }{Pr(adopt \\, B | k)} = \\frac{1 + \\exp^{-\\beta (ΠB_k - ΠA_k)}}{1 + \\exp^{-\\beta (ΠA_k - ΠB_k)}}\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86898d7e-42d1-4ef9-af35-0859f8097c22",
   "metadata": {},
   "source": [
    "#### Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bea9cbf-f84a-4131-893c-47099a4487a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def fermi_learning(β:nptyping.NDArray, # learning rate\n",
    "                   fitnessA:nptyping.NDArray, # fitness of strategy A\n",
    "                   fitnessB:nptyping.NDArray # fitness of strategy B\n",
    "                  ) -> nptyping.NDArray:\n",
    "    \"\"\"Compute the likelihood that a player with strategy B adopts strategy A using the fermi function.\"\"\"\n",
    "    return (1 + np.exp(-β*(fitnessA - fitnessB)))**-1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb62f2bd-4534-4464-9147-de20bf2dc42b",
   "metadata": {},
   "source": [
    "#### Examples and Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fca8e00-f849-490b-b29d-54119b064a2e",
   "metadata": {},
   "source": [
    "When each strategy has the same fitness, then the likelihoodthat a player adopts strategy $A$ is 50%, no matter the value of $\\beta$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678244e2-9597-4d85-96ae-a69211d64539",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = fermi_learning(np.array([1]), \n",
    "                   np.array([5]),\n",
    "                   np.array([5]))\n",
    "nptyping.assert_isinstance(x, nptyping.NDArray[nptyping.Shape[\"1\"], typing.Any])\n",
    "fastcore.test.test_eq(x, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e881f80e-272a-4727-9a46-881e5b51e38f",
   "metadata": {},
   "source": [
    "### Fixation rate\n",
    "\n",
    "> The fixation rate for type B in a population of type A, $\\rho$, is defined as the probability that the appearance of a mutant of type B leads to the entire population adopting type B instead of A, i.e. what is the likelihood that a mutant of type A invades population B."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a01463-b50c-4fd6-aade-8ec965813481",
   "metadata": {},
   "source": [
    "#### Derivation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ffe1bf-842e-4890-b40f-493bd627e9ce",
   "metadata": {},
   "source": [
    "A derivation of the fixation rate defined below can be found in Nowak 2006 (reproduced below).\n",
    "\n",
    "> Consider a one-dimensional stochastic process on a discrete state space, $ i \\in \\{0, 1, \\cdots, N\\}$ that represents the number of individuals in a population of $N$ individuals who are of type $A$, the rest are type $B$.\n",
    ">\n",
    "> In each stochastic event, the number of individuals of type $A$ can at most increase or decrease by 1.\n",
    ">\n",
    "> For a given number of individuals, $i$, let $a_i$, $b_i$, and $1 - a_i - b_i$ represent the chance of an increase, decrease, or no change in $i$.\n",
    "> \n",
    "> This stochastic process follows the transition matrix ,$P$ (*not to be confused with the transition matrices we discuss elsewhere!*)\n",
    ">\n",
    ">\n",
    "> \\begin{equation}\n",
    "P \\, = \\, \\begin{pmatrix}\n",
    "1 & 0 & 0 & \\cdots & 0 & 0 & 0\\\\\n",
    "b_1 & (1 - a_1 - b_1) & a_1 & \\cdots & 0 & 0 & 0\\\\\n",
    "\\vdots & \\vdots & \\vdots & \\ddots & \\vdots & \\vdots & \\vdots\\\\\n",
    "0 & 0 & 0 & \\cdots & b_{n-1} & (1 - a_{n-1} - b_{n-1}) & a_{n-1}\\\\\n",
    "0 & 0 & 0 & \\cdots & 0 & 0 & 1\\\\\n",
    "\\end{pmatrix}\n",
    "\\end{equation}\n",
    ">\n",
    "> Denote by $x_i$ the probability of reaching state $N$ when starting from $i$.\n",
    ">\n",
    "> From transition matrix $P$ above, we can see that $x_i$ must satisfy:\n",
    ">\n",
    "> $x_0 = 0$\n",
    ">\n",
    "> $x_i = b_i x_{i-1} + (1 - a_i - b_i) x_i + a_i x_{i+1}$\n",
    ">\n",
    "> $x_N = 1$\n",
    ">\n",
    "> The fixation rate for a mutant A in a population of type B is clearly $x_1$\n",
    ">\n",
    "> We can solve for $x_i$ by rewriting the above as $b_i x_i - b_i  x_{i-1} = a_i x_{i+1} - a_i x_i$.\n",
    "> \n",
    "> We can denote $y_i = x_i - x_{i-1}$ to simplify the above to $y_{i+1} = \\frac{b_i}{a_i} y_i$\n",
    ">\n",
    "> Notice that $\\sum_{i=1}^N{y_i} = x_N - x_0 = 1$ and that $y_1 = x_1$\n",
    ">\n",
    "> We can use the above to write\n",
    "\\begin{equation}\n",
    "x_1 + {\\sum_{i=2}^N{y_i}} = x_1 (1 + {\\sum_{i=1}^{N-1}{\\prod_{j=1}^{i} \\frac{b_j}{a_j}}}) = 1\n",
    "\\end{equation}\n",
    ">\n",
    "> And so\n",
    "\\begin{equation}\n",
    "x_1 = \\frac{1}{(1 + \\sum_{i=1}^{N-1}{\\prod_{j=1}^{i} \\frac{b_j}{a_j}})}\n",
    "\\end{equation}\n",
    ">\n",
    "> Note that $x_1$ is the fixation rate for a mutant $A$ in a population of type $B$, often denoted as $\\rho$.\n",
    ">\n",
    "> *Also note that $x_{N-1}$ is the fixation rate for a mutant $B$ in a population of type $A$. We could find expressions for all $x_i$ if we note that $x_i = x_1 (1 + \\sum_{j=1}^{i-1}{\\prod_{k=1}^{j} \\frac{b_k}{a_k}})$ (see Nowak 2006 for further details).*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd408dd8-b57b-4fce-9100-758299ea3c18",
   "metadata": {},
   "source": [
    "#### Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4b2af0-7469-4788-bd6b-96d143e27ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "T_type = list[nptyping.NDArray[nptyping.Shape[\"N_models\"], typing.Any]]\n",
    "\n",
    "def fixation_rate(Tplus: T_type, # A list of NDarrays, one array (of size n_models) for each possible number of mutants in the population; the probability of gaining one mutant\n",
    "                  Tneg: T_type, # A list of NDarrays, one array (of size n_models) for each possible number of mutants in the population; the probability of losing one mutant\n",
    "                 ) -> nptyping.NDArray[nptyping.Shape[\"N_models\"], typing.Any]: # Fixation rates for the given strategy in each model\n",
    "    \"\"\"Calculate the likelihood that a mutant invades the population.\"\"\"\n",
    "    Z = len(Tplus) + 1\n",
    "    ρ = (np.sum([np.prod([Tneg[j-1]/Tplus[j-1]\n",
    "                         for j in range(1,i+1)],\n",
    "                        axis=0,\n",
    "                        keepdims=False)\n",
    "                 for i in range(1,Z)],\n",
    "                axis=0,\n",
    "                keepdims=False)\n",
    "        + 1)**-1\n",
    "    return ρ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4236065c-1875-4503-b790-8b59188e13b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/PaoloBova/gh-pages-example/blob/main/gh_pages_example/methods.py#L27){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### fixation_rate\n",
       "\n",
       ">      fixation_rate (Tplus:list[nptyping.base_meta_classes.NDArray],\n",
       ">                     Tneg:list[nptyping.base_meta_classes.NDArray])\n",
       "\n",
       "Calculate the likelihood that a mutant invades the population.\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| Tplus | list | A list of NDarrays, one array (of size n_models) for each possible number of mutants in the population; the probability of gaining one mutant |\n",
       "| Tneg | list | A list of NDarrays, one array (of size n_models) for each possible number of mutants in the population; the probability of losing one mutant |\n",
       "| **Returns** | **NDArray** | **Fixation rates for the given strategy in each model** |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/PaoloBova/gh-pages-example/blob/main/gh_pages_example/methods.py#L27){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### fixation_rate\n",
       "\n",
       ">      fixation_rate (Tplus:list[nptyping.base_meta_classes.NDArray],\n",
       ">                     Tneg:list[nptyping.base_meta_classes.NDArray])\n",
       "\n",
       "Calculate the likelihood that a mutant invades the population.\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| Tplus | list | A list of NDarrays, one array (of size n_models) for each possible number of mutants in the population; the probability of gaining one mutant |\n",
       "| Tneg | list | A list of NDarrays, one array (of size n_models) for each possible number of mutants in the population; the probability of losing one mutant |\n",
       "| **Returns** | **NDArray** | **Fixation rates for the given strategy in each model** |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(fixation_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aeab27b-5b89-424e-981d-0a6d1b161e7e",
   "metadata": {},
   "source": [
    "#### Examples and Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005877f9-bb91-4f68-a982-a5d50ca48f71",
   "metadata": {},
   "source": [
    "When the chance of gaining a mutant always equals the chance of losing a mutant, then the fixation rate will be $\\frac{1}{Z}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be4272f-1d85-416b-b424-53d4d3186b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = 2 # With Z=2, we only need to evaluate Tplus and Tneg for when k=1\n",
    "Tplus_example = [np.array([0.4])]\n",
    "Tneg_example =  [np.array([0.4])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0d9199-f2e7-4dfd-927e-f6c21fc83454",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|  hide\n",
    "# validate test inputs\n",
    "assert len(Tplus_example) == len(Tneg_example)\n",
    "for tplus, tneg in zip(Tplus_example, Tneg_example):\n",
    "    assert tplus.shape == tneg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f41700-0399-4be0-9992-5a111cc086c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fixation_rate_result = fixation_rate(Tplus_example, Tneg_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd36d254-7f82-4f86-bd1f-c5bcd6d679e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fastcore.test.test_eq(fixation_rate_result, np.array([0.5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97469d4-36bf-4d67-9e1f-d39651db1b61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "nptyping.assert_isinstance(fixation_rate_result,\n",
    "                           nptyping.NDArray[nptyping.Shape[\"1\"], typing.Any])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9516d8-2e23-4468-8086-54e4dcd59c8a",
   "metadata": {},
   "source": [
    "When the chance of gaining a mutant is half the chance of losing a mutant, then the fixation rate will be\n",
    "\n",
    "\\begin{equation}\n",
    "\\rho = \\frac{1}{(1 + \\sum_{j=1}^{Z-1}{2^j})}\n",
    "\\end{equation}\n",
    "\n",
    "When $Z=2$, we have $\\rho = \\frac{1}{3}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c929e5-3ab3-48ae-9dba-002c0054f437",
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = 2 # With Z=2, we only need to evaluate Tplus and Tneg for when k=1\n",
    "Tplus_example = [np.array([0.2])]\n",
    "Tneg_example =  [np.array([0.4])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ccc5de-08ce-4d23-bcc4-0f19eb93f390",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|  hide\n",
    "# validate test inputs\n",
    "assert len(Tplus_example) == len(Tneg_example)\n",
    "for i, tplus in enumerate(Tplus_example):\n",
    "    assert tplus.shape == Tneg_example[i].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011ff240-e534-4220-bd37-fb42cb30caa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fixation_rate_result = fixation_rate(Tplus_example, Tneg_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca864e7-693c-4787-9eb7-c3416c5245fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "fastcore.test.test_eq(fixation_rate_result, np.array([1/3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2cff06-3c08-458d-a02a-e68a1c518211",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "nptyping.assert_isinstance(fixation_rate_result,\n",
    "                           nptyping.NDArray[nptyping.Shape[\"1\"], typing.Any])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f635d3-37a5-4969-a784-1875e9486665",
   "metadata": {},
   "source": [
    "We could instead consider an example where we have a mutant Defector (D) who appears in a population of Cooperators (C) playing a standard Prisoner's Dilemma.\n",
    "\n",
    "We will consider an example of such a scenario where chance of gaining/losing a D player be given by $\\frac{1}{1 + e^{\\pm \\beta \\frac{Z+1}{Z-1}}}$.\n",
    "\n",
    "The fixation rate will be given by the following expression:\n",
    "\n",
    "\\begin{equation}\n",
    "\\rho = \\frac{1}{1 + \\sum_{j=1}^{Z-1}{(\\frac{1 + e^{- \\beta \\frac{Z+1}{Z-1}}}{1 + e^{\\beta \\frac{Z+1}{Z-1}}})^j}}\n",
    "\\end{equation}\n",
    "\n",
    "For this example, we will let $\\beta=1$ and $Z=10$, so $\\beta \\frac{Z+1}{Z-1} = \\frac{11}{9}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3006c88-0cde-4e32-934e-59c97c91df6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "β = 1\n",
    "Z = 10\n",
    "ρ_CD = 1 / (1 + sum((1 + np.exp(- β * (Z + 1) / (Z-1)))**j \n",
    "                    / (1 + np.exp(β * (Z + 1) / (Z-1)))**j\n",
    "                    for j in range(1, Z)))\n",
    "Tplus_example = [np.array([1 / (1 + np.exp(- β * (Z + 1) / (Z-1)))])\n",
    "                 for _ in range(Z-1)]\n",
    "Tneg_example =  [np.array([1 / (1 + np.exp(β * (Z + 1) / (Z-1)))])\n",
    "                 for _ in range(Z-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e5b49e-be35-475b-80c1-249b248672dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|  hide\n",
    "# validate test inputs\n",
    "assert len(Tplus_example) == len(Tneg_example)\n",
    "for i, tplus in enumerate(Tplus_example):\n",
    "    assert tplus.shape == Tneg_example[i].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023ec211-bf09-48b8-b14a-1f7d9f2a2e10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "nptyping.assert_isinstance(fixation_rate(Tplus_example, Tneg_example),\n",
    "                           nptyping.NDArray[nptyping.Shape[\"1\"], typing.Any])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfa15aa-41f1-478e-8d5f-edb6f7902064",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fastcore.test.is_close(fixation_rate(Tplus_example, Tneg_example), ρ_CD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c827802-97f6-4bf4-a626-3e8db969fb97",
   "metadata": {},
   "source": [
    "### Build transition matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd8d5bc-dfd0-4a4b-a750-9ecec7fdd117",
   "metadata": {},
   "source": [
    "Recall that step 1 of finding the solution to the Evolutionary Game dynamics is to build a transition matrix between all monomorphic states. \n",
    "\n",
    "The transition matrix captures the probability that if the population of the Evolutionary Game transitions to another state. We read an entry of the transition matrix as saying the probability of transitioning from the row state to column state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932859e9-a0bb-48c3-9853-7ff72c997165",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class ModelTypeEGT():\n",
    "    \"\"\"This is the schema for an Evolutionary Game Theory model.\n",
    "    \n",
    "    Note: This schema is not enforced and is here purely for documentation\n",
    "    purposes.\"\"\"\n",
    "    def __init__(self, \n",
    "                 Z: int, # the size of the population\n",
    "                 strategy_set: list[str], # the set of strategies in the model\n",
    "                 β: nptyping.NDArray, # the learning rate\n",
    "                 payoffs: nptyping.NDArray, # the payoffs of the game\n",
    "                 transition_matrix: nptyping.NDArray=None, # the model's transition matrix\n",
    "                 ergodic: nptyping.NDArray=None, # ergodic distribution of the model's markov chain\n",
    "                ):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61aaa4a8-200c-4bbe-b6bb-34ed13151248",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/PaoloBova/gh-pages-example/blob/main/gh_pages_example/methods.py#L43){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ModelTypeEGT\n",
       "\n",
       ">      ModelTypeEGT (Z:int, strategy_set:list[str], β:nptyping.ndarray.NDArray,\n",
       ">                    payoffs:nptyping.ndarray.NDArray,\n",
       ">                    transition_matrix:nptyping.ndarray.NDArray=None,\n",
       ">                    ergodic:nptyping.ndarray.NDArray=None)\n",
       "\n",
       "This is the schema for an Evolutionary Game Theory model.\n",
       "\n",
       "Note: This schema is not enforced and is here purely for documentation\n",
       "purposes.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| Z | int |  | the size of the population |\n",
       "| strategy_set | list |  | the set of strategies in the model |\n",
       "| β | NDArray |  | the learning rate |\n",
       "| payoffs | NDArray |  | the payoffs of the game |\n",
       "| transition_matrix | NDArray | None | the model's transition matrix |\n",
       "| ergodic | NDArray | None | ergodic distribution of the model's markov chain |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/PaoloBova/gh-pages-example/blob/main/gh_pages_example/methods.py#L43){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ModelTypeEGT\n",
       "\n",
       ">      ModelTypeEGT (Z:int, strategy_set:list[str], β:nptyping.ndarray.NDArray,\n",
       ">                    payoffs:nptyping.ndarray.NDArray,\n",
       ">                    transition_matrix:nptyping.ndarray.NDArray=None,\n",
       ">                    ergodic:nptyping.ndarray.NDArray=None)\n",
       "\n",
       "This is the schema for an Evolutionary Game Theory model.\n",
       "\n",
       "Note: This schema is not enforced and is here purely for documentation\n",
       "purposes.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| Z | int |  | the size of the population |\n",
       "| strategy_set | list |  | the set of strategies in the model |\n",
       "| β | NDArray |  | the learning rate |\n",
       "| payoffs | NDArray |  | the payoffs of the game |\n",
       "| transition_matrix | NDArray | None | the model's transition matrix |\n",
       "| ergodic | NDArray | None | ergodic distribution of the model's markov chain |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(ModelTypeEGT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525269fc-1afe-4e7b-9e72-c7f6f6596cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def build_transition_matrix(models:dict # A dictionary that contains the parameters in `ModelTypeEGT`\n",
    "                           ):\n",
    "    \"\"\"Build a transition matrix between all monomorphic states\n",
    "    using the fermi social learning rule for each model.    \n",
    "    \"\"\"\n",
    "    \n",
    "    Z, S, β = [models[k] for k in ['Z','strategy_set', 'β']]\n",
    "    π = models['payoffs']\n",
    "    n_models = π.shape[0]\n",
    "    M = np.zeros(( n_models, len(S), len(S)))\n",
    "    for row_ind, s in enumerate(S):\n",
    "        for col_ind, sₒ in enumerate(S):\n",
    "            if row_ind == col_ind:\n",
    "                # We compute these entries later\n",
    "                continue\n",
    "            πAA = π[:, row_ind, row_ind]\n",
    "            πAB = π[:, row_ind, col_ind]\n",
    "            πBA = π[:, col_ind, row_ind]\n",
    "            πBB = π[:, col_ind, col_ind]\n",
    "            ΠA = [πAA*(k-1)/(Z-1) + πAB*(Z-k)/(Z-1)\n",
    "                  for k in range(1, Z)]\n",
    "            ΠB = [πBA*k/(Z-1)  + πBB*(Z-k-1)/(Z-1)\n",
    "                  for k in range(1, Z)]\n",
    "            # For numerical stability we ignore the k/Z and (Z-k)/k factors\n",
    "            # in Tplus and Tneg since they cancel out when fermi_learning\n",
    "            # takes their ratio\n",
    "            Tplus = [fermi_learning(β, ΠB[k-1], ΠA[k-1])\n",
    "                     for k in range(1, Z)]\n",
    "            Tneg = [fermi_learning(β, ΠA[k-1], ΠB[k-1])\n",
    "                    for k in range(1, Z)]\n",
    "            # This is the probability that B successfully invades A\n",
    "            ρ = fixation_rate(Tplus, Tneg)\n",
    "            M[:, row_ind, col_ind] = ρ / max(1, len(S)-1)\n",
    "    for row_ind in range(len(S)):\n",
    "        col_inds = [i for i in range(len(S)) if i != row_ind]\n",
    "        no_move = 1 - np.sum(M[:, row_ind, col_inds], axis=1)\n",
    "        M[:, row_ind, row_ind] = no_move\n",
    "    return {**models, \"transition_matrix\": M}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098a1361-4d6c-4eb5-8c6f-6df0a2ab8938",
   "metadata": {},
   "source": [
    "#### Examples and Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25222a93-d57e-47b9-abb6-d1280b5d99a3",
   "metadata": {},
   "source": [
    "Consider the following two examples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b182c962-85a7-4812-aa09-d5a9487909fd",
   "metadata": {},
   "source": [
    "**Example 1**\n",
    "\n",
    "Let all payoffs be equal in the game's payoff matrix. All expected payoffs will be equal too.\n",
    "\n",
    "So, Fermi learning will say that each individual has a 50% chance of adopting the behaviour of the one they observe.\n",
    "\n",
    "We therefore have an equal chance during each epoch of gaining or losing an individual of the given type, in this example we denote the type as $s \\in \\{A, B\\}$, although this probability depends on population size $Z$ and the current number of individuals of that type, $k$, $T^+_s(k) = T^-_s(k) = \\frac{Z-k}{Z} \\frac{k}{Z} \\frac{1}{2}$.\n",
    "\n",
    "Recall that we calculate the fixation rate, $\\rho$ as follows:\n",
    "\\begin{equation}\n",
    "\\rho = \\frac{1}{1 + \\sum_{j=1}^{N-1}{\\prod_{k=1}^{j} \\frac{b_k}{a_k}}}\n",
    "\\end{equation}\n",
    "where $N=Z$, $b_k = T^-_s(k)$ and $a_k = T^+_s(k)$\n",
    "\n",
    "In this example, for each strategy $s$, $T^-_s(k) = T^+_s(k), \\, \\forall k$, so $\\rho = \\frac{1}{Z}$.\n",
    "\n",
    "We only have $2$ strategies, and $Z=10$, so the final transition matrix will look like\n",
    "\n",
    "\\begin{equation}\n",
    "M \\, = \\, \\begin{pmatrix}\n",
    "1 - \\frac{\\rho}{2 - 1} & \\frac{\\rho}{2 - 1} &\\\\\n",
    "\\frac{\\rho}{2 - 1} & 1 - \\frac{\\rho}{2 - 1}\\\\\n",
    "\\end{pmatrix}\n",
    "= \\begin{pmatrix}\n",
    "0.9 & 0.1 &\\\\\n",
    "0.1 & 0.9\\\\\n",
    "\\end{pmatrix}\n",
    "\\end{equation}\n",
    "\n",
    "Note that the above example describes neutral drift, the idea that even if there is no advantage to be gained from any particular strategy, social learning can still result in the spread of that behaviour. Neutral drift also occurs if we set the Fermi learning rate $\\beta = 0$, no matter what payoff matrix describes the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b51afb-7c71-4fed-a636-a67705304ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "payoffs = np.array([[[2, 2],\n",
    "                     [2, 2]]\n",
    "                   ])\n",
    "Z = 10\n",
    "β = 1\n",
    "models = {\"payoffs\": payoffs,\n",
    "          \"Z\": Z,\n",
    "          \"β\": β,\n",
    "          \"strategy_set\": [\"A\", \"B\"],\n",
    "         }\n",
    "result = build_transition_matrix(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d41c9a-9ad4-482f-a003-63eb6477a2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fastcore.test.test_close(result['transition_matrix'],\n",
    "                         np.array([[0.9, 0.1],\n",
    "                                   [0.1, 0.9]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a32d142-e5ae-455d-b782-117edb407a10",
   "metadata": {},
   "source": [
    "**Example 2**\n",
    "\n",
    "Let the payoff matrix be akin to a Prisoner's Dilemma with two strategies, $C$ or $D$ (Cooperate or Defect respectively):\n",
    "\n",
    "\\begin{pmatrix}\n",
    "2 & 0\\\\\n",
    "3 & 1\\\\\n",
    "\\end{pmatrix}\n",
    "\n",
    "Again, for this simple example, the relative average success of strategy $C$ is independent of the number of $C$ players, $k$. This is rarely the case in practise but permits an illustrative example.\n",
    "\n",
    "$C$'s relative success over $D$ will be $\\frac{2 (k-1)}{Z-1} - \\frac{3 k + (Z - k - 1)}{Z-1} = - \\frac{Z + 1}{Z-1}$.\n",
    "\n",
    "Fermi learning means the probability of a $D$ player adopting what they see $C$ do is:\n",
    "\n",
    "\\begin{equation}\n",
    "\\frac{1}{1 + e^{- \\beta (\\Pi_C(k) - \\Pi_D(k))}} = \\frac{1}{1 + e^{\\beta \\frac{Z + 1}{Z-1}}}\n",
    "\\end{equation}\n",
    "\n",
    "The fixation rate for mutant $C$ in a population of $D$ players, $\\rho_{DC}$, can be computed as\n",
    "\n",
    "\\begin{equation}\n",
    "\\rho_{DC} = \\frac{1}{1 + \\sum_{j=1}^{Z-1}{(\\frac{1 + e^{\\beta \\frac{Z + 1}{Z-1}}}{1 + e^{-\\beta \\frac{Z + 1}{Z-1}}})^j}}\n",
    "\\end{equation}\n",
    "\n",
    "Similarly, the fixation rate for mutant $D$ in a population of $C$ players, $\\rho_{CD}$, can be computed as \n",
    "\n",
    "\\begin{equation}\n",
    "\\rho_{CD} = \\frac{1}{1 + \\sum_{j=1}^{Z-1}{(\\frac{1 + e^{-\\beta \\frac{Z + 1}{Z-1}}}{1 + e^{\\beta \\frac{Z + 1}{Z-1}}})^j}}\n",
    "\\end{equation}\n",
    "\n",
    "For $Z=10$ and $\\beta = 1$, the above yields the following transition matrix,\n",
    "\n",
    "\\begin{equation}\n",
    "M \\, = \\, \\begin{pmatrix}\n",
    "1 - \\frac{\\rho_{CD}}{2 - 1} & \\frac{\\rho_{CD}}{2 - 1} &\\\\\n",
    "\\frac{\\rho_{DC}}{2 - 1} & 1 - \\frac{\\rho_{DC}}{2 - 1}\\\\\n",
    "\\end{pmatrix}\n",
    "\\approx \\begin{pmatrix}\n",
    "0.295 & 0.705 &\\\\\n",
    "0.000 & 1.000\\\\\n",
    "\\end{pmatrix}\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e885818-dcfd-4443-9ae3-2c616b8e976e",
   "metadata": {},
   "outputs": [],
   "source": [
    "payoffs = np.array([[[2, 0],\n",
    "                     [3, 1]],\n",
    "                   ])\n",
    "Z = 10\n",
    "β = 1\n",
    "models = {\"payoffs\": payoffs,\n",
    "          \"Z\": Z,\n",
    "          \"β\": β,\n",
    "          \"strategy_set\": [\"C\", \"D\"],\n",
    "         }\n",
    "result = build_transition_matrix(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f9b18d-a668-430f-8fcf-a9702fbfd9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ρ_CD = 1 / (1 + sum((1 + np.exp(- β * (Z + 1) / (Z-1)))**j \n",
    "                    / (1 + np.exp(β * (Z + 1) / (Z-1)))**j\n",
    "                    for j in range(1, Z)))\n",
    "ρ_DC = 1 / (1 + sum((1 + np.exp(β * (Z + 1) / (Z-1)))**j\n",
    "                    / (1 + np.exp(- β * (Z + 1) / (Z-1)))**j \n",
    "                    for j in range(1, Z)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deed5ac3-48a9-47ea-86b8-d3a1135077fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fastcore.test.test_close(result['transition_matrix'],\n",
    "                         np.array([[1- ρ_CD, ρ_CD],\n",
    "                                   [ρ_DC, 1 - ρ_DC]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28cfebf8-5411-4d33-89b6-cf010a272b93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/PaoloBova/gh-pages-example/blob/main/gh_pages_example/methods.py#L76){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### build_transition_matrix\n",
       "\n",
       ">      build_transition_matrix (models:dict)\n",
       "\n",
       "Build a transition matrix between all monomorphic states\n",
       "using the fermi social learning rule for each model.\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| models | dict | A dictionary that contains the parameters in `ModelTypeEGT` |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/PaoloBova/gh-pages-example/blob/main/gh_pages_example/methods.py#L76){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### build_transition_matrix\n",
       "\n",
       ">      build_transition_matrix (models:dict)\n",
       "\n",
       "Build a transition matrix between all monomorphic states\n",
       "using the fermi social learning rule for each model.\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| models | dict | A dictionary that contains the parameters in `ModelTypeEGT` |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(build_transition_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf604f74-2729-4ac9-bbfc-f1cf1fa4a9fc",
   "metadata": {},
   "source": [
    "### Find ergodic strategy distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aced671-f623-440b-ab31-c0d200ee0729",
   "metadata": {},
   "source": [
    "Step 2 is to find the ergodic distribution for the Evolutionary Game using the transition matrix we constructed in step 1.\n",
    "\n",
    "Let $M$ denote the transition matrix, and $\\omega_t$ be the column vector describing the proportions with which each strategy is played in the population.\n",
    "\n",
    "We can describe the evolution of this system with $\\omega_{t+1} = M^T \\omega_t$, i.e. the proportion of players that use a given strategy in the next round will be equal to the sum of the proportions of players for each strategy who adopted that strategy in the current round. Equivalently, we can also consider $\\omega_t$ as describing the probabilities that the system at time t is in each of the monomorphic states.\n",
    "\n",
    "As each of the monomporphic states described in the transition matrix is reachable from any other with some probability and since the transition probabilities only depend on the current state, what we have is a markov chain which is irreducible.\n",
    "\n",
    "The ergodicity theorem guarantees that such irreducible and aperiodic markov chains have an ergodic distribution that the system converges to, no matter where it starts. An ergodic distribution (also called a stationary distribution),  $\\omega^*$ satisfies  $\\omega^* = M^T \\omega^*$ [[1]](https://gregorygundersen.com/blog/2019/10/28/ergodic-markov-chains/) [[2]](http://www.stat.columbia.edu/~liam/teaching/neurostat-spr11/papers/mcmc/Ergodicity_Theorem.pdf).\n",
    "\n",
    "Our ergodic distribution, $\\omega^*$, is therefore defined as the normalised right-hand eigenvector with eigenvalue 1 of the transposed transition matrix, $M^T$ (or equivalently, if we defined $\\omega$ as a row vector instead, $\\omega^*$ would be the left-hand eigenvector with eigenvalue 1 of transition matrix, $M$; numerical computing packages usually return the right-hand eigenvectors more directly, which is why I used the other formalism).\n",
    "\n",
    "We use standard linear algebra methods from the [numpy](https://numpy.org/) package to find this eigenvector. These numerical methods will usually not return an eigenvector which is normalised to sum to 1, so we must normalise the eigenvector we are given. See their documentation to learn more about these numerical methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c98786-9d06-4471-b322-a90e521e6fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def find_ergodic_distribution(models):\n",
    "    \"\"\"Find the ergodic distribution of a markov chain with the\n",
    "    given transition matrix.\"\"\"\n",
    "    \n",
    "    M = models[\"transition_matrix\"]\n",
    "    # find unit eigenvector of markov chain\n",
    "    Λ,V = np.linalg.eig(M.transpose(0,2,1))\n",
    "    x = np.isclose(Λ, 1)\n",
    "    # if multiple unit eigenvalues then choose the first\n",
    "    y = np.zeros_like(x, dtype=bool)\n",
    "    idx = np.arange(len(x)), x.argmax(axis=1)\n",
    "    y[idx] = x[idx]\n",
    "    ergodic = np.array(V.transpose(0,2,1)[y], dtype=float)\n",
    "    # ensure ergodic frequencies are positive and sum to 1\n",
    "    ergodic = np.abs(ergodic) / np.sum(np.abs(ergodic), axis=1)[:, None]\n",
    "    return {**models, 'ergodic':ergodic}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0249dbbc-12f1-4cee-8488-c5f755216cf9",
   "metadata": {},
   "source": [
    "#### Examples and Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb2ae7f-f94f-4b54-90eb-ec4af9077aba",
   "metadata": {},
   "source": [
    "Let our transition matrix, $M$ be\n",
    "\n",
    "\\begin{equation}\n",
    "M = \\begin{pmatrix}\n",
    "\\frac{3}{4} & \\frac{1}{4} \\\\\n",
    "\\frac{1}{4} & \\frac{3}{4} \\\\\n",
    "\\end{pmatrix}\n",
    "\\end{equation}\n",
    "\n",
    "Note that $M^T$ is a stochastic matrix because each column of the transposed matrix would sum to $1$ (in general the rows of the transposed matrix are unlikely to sum to 1, but choosing an example like the above makes it easy to compute the eigenvectors).\n",
    "\n",
    "It's not too hard to verify that the characteristic polynomial of $M^T$ can be factored into $(\\lambda - 1)(\\lambda - \\frac{1}{2})$, so we have two eigenvalues, $1$ and $\\frac{1}{2}$.\n",
    "\n",
    "It's not too hard to verify that column vector $[1, 1]$ is the eigenvector of $M^T$ with eigenvalue $1$\n",
    ".\n",
    "\n",
    "Now that we know the weights placed on each strategy, we can compute the strategy distribution by normalising our eigenvector.\n",
    "\n",
    "The ergodic distribution i $\\omega^* = [\\frac{1}{2}, \\frac{1}{2}]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ac241d-d8c9-40f6-ad80-0ddb81b00e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "M = np.array([[[3/4, 1/4],\n",
    "               [1/4, 3/4]],\n",
    "             ])\n",
    "models = {\"transition_matrix\": M}\n",
    "result = find_ergodic_distribution(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc0de01-3983-48c1-956f-3c686c4d27b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fastcore.test.test_eq(result['ergodic'],\n",
    "                      np.array([[1/2, 1/2]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94604c8-2f2b-46d5-8234-334635abd500",
   "metadata": {},
   "source": [
    "Here is another quick illustrative example.\n",
    "\n",
    "Let our transition matrix, $M$ be\n",
    "\n",
    "\\begin{equation}\n",
    "M = \\begin{pmatrix}\n",
    "\\frac{3}{4} & \\frac{1}{4} \\\\\n",
    "\\frac{3}{4} & \\frac{1}{4} \\\\\n",
    "\\end{pmatrix}\n",
    "\\end{equation}\n",
    "\n",
    "$M^T$ is a stochastic matrix. It is easy to verify that $[\\frac{3}{4}, \\frac{1}{4}]$ is the normalised eigenvector with eigenvalue 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ae7587-ea91-4a61-a316-35563ea0222f",
   "metadata": {},
   "outputs": [],
   "source": [
    "M = np.array([[[3/4, 1/4],\n",
    "               [3/4, 1/4]],\n",
    "             ])\n",
    "models = {\"transition_matrix\": M}\n",
    "result = find_ergodic_distribution(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8543490-6385-4b3b-9801-9229a54cb053",
   "metadata": {},
   "outputs": [],
   "source": [
    "fastcore.test.test_eq(result['ergodic'],\n",
    "                      np.array([[3/4, 1/4]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27968b3f-8b47-4298-b6e6-1020c894e8ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/PaoloBova/gh-pages-example/blob/main/gh_pages_example/methods.py#L115){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### find_ergodic_distribution\n",
       "\n",
       ">      find_ergodic_distribution (models)\n",
       "\n",
       "Find the ergodic distribution of a markov chain with the\n",
       "given transition matrix."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/PaoloBova/gh-pages-example/blob/main/gh_pages_example/methods.py#L115){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### find_ergodic_distribution\n",
       "\n",
       ">      find_ergodic_distribution (models)\n",
       "\n",
       "Find the ergodic distribution of a markov chain with the\n",
       "given transition matrix."
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(find_ergodic_distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d870ac66-b641-434b-bb9a-27df3577eecf",
   "metadata": {},
   "source": [
    "### Run full markov chain algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9cd9f0e-f1e5-459a-b7a9-829c11bfc7e9",
   "metadata": {},
   "source": [
    "Finally, here is a helper function to both build the transition matrix for the model and find its ergodic distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe4a9b3-6248-4f70-9694-820307de7b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def markov_chain(models):\n",
    "    \"\"\"Find the ergodic distribution of the evolutionary\n",
    "    game given by each model in models.\"\"\"\n",
    "    return thread_macro(models,\n",
    "                        build_transition_matrix,\n",
    "                        find_ergodic_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0fb6f2-cb09-4a98-ac1c-f91aa1b292f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/PaoloBova/gh-pages-example/blob/main/gh_pages_example/methods.py#L133){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### markov_chain\n",
       "\n",
       ">      markov_chain (models)\n",
       "\n",
       "Find the ergodic distribution of the evolutionary\n",
       "game given by each model in models."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/PaoloBova/gh-pages-example/blob/main/gh_pages_example/methods.py#L133){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### markov_chain\n",
       "\n",
       ">      markov_chain (models)\n",
       "\n",
       "Find the ergodic distribution of the evolutionary\n",
       "game given by each model in models."
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(markov_chain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b7387c-e3a6-4aff-bfc4-6ce526a77853",
   "metadata": {},
   "source": [
    "# Notebook Footer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2068db8-0c99-4932-bdf8-cfe23f6b0594",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
