{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Payoff Matrices (part 1)\n",
    "\n",
    "> This module contains payoff matrices for different evolutionary games\n",
    ">\n",
    "> Part 1 contains payoff matrices for the following games\n",
    "> - DSAIR\n",
    "> - DSAIR with peer punishment or reward\n",
    "> - DSAIR with voluntary commitments\n",
    ">\n",
    "> Note that all of the payoff matrices here are replications of the models from The Anh et al. 2020, 2021, 2022."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp payoffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *\n",
    "from gh_pages_example.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "import nptyping\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DSAIR Model Paramaters\n",
    "\n",
    "| keyword | value type | range | optional | description | \n",
    "|---------|------------|-------|----------|-------------|\n",
    "| b | NDArray | b > 0| | The size of the per round benefit of leading the AI development race|\n",
    "| c | NDArray | c > 0| | The cost of implementing safety recommendations per round|\n",
    "| s | NDArray | s > 1| | The speed advantage from choosing to ignore safety recommendations|\n",
    "| p | NDArray | [0, 1]| | The probability that unsafe firms avoid an AI disaster|\n",
    "| B | NDArray | B >> b| | The size of the prize from winning the AI development race|\n",
    "| W | NDArray | $$[10, 10^6]$$| | The anticipated timeline until the development race has a winner if everyone behaves safely|\n",
    "| pfo | NDArray | [0, 1]|Yes| The probability that firms who ignore safety precautions are found out|\n",
    "| ϵ | NDArray | ϵ > 0|Yes| The cost of setting up a voluntary commitment|\n",
    "| ω | NDArray | [0, 1]|Yes| Noise in arranging an agreement, with some probability they fail to succeed in making an agreement|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DSAIR Payoff Matrix (Short Run)\n",
    "\n",
    "| Strategy | Safe | Unsafe |\n",
    "|----------|---|---|\n",
    "| **Safe** | $$\\frac{b}{2} - c$$|  $$\\frac{b}{s+1} - c$$ |\n",
    "| **Unsafe** | $$b \\frac{s}{s+1}$$| $$\\frac{b}{2} $$|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def payoffs_sr(models):\n",
    "    \"\"\"The short run payoffs for the DSAIR game.\"\"\"\n",
    "    s, b, c = [models[k] for k in ['s', 'b', 'c']]\n",
    "    πAA = -c + b/2\n",
    "    πAB = -c + b/(s+1)\n",
    "    πBA = s*b/(s+1)\n",
    "    πBB = b/2\n",
    "    matrix = np.block([[πAA, πAB], \n",
    "                       [πBA, πBB]])\n",
    "    return {**models, 'payoffs_sr':matrix}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DSAIR Payoff Matrix (Short Run) with probability of being found out\n",
    "\n",
    "| Strategy | Safe | Unsafe |\n",
    "|----------|---|---|\n",
    "| **Safe** | $$\\frac{b}{2} - c$$|  $$(1 - p_{fo}) \\frac{b}{s+1} + p_{fo} b - c$$ |\n",
    "| **Unsafe** | $$ (1 - p_{fo}) b \\frac{s}{s+1}$$| $$(1 - p_{fo}^2) \\frac{b}{2} $$|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def payoffs_sr_pfo_extension(model):\n",
    "    \"\"\"The short run payoffs for the DSAIR game with a chance of unsafe\n",
    "    behaviour being spotted.\"\"\"\n",
    "    s, b, c, pfo = [model[k] for k in ['s', 'b', 'c', 'pfo']]\n",
    "    πAA =  -c + b/2\n",
    "    πAB = -c + b/(s+1) * (1 - pfo) + pfo * b\n",
    "    πBA = (1 - pfo) * s * b / (s+1)\n",
    "    πBB = (1 - pfo**2) * b/2\n",
    "    matrix = np.block([[πAA, πAB],\n",
    "                       [πBA, πBB]])\n",
    "    return {**model, 'payoffs_sr':matrix}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DSAIR Payoff Matrix (Long Run)\n",
    "\n",
    "Denote $\\pi$ as one of the short run payoff matrices discussed above with rows and columns indexed by letters A, B, ...\n",
    "\n",
    "| Strategy | Always Safe | Always Unsafe |\n",
    "|----------|---|---|\n",
    "| **Always Safe** | $$πAA + \\frac{B}{2W}$$|  $$πAB$$ |\n",
    "| **Always Unsafe** | $$p \\, (s \\frac{B}{W} + πBA)$$| $$p \\, (s \\frac{B}{2W} + πBB)$$|\n",
    "\n",
    "*Note: In a model where we suffer a collective risk of an AI disaster if the winner is unsafe, payoffs for firms who play safe when facing an unsafe firm are also multiplied by $p$.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def payoffs_lr(model):\n",
    "    \"\"\"The long run average payoffs for the DSAIR game.\"\"\"\n",
    "    s, p, B, W = [model[k] for k in ['s', 'p', 'B', 'W']]\n",
    "    πAA,πAB,πBA,πBB = [model['payoffs_sr'][:,[i],[j]]\n",
    "                       for i in range(2) for j in range(2)]\n",
    "    πAA = πAA + B/(2*W)\n",
    "    πAB = πAB\n",
    "    πBA = p*(s*B/W + πBA)\n",
    "    πBB = p*(s*B/(2*W) + πBB)\n",
    "    payoffs = np.block([[πAA, πAB],\n",
    "                        [πBA, πBB]])\n",
    "    return {**model, 'payoffs': payoffs}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DSAIR Payoff Matrix with punishments (Long Run)\n",
    "\n",
    "Denote $\\pi$ as one of the short run payoff matrices discussed above with rows and columns indexed by letters A, B, ...\n",
    "\n",
    "**Always Safe** and **Always Unsafe** play as they usually do.\n",
    "\n",
    "**Punish Unsafe** always plays Safe. However, they will pay a cost to punish their co-player if the co-player plays Unsafe.\n",
    "\n",
    "\n",
    "| Strategy | Always Safe | Always Unsafe | Punish Unsafe |\n",
    "|----------|---|---|---|\n",
    "| **Always Safe** | $$πAA + \\frac{B}{2W}$$|  $$πAB$$ | $$πAA + \\frac{B}{2W}$$ |\n",
    "| **Always Unsafe** | $$p \\, (s \\frac{B}{W} + πBA)$$| $$p \\, (s \\frac{B}{2W} + πBB)$$| punished_payoff|\n",
    "| **Punish Unsafe** | $$πAA + \\frac{B}{2W}$$| sanctioner_payoff | $$πAA + \\frac{B}{2W}$$ |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def payoffs_lr_peer_punishment(model):\n",
    "    \"\"\"The long run average payoffs for the DSAIR game with peer punishment.\"\"\"\n",
    "    s,b,c, p, B, W = [model[k] for k in ['s', 'b', 'c', 'p', 'B', 'W']]\n",
    "    α, γ, ϵ = [model[k] for k in ['α', 'γ', 'ϵ']]\n",
    "    πAA,πAB,πBA,πBB = [model['payoffs_sr'][:,[i],[j]]\n",
    "                       for i in range(2) for j in range(2)]\n",
    "    \n",
    "    s_punished = s - γ\n",
    "    s_sanctioner = s - α\n",
    "    punished_wins = (s > γ) & ((W-s)/(s-γ) <= (W-1)/(s-α))\n",
    "    punished_draws = (s > γ) & ((W-s)/(s-γ) == (W-1)/(s-α))\n",
    "    sanctioner_wins = (s > α) & ((W-s)/(s-γ) >= (W-1)/(s-α))\n",
    "    no_winner = (s_punished <= 0) & (s_sanctioner <= 0)\n",
    "\n",
    "    both_speeds_positive = (s_punished > 0) & (s_sanctioner > 0)\n",
    "    only_sanctioner_speed_positive = (s_punished <= 0) & (s_sanctioner > 0)\n",
    "    only_punisher_speed_positive = (s_punished > 0) & (s_sanctioner <= 0)\n",
    "\n",
    "    p_loss = np.where(punished_wins | punished_draws, p, 1)\n",
    "    R = np.where(no_winner,\n",
    "                 np.inf,\n",
    "                 1 + np.minimum((W-s)/ np.maximum(s_punished, 1e-10),\n",
    "                                (W-1)/ np.maximum(s_sanctioner, 1e-10)))\n",
    "    B_s = np.where(sanctioner_wins, B, np.where(punished_draws, B/2, 0))\n",
    "    B_p = np.where(punished_wins, B, np.where(punished_draws, B/2, 0))\n",
    "    b_s = np.where(both_speeds_positive,\n",
    "                   b * (s - α)/(s-γ + s - α),\n",
    "                   np.where(only_sanctioner_speed_positive, b, 0))\n",
    "    b_p = np.where(both_speeds_positive,\n",
    "                   b * (s - γ)/(s-γ + s - α),\n",
    "                   np.where(only_punisher_speed_positive, b, 0))\n",
    "\n",
    "    sanctioner_payoff = (1 / R) * (πAB + B_s + (R-1)*(b_s - c)) - ϵ\n",
    "    punished_payoff = (p_loss / R) * (πBA + B_p + (R-1)*b_p) - ϵ\n",
    "    \n",
    "    ΠAA = πAA + B/(2*W)\n",
    "    ΠAB = p*(s*B/W + πBA)\n",
    "    ΠAC = πAA + B/(2*W)\n",
    "    ΠBA = p*(s*B/W + πBA)\n",
    "    ΠBB = p*(s*B/(2*W) + πBB)\n",
    "    ΠBC = punished_payoff\n",
    "    ΠCA = πAA + B/(2*W)\n",
    "    ΠCB = sanctioner_payoff\n",
    "    ΠCC = πAA + B/(2*W)\n",
    "    matrix = np.block([[ΠAA, ΠAB, ΠAC], \n",
    "                       [ΠBA, ΠBB, ΠBC],\n",
    "                       [ΠCA, ΠCB, ΠCC],\n",
    "                       ])\n",
    "    return {**model, 'payoffs':matrix}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Expressions for the sanctioner and punished payoffs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For convenience we denote a number of new variables to simplify the expressions for the sanctioner and punished payoffs.\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{sanctioner payoff} = \\frac{1}{R} (\\pi AB + B_s + (R-1) (b_s - c))\\\\\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{punished payoff} = \\frac{p_{punish}}{R} (πBA + B_p + (R-1) b_p)\\\\\n",
    "\\end{equation}\n",
    "\n",
    "*Note: In a model where we suffer a collective risk of an AI disaster if the winner is unsafe, payoffs for firms who play safe when facing an unsafe firm are also multiplied by $p_{punish}$.*\n",
    "\n",
    "We can read the above payoffs as telling us the average payoffs over the R rounds of the race for each firm, assuming the punishment is levied at the end of the first round and the remaining $R - 1$ rounds are played with the punishment in effect.\n",
    "\n",
    "Note that $s_{\\beta}$ denotes the new speed of the firm who is punished and $s_{\\alpha}$ as the speed of the firm who levies the punishment.\n",
    "\n",
    "Below we denote the four possible outcomes (ignoring disaster) of a race between a sanctioner and a punished firm:\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{punished wins} = (s_{\\beta} > 0) \\, \\& \\, (\\frac{W-s}{s_{\\beta}} <= \\frac{W-1}{s_{\\alpha}})\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{sanctioner wins} = (s_{\\alpha} > 0) \\, \\& \\, (\\frac{W-1}{s_{\\alpha}} <= \\frac{W-s}{s_{\\beta}})\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{draw} = (s_{\\beta} > 0) \\, \\& \\, (\\frac{W-s}{s_{\\beta}} = \\frac{W-1}{s_{\\alpha}})\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{no winner} = (s_{\\beta} <= 0)  \\, \\& \\,  (s_{\\alpha} <= 0)\n",
    "\\end{equation}\n",
    "\n",
    "We can use the above expressions to define the following variables:\n",
    "\n",
    "$p_{punish}$ is the probability of avoiding an AI disaster if a punishment is levied and depends on who wins the race.\n",
    "\n",
    "\\begin{equation}\n",
    "p_{punish} = \\begin{cases} 0 & \\text{sanctioner wins | no winner} \\\\\n",
    "p & otherwise\n",
    "\\end{cases}\n",
    "\\end{equation}\n",
    "\n",
    "$R$ is the number of rounds that the race lasts for; the race ends when the first firm reaches the finish line.\n",
    "\n",
    "\\begin{equation}\n",
    "R = \\begin{cases} \\infty & \\text{no winner} \\\\\n",
    "\\frac{W - 1}{s_{\\alpha}} & \\text{sanctioner wins} \\\\\n",
    "\\frac{W - s}{s_{\\beta}} & \\text{punished wins | draw} \\\\\n",
    "\\end{cases}\n",
    "\\end{equation}\n",
    "\n",
    "$B_s$ is the prize that the sanctioner receives at the end of the race.\n",
    "\n",
    "\\begin{equation}\n",
    "B_s = \\begin{cases} B & \\text{sanctioner wins} \\\\\n",
    "\\frac{B}{2} & \\text{draw} \\\\\n",
    "0 & otherwise \\\\\n",
    "\\end{cases}\n",
    "\\end{equation}\n",
    "\n",
    "$B_p$ is the prize that the punished receives at the end of the race.\n",
    "\n",
    "\\begin{equation}\n",
    "B_p = \\begin{cases} B & \\text{punished wins} \\\\\n",
    "\\frac{B}{2} & \\text{draw} \\\\\n",
    "0 & otherwise \\\\\n",
    "\\end{cases}\n",
    "\\end{equation}\n",
    "\n",
    "$b_s$ is the benefit the sanctioner receives each round, they only gain a benefit if their speed is positive but gain the whole benefit if they are the only firm with positive speed.\n",
    "\n",
    "\\begin{equation}\n",
    "b_s = \\begin{cases} p_{fo} b + (1-p_{fo}) b \\frac{s_{\\alpha}}{s_{\\alpha} + s_{\\beta}} & s_{\\alpha}, s_{\\beta} > 0\\\\\n",
    "b & s_{\\alpha} > 0 >= s_{\\beta} \\\\\n",
    "0 & s_{\\alpha} <= 0 \\\\\n",
    "\\end{cases}\n",
    "\\end{equation}\n",
    "\n",
    "$b_p$ is the benefit the punished receives each round, they only gain a benefit if their speed is positive but gain the whole benefit if they are the only firm with positive speed.\n",
    "\n",
    "\\begin{equation}\n",
    "b_p = \\begin{cases} (1-p_{fo}) b \\frac{s_{\\beta}}{s_{\\alpha} + s_{\\beta}} & s_{\\alpha}, s_{\\beta} > 0\\\\\n",
    "b & s_{\\beta} > 0 >= s_{\\alpha} \\\\\n",
    "0 & s_{\\beta} <= 0 \\\\\n",
    "\\end{cases}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DSAIR Payoff Matrix with rewards (Long Run)\n",
    "\n",
    "Denote $\\pi$ as one of the short run payoff matrices discussed above with rows and columns indexed by letters A, B, ...\n",
    "\n",
    "**Always Safe** and **Always Unsafe** play as they usually do.\n",
    "\n",
    "**Reward Safe** always plays Safe. However, they will pay a cost to reward their co-player if the co-player plays Safe.\n",
    "\n",
    "| Strategy | Always Safe | Always Unsafe | Reward Safe |\n",
    "|----------|---|---|---|\n",
    "| **Always Safe** | $$πAA + \\frac{B}{2W}$$|  $$πAB$$ | $$πAA + \\frac{B (1 + s_{\\beta})}{W}$$ |\n",
    "| **Always Unsafe** | $$p \\, (s \\frac{B}{W} + πBA)$$| $$p \\, (s \\frac{B}{2W} + πBB)$$| $$p \\, (s \\frac{B}{W} + πBA)$$|\n",
    "| **Reward Safe** | $$ πAA $$| $$ πAB $$| $$πAA + \\frac{B (1 + s_{\\beta} - s_{\\alpha})}{2W}$$ |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def payoffs_lr_peer_reward(model):\n",
    "    \"\"\"The long run average payoffs for the DSAIR game with peer punishment.\"\"\"\n",
    "    s,b,c, p, B, W = [model[k] for k in ['s', 'b', 'c', 'p', 'B', 'W']]\n",
    "    α, γ, ϵ = [model[k] for k in ['α', 'γ', 'ϵ']]\n",
    "    πAA,πAB,πBA,πBB = [model['payoffs_sr'][:,[i],[j]]\n",
    "                       for i in range(2) for j in range(2)]\n",
    "    \n",
    "    s_rewarded = s + γ\n",
    "    s_helper = s - α\n",
    "    ΠAA = πAA + B/(2*W)\n",
    "    ΠAB = p*(s*B/W + πBA)\n",
    "    ΠAC = πAA + B * s_rewarded / ((s_rewarded + s_helper) * W)\n",
    "    ΠBA = p*(s*B/W + πBA)\n",
    "    ΠBB = p*(s*B/(2*W) + πBB)\n",
    "    ΠBC = p*(s*B/W + πBA)\n",
    "    ΠCA = πAA\n",
    "    ΠCB = πAB\n",
    "    ΠCC = πAA + B * (1 + s_rewarded - s_helper)/(2*W)\n",
    "    matrix = np.block([[ΠAA, ΠAB, ΠAC], \n",
    "                       [ΠBA, ΠBB, ΠBC],\n",
    "                       [ΠCA, ΠCB, ΠCC],\n",
    "                       ])\n",
    "    return {**model, 'payoffs':matrix}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DSAIR Payoff Matrix with voluntary commitments (Long Run)\n",
    "\n",
    "Denote $\\pi$ as one of the short run payoff matrices discussed above with rows and columns indexed by letters A, B, ...\n",
    "\n",
    "The strategies below are less obvious than in earlier models. **Always Safe Out** and **Always Unsafe Out** are the same strategies we are used to.\n",
    "\n",
    "**Always Safe In** is willing to form a commitment to play Safe. Otherwise, they will always play Unsafe.\n",
    "\n",
    "**Always Unsafe In** is willing to form a commitment but will violate it by always playing Unsafe. This way, they anticipate that they can encourage other firms to play safe and so pull ahead of them in the race.\n",
    "\n",
    "**Punish Violator** is willing to form a commitment to play Safe. Otherwise, they will always play Unsafe. If the coparty to the commitment violates the commitment by playing Unsafe, then this player pays a cost to levy a punishment on the violator.\n",
    "\n",
    "| Strategy| Always Safe Out | Always Unsafe Out |  Always Safe In | Always Unsafe In  | Punish Violator |\n",
    "|----------|---|---|---|---|---|\n",
    "| **Always Safe Out** | $$πAA + \\frac{B}{2W}$$| $$πAB$$ | $$πAB$$ | $$πAB$$ | $$πAB$$|\n",
    "| **Always Unsafe Out** | $$p \\, (s \\frac{B}{W} + πBA)$$| $$p \\, (s \\frac{B}{2W} + πBB)$$| $$p \\, (s \\frac{B}{2W} + πBB)$$| $$p \\, (s \\frac{B}{2W} + πBB)$$ | $$p \\, (s \\frac{B}{2W} + πBB)$$ |\n",
    "| **Always Safe In** | $$p \\, (s \\frac{B}{W} + πBA)$$|  $$p \\, (s \\frac{B}{2W} + πBB)$$ | $$πAA + \\frac{B}{2W} - \\epsilon$$| $$πAB - \\epsilon$$| $$πAA + \\frac{B}{2W} - \\epsilon$$ |\n",
    "| **Always Unsafe In** | $$p \\, (s \\frac{B}{W} + πBA)$$| $$p \\, (s \\frac{B}{2W} + πBB)$$| $$p \\, (s \\frac{B}{W} + πBA) - \\epsilon$$| $$p \\, (s \\frac{B}{2W} + πBB) - \\epsilon$$ | punished_payoff - ϵ |\n",
    "| **Punish Violator** | $$p \\, (s \\frac{B}{W} + πBA)$$| $$p \\, (s \\frac{B}{2W} + πBB)$$| $$πAA + \\frac{B}{2W} - \\epsilon$$ | sanctioner_payoff - ϵ| $$πAA + \\frac{B}{2W} - \\epsilon$$ |\n",
    "\n",
    "The punished and sanctioner payoffs above are exactly the same as in the model with punishments above, so I do not repeat this here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def payoffs_lr_voluntary(model):\n",
    "    \"\"\"The long run average payoffs for the DSAIR game with voluntary\n",
    "    commitments.\"\"\"\n",
    "    s,b,c, p, B, W = [model[k] for k in ['s', 'b', 'c', 'p', 'B', 'W']]\n",
    "    α, γ, ϵ = [model[k] for k in ['α', 'γ', 'ϵ']]\n",
    "    πAA,πAB,πBA,πBB = [model['payoffs_sr'][:,[i],[j]]\n",
    "                       for i in range(2) for j in range(2)]\n",
    "    \n",
    "    s_punished = s - γ\n",
    "    s_sanctioner = s - α\n",
    "    punished_wins = (s > γ) & ((W-s)/(s-γ) <= (W-1)/(s-α))\n",
    "    punished_draws = (s > γ) & ((W-s)/(s-γ) == (W-1)/(s-α))\n",
    "    sanctioner_wins = (s > α) & ((W-s)/(s-γ) >= (W-1)/(s-α))\n",
    "    no_winner = (s_punished <= 0) & (s_sanctioner <= 0)\n",
    "\n",
    "    both_speeds_positive = (s_punished > 0) & (s_sanctioner > 0)\n",
    "    only_sanctioner_speed_positive = (s_punished <= 0) & (s_sanctioner > 0)\n",
    "    only_punisher_speed_positive = (s_punished > 0) & (s_sanctioner <= 0)\n",
    "\n",
    "    p_punish = np.where(punished_wins | punished_draws, p, 1)\n",
    "    R = np.where(no_winner,\n",
    "                 np.inf,\n",
    "                 1 + np.minimum((W-s)/ np.maximum(s_punished, 1e-10),\n",
    "                                (W-1)/ np.maximum(s_sanctioner, 1e-10)))\n",
    "    B_s = np.where(sanctioner_wins, B, np.where(punished_draws, B/2, 0))\n",
    "    B_p = np.where(punished_wins, B, np.where(punished_draws, B/2, 0))\n",
    "    b_s = np.where(both_speeds_positive,\n",
    "                   b * (s - α)/(s-γ + s - α),\n",
    "                   np.where(only_sanctioner_speed_positive, b, 0))\n",
    "    b_p = np.where(both_speeds_positive,\n",
    "                   b * (s - γ)/(s-γ + s - α),\n",
    "                   np.where(only_punisher_speed_positive, b, 0))\n",
    "\n",
    "    sanctioner_payoff = (1 / R) * (πAB + B_s + (R-1)*(b_s - c)) - ϵ\n",
    "    punished_payoff = (p_punish / R) * (πBA + B_p + (R-1)*b_p) - ϵ\n",
    "    \n",
    "    ΠAA = πAA + B/(2*W)\n",
    "    ΠAB = πAB\n",
    "    ΠAC = πAB\n",
    "    ΠAD = πAB\n",
    "    ΠAE = πAB\n",
    "    ΠBA = p*(s*B/W + πBA)\n",
    "    ΠBB = p*(s*B/(2*W) + πBB)\n",
    "    ΠBC = p*(s*B/(2*W) + πBB)\n",
    "    ΠBD = p*(s*B/(2*W) + πBB)\n",
    "    ΠBE = p*(s*B/(2*W) + πBB)\n",
    "    ΠCA = p*(s*B/W + πBA)\n",
    "    ΠCB = p*(s*B/(2*W) + πBB)\n",
    "    ΠCC = πAA + B/(2*W) - ϵ\n",
    "    ΠCD = πAB - ϵ\n",
    "    ΠCE = πAA + B/(2*W) - ϵ\n",
    "    ΠDA = p*(s*B/W + πBA)\n",
    "    ΠDB = p*(s*B/(2*W) + πBB)\n",
    "    ΠDC = p*(s*B/W + πBA) - ϵ\n",
    "    ΠDD = p*(s*B/(2*W) + πBB) - ϵ\n",
    "    ΠDE = punished_payoff - ϵ\n",
    "    ΠEA = p*(s*B/W + πBA) - ϵ\n",
    "    ΠEB = p*(s*B/(2*W) + πBB)\n",
    "    ΠEC = πAA + B/(2*W) - ϵ\n",
    "    ΠED = sanctioner_payoff - ϵ\n",
    "    ΠEE = πAA + B/(2*W) - ϵ\n",
    "    matrix = np.block([[ΠAA, ΠAB, ΠAC, ΠAD, ΠAE], \n",
    "                       [ΠBA, ΠBB, ΠBC, ΠBD, ΠBE],\n",
    "                       [ΠCA, ΠCB, ΠCC, ΠCD, ΠCE],\n",
    "                       [ΠDA, ΠDB, ΠDC, ΠDD, ΠDE],\n",
    "                       [ΠEA, ΠEB, ΠEC, ΠED, ΠEE]\n",
    "                       ])\n",
    "    return {**model, 'payoffs':matrix}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
