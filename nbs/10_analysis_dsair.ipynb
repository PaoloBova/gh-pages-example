{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8663e504-288d-4d04-bea2-ec3d8e6aceb6",
   "metadata": {},
   "source": [
    "# Analysis of the DSAIR model\n",
    "\n",
    "> A number of replications and extensions of The Anh et al.'s analysis of their DSAIR model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ca64e1-4ca6-4b66-80d6-2361849047c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp analysis_dsair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039a6fa5-e85d-468c-a3d0-8f314547c6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#| export\n",
    "from gh_pages_example.conditions import *\n",
    "from gh_pages_example.methods import *\n",
    "from gh_pages_example.payoffs import *\n",
    "from gh_pages_example.types import *\n",
    "from gh_pages_example.utils import *\n",
    "\n",
    "import typing\n",
    "\n",
    "import fastcore.test\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from nbdev.showdoc import *\n",
    "import nptyping\n",
    "import numpy as np\n",
    "import pandas\n",
    "import seaborn as sns "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6ac3f1-dd2d-4685-a3e3-c85baff0dd2b",
   "metadata": {},
   "source": [
    "This notebook contains a number of analyses of different versions of the DSAIR model.\n",
    "\n",
    "Each analysis involves a number of steps:\n",
    "\n",
    "1. Create parameter space\n",
    "2. Run the model\n",
    "3. Process the results\n",
    "4. Visualise results and explain what we observe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3055f551-02e7-417e-82b7-0efc1f7ed194",
   "metadata": {},
   "source": [
    "## Baseline DSAIR model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c476f8fe-d8a1-432c-b061-eb2af2c25b58",
   "metadata": {},
   "source": [
    "### Create parameter space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5cc21a7-9231-49fd-929e-9c9ebecb96ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def fig1_data(b:float=4,\n",
    "              c:float=1,\n",
    "              B:float=10**4,\n",
    "              W:float=100,\n",
    "              β:float=0.01,\n",
    "              Z:int=100,\n",
    "              S:list[str]=[\"AS\", \"AU\"],\n",
    "              collective:float=1) -> dict: # A dictionary containing the items in `ModelTypeDSAIR`\n",
    "    \"\"\"Initialise baseline DSAIR models which vary `s` and `p`. By default,\n",
    "    we create models for replicating Figure 1 of The Anh et al. 2021.\"\"\"\n",
    "    namesofvalues=['s','b','c','p','B','W','β','collective']\n",
    "    matchingvalues = np.array([[s,b,c,p,B,W,β,collective]\n",
    "                               for s in np.arange(1,5.1,0.1)\n",
    "                               for p in np.arange(0,1.02,0.02)])\n",
    "    models = {k:v for k, v in zip(namesofvalues, matchingvalues.T)}\n",
    "    models = {**models,\n",
    "              'Z':Z, # Z should be a scalar\n",
    "              'strategy_set':S # S should be a list of strings\n",
    "             }\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa5cfd7-2b4b-4a33-ba50-64a180df568d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/PaoloBova/gh-pages-example/blob/main/gh_pages_example/analysis_dsair.py#L25){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### fig1_data\n",
       "\n",
       ">      fig1_data (b:float=4, c:float=1, B:float=10000, W:float=100,\n",
       ">                 β:float=0.01, Z:int=100, S:list[str]=['AS', 'AU'],\n",
       ">                 collective:float=1)\n",
       "\n",
       "Initialise baseline DSAIR models which vary `s` and `p`. By default,\n",
       "we create models for replicating Figure 1 of The Anh et al. 2021.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| b | float | 4 |  |\n",
       "| c | float | 1 |  |\n",
       "| B | float | 10000 |  |\n",
       "| W | float | 100 |  |\n",
       "| β | float | 0.01 |  |\n",
       "| Z | int | 100 |  |\n",
       "| S | list | ['AS', 'AU'] |  |\n",
       "| collective | float | 1 |  |\n",
       "| **Returns** | **dict** |  | **A dictionary containing the items in `ModelTypeDSAIR`** |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/PaoloBova/gh-pages-example/blob/main/gh_pages_example/analysis_dsair.py#L25){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### fig1_data\n",
       "\n",
       ">      fig1_data (b:float=4, c:float=1, B:float=10000, W:float=100,\n",
       ">                 β:float=0.01, Z:int=100, S:list[str]=['AS', 'AU'],\n",
       ">                 collective:float=1)\n",
       "\n",
       "Initialise baseline DSAIR models which vary `s` and `p`. By default,\n",
       "we create models for replicating Figure 1 of The Anh et al. 2021.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| b | float | 4 |  |\n",
       "| c | float | 1 |  |\n",
       "| B | float | 10000 |  |\n",
       "| W | float | 100 |  |\n",
       "| β | float | 0.01 |  |\n",
       "| Z | int | 100 |  |\n",
       "| S | list | ['AS', 'AU'] |  |\n",
       "| collective | float | 1 |  |\n",
       "| **Returns** | **dict** |  | **A dictionary containing the items in `ModelTypeDSAIR`** |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(fig1_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990af254-8051-4b86-b0ae-d5985dbc240a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "models = fig1_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15003aa-ccf7-42c6-931b-4b1a22fcf463",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "b=4; c=1; B=10**4; W=100; β=0.1; Z=100; S=[\"AS\", \"AU\"]; collective=1\n",
    "models = fig1_data(b=b, c=c, B=B, W=W, β=β, Z=Z, S=S, collective=collective)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b11d3e-ec4e-4810-abe7-f2206180348a",
   "metadata": {},
   "source": [
    "### Run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34170d30-e5ae-4bbb-b629-10ceaf86c541",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "results = thread_macro(models,\n",
    "                       payoffs_sr,\n",
    "                       payoffs_lr,\n",
    "                       threshold_society_prefers_safety_dsair,\n",
    "                       threshold_risk_dominant_safety_dsair,\n",
    "                       markov_chain,\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df96df66-79ae-457d-8069-f18a79cafabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "{k:v.shape for k,v in results.items() if isinstance(v, np.ndarray)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d5ad71-88ea-4a7a-b761-f6046a697fdd",
   "metadata": {},
   "source": [
    "### Process the results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6526b240-610a-4a04-91e7-4610d90115cf",
   "metadata": {},
   "source": [
    "Now that we have collected some results, we need to process them so that we can display what we want to.\n",
    "\n",
    "The general approach I follow is to flatten the `results` dictionary and convert it into a [pandas](https://pandas.pydata.org/pandas-docs/stable/index.html) dataframe.\n",
    "\n",
    "Here, we also compute the risk of an AI related disaster, $p_{risk} = 1 - p$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb627850-0835-48df-8801-706c5dacab6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#| export\n",
    "\n",
    "flat_results = {k:results[k] for k in ['s','b','c','p','B','W','β',\n",
    "                                       'threshold_society_prefers_safety',\n",
    "                                       'threshold_risk_dominant_safety']}\n",
    "flat_results['pr'] = np.round(1 - flat_results['p'], 2)\n",
    "flat_results['s'] = np.round(flat_results['s'], 2)\n",
    "for i, strategy in enumerate([\"AS\", \"AU\"]):\n",
    "    flat_results[strategy + \"_frequency\"] = results['ergodic'][:,i]\n",
    "    \n",
    "df = pandas.DataFrame(flat_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42e253b-0b38-4f91-a276-fb1aad5092fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo:false\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e3817d-f2b1-4b1c-a91b-c81c9e6fd7f0",
   "metadata": {},
   "source": [
    "### Visualise results and explain what we observe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4ec6b8-18a4-42c8-8ed2-22b5a8cb0fd4",
   "metadata": {},
   "source": [
    "I am using the [Matplotlib](https://matplotlib.org/stable/index.html) library to visualize our data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d4b10d-ca62-403e-b08f-e2f9dfd25d25",
   "metadata": {},
   "source": [
    "#| hide\n",
    "\n",
    ":::{.callout-note}\n",
    "Note that there are five types of callouts, including: \n",
    "`note`, `tip`, `warning`, `caution`, and `important`.\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8986e9da-dc79-443d-b575-e673106c91f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "sns.set_theme(style='darkgrid',palette='deep' ,font='sans-serif', font_scale=1.4)\n",
    "plt.rcParams[\"axes.grid\"] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899b278d-39b1-4d62-b553-56ce68a9d4fc",
   "metadata": {},
   "source": [
    "I first replicate the Figure 1 from The Anh Han et al. 2021\n",
    "\n",
    "The figure describes how the the frequency of Always Unsafe (**AU**) varies with both the speed advantage given to those who play **AU**, $s$, and the risk that such firms cause an AI disaster, $p_{risk}$. We have also plotted two lines, the lower line shows the boundary where society is indifferent between the two strategies. A greater risk or a slower speed advantage from this boundary implies society prefers players to play Always Safe (**AS**). The higher line shows the threshold for which **AU** is risk dominant over **AS**. For this baseline model, risk dominance implies that the strategy will be selected for by evolution (which is why the line follows the boundary where players switch from **AU** to **AS**). As with the lower line, any higher risk or lower speed implies that **AS** will instead by risk dominant over **AU**.\n",
    "\n",
    "These lines therefore split the heatmap into 3 regions. \n",
    "(i) Society prefers **AS** and **AS** is selected by social learning.\n",
    "(ii) Society prefers **AS** but **AU** is selected by social learning\n",
    "(iii) Society prefers **AU** and **AU** is selected by social learning\n",
    "\n",
    "In region (i) companies will be alligned with Society's preference for safety. In region (iii), society is willing to accept the risks as they anticipate greater benefits from innovation. In region (ii), we see a dilemma where all players are choosing to play **AU**, even though society prefers them to play **AS**. We can refer to this region as the *Dilemma zone*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a3a581-d18d-44b6-8980-beedbddfb39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo:false\n",
    "table = df.pivot_table(index='pr', columns='s', values='AU_frequency')\n",
    "\n",
    "heatmap, ax = plt.subplots()\n",
    "im = ax.imshow(table.values,\n",
    "               cmap='inferno',\n",
    "               extent=[table.columns.min(),\n",
    "                       table.columns.max(),\n",
    "                       table.index.min(),\n",
    "                       table.index.max()],\n",
    "               interpolation='nearest',\n",
    "               origin='lower',\n",
    "               aspect='auto')\n",
    "ax.set(xlabel='Speed avantage, s',\n",
    "       ylabel='Risk of an AI disaster, pr')\n",
    "\n",
    "cbar = heatmap.colorbar(im)\n",
    "cbar.ax.set_ylabel('AU Frequency')\n",
    "\n",
    "# Add threshold boundaries to convey dilemma region\n",
    "plt.plot(table.columns, df[df.pr==1]['threshold_society_prefers_safety'])\n",
    "plt.plot(table.columns, df[df.pr==1]['threshold_risk_dominant_safety']);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5377847-ac06-4684-b6ef-2171709c8e7c",
   "metadata": {},
   "source": [
    ":::{.callout-caution}\n",
    "Note that this model is illustrative only: at best here, society refers to the collection of all firms.\n",
    "\n",
    "We could instead explicitly model society's preferences over safety and innovation, distinct from the companies. Such a model will still have the 3 regions we are currently discussing, though the negative externalities of an AI disaster will likely lead to a greater *dillemma zone*. \n",
    "\n",
    "Another insight that such an extension would communicate is that companies may have incentive to work together to make sure their preferences are weighted more highly than the rest of society. It would be interesting to see whether we can observe this in pracitse, for examle in the European AI Act. The main challenge this task presents us is how to determine whether companies are working together to have their voices heard or whether they each already have strong enough incentives to uniltaterally influence policy.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236d9089-feb3-49b0-9a5d-212fe9efadaf",
   "metadata": {},
   "source": [
    "I have also plotted a cross-section of the above heatmap for speed advantage, $s=1.5$. This plot shows how players are distributed between the 2 available strategies, $AU$ and $AS$. Here, the blue area represents the proportion of players who follow $AU$ for each level of risk, whereas the red area tells us the proportion who play $AS$. I also mark the 3 regions discussed above.\n",
    "\n",
    "We will often make use of this cross-section plot in more complex models when we want to show the relative frequencies of more than 2 strategies. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80dc11b7-2058-4e36-9e36-1878b5406d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo:false\n",
    "dfplot2 = df[df.s==1.5]\n",
    "x = dfplot2.pr.values\n",
    "y1 = dfplot2.AU_frequency.values\n",
    "y2 = dfplot2.AS_frequency.values\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.stackplot(x,\n",
    "             [y1, y2],\n",
    "             labels=['AU', 'AS'],\n",
    "             alpha=0.8)\n",
    "ax.legend(loc='upper left')\n",
    "ax.set_title('Strategy distribution')\n",
    "ax.set_xlabel('Risk of an AI disaster, pr')\n",
    "ax.set_ylabel('Proportion')\n",
    "\n",
    "# Add threshold boundaries to convey dilemma region\n",
    "plt.vlines([dfplot2[dfplot2.pr==1]['threshold_society_prefers_safety'],\n",
    "            dfplot2[dfplot2.pr==1]['threshold_risk_dominant_safety']],\n",
    "           0,\n",
    "           0.995,\n",
    "           colors=['C2', 'C3'],\n",
    "           linewidth=3,\n",
    "           label='pr*');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b673a3ec-e041-49ec-a938-6871a7d3803d",
   "metadata": {},
   "source": [
    "#| hide\n",
    "\n",
    "### Explain the patterns observed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a55edf-d4cc-4f89-90ac-35c6af087d5a",
   "metadata": {},
   "source": [
    "#| hide\n",
    "\n",
    "# References"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c50b416-290c-4b5a-ab60-4a84f50f24c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
